{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "o5IXxxDJpF4t",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "# EXERCISES Hyperparameter tuning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Task 1 : Import libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " Import the necessary libraries (Import pandas, numpy, matplotlib, seaborn, and sklearn libraries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-13T15:53:17.185611Z",
          "start_time": "2024-10-13T15:53:17.153174Z"
        },
        "id": "WlVApf6xpF4u"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Import libraries for data handling and visualization\n",
        "import pandas as pd  # voor dataframes\n",
        "import numpy as np  # voor numerieke arrays en berekeningen\n",
        "import matplotlib.pyplot as plt  # voor grafieken\n",
        "import seaborn as sns  # voor statistische visualisatie\n",
        "\n",
        "# Import scikit-learn modules (ML, validatie, etc.)\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_scorefrom sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import validation_curve\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Task 2 : Load the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "xJqqzvwhpF6r",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        " We load the data again from the Concrete Compressive Strength Dataset Regression Notebook 'Concrete_Data.csv'.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-13T18:51:23.634903Z",
          "start_time": "2024-10-13T18:51:23.551264Z"
        },
        "id": "RtAVIAsLpF6s",
        "outputId": "71957e9d-e2e6-4053-94d2-4eac0b0beae9"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"../Datasets/Concrete_data.csv\", sep=\",\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "Eb6-96GRpF6t",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "### Task 3 : Polynomial regression function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create a function 'polynomial_regression' with 2 parameters: degree (default=2) and **kwargs. The function returns a polynomial model, constructed by a pipeline \n",
        "of 'PolynomialFeatures' (with degree as parameter and include_bias set to False) and 'LinearRegression' (with **kwargs as parameter). \n",
        "What is the goal of the **kwargs parameter and what does the ** operator do?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-13T18:51:24.891126Z",
          "start_time": "2024-10-13T18:51:24.850098Z"
        },
        "id": "NCo39aidpF6u"
      },
      "outputs": [],
      "source": [
        "class GeneralRegression:\n",
        "    def __init__(self, degree=1, exp=False, log=False, **kwargs):\n",
        "        self.degree = degree\n",
        "        self.exp = exp\n",
        "        self.log = log\n",
        "        self.kwargs = kwargs\n",
        "        self.model = None\n",
        "        self.x_orig = None\n",
        "        self.y_orig = None\n",
        "        self.X = None\n",
        "        self.y = None\n",
        "\n",
        "    def fit(self, x: np.array, y: np.array):\n",
        "        self.x_orig = x\n",
        "        self.y_orig = y\n",
        "        self.X = x.reshape(-1, 1)\n",
        "\n",
        "        if self.exp:\n",
        "            self.y = np.log(y)\n",
        "\n",
        "        else:\n",
        "            self.y = y\n",
        "\n",
        "        if self.log:\n",
        "            self.X = np.log(self.X)\n",
        "\n",
        "        self.model = make_pipeline(PolynomialFeatures(degree=self.degree, include_bias=False), LinearRegression(**self.kwargs))\n",
        "        self.model.fit(self.X, self.y)\n",
        "\n",
        "    def predict(self, x: np.array):\n",
        "        X = x.reshape(-1, 1)\n",
        "\n",
        "        if self.exp:\n",
        "            return np.exp(self.model.predict(X))\n",
        "\n",
        "        if self.log:\n",
        "            return self.model.predict(np.log(X))\n",
        "\n",
        "        return self.model.predict(X)\n",
        "    \n",
        "#de ** operator verzamelt alle extra keyword arguments in een dictionary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "jQE9VvUspF6w",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "### Task 4 : Validation curves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "jQE9VvUspF6w",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "Create the the target variable 'csMPa' (y) and the feature variable (X) with 'Cement', 'Water', and 'Age' as features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Zet de correcte kolomnamen volgens de CSV\n",
        "y = data['csMPa']  # doelvariabele\n",
        "X = data[['cement', 'water', 'age']]  # features\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "jQE9VvUspF6w",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "Calculate the training and the validation R-squared scores for the polynomial regression models of degree 1 to 5. Use a cross-validation fold value of 5. \n",
        "Print the average scores over the different cross-validation folds for the different models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-13T18:51:30.740793Z",
          "start_time": "2024-10-13T18:51:30.173887Z"
        },
        "id": "Of-SWsvNpF6w",
        "outputId": "0648cacb-3fd1-4c9f-b161-94d2a3e8d6de"
      },
      "outputs": [],
      "source": [
        "degrees = range(1, 6)  # degrees 1 tot 5\n",
        "cv_folds = 5\n",
        "\n",
        "train_scores_all = []\n",
        "val_scores_all = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "jQE9VvUspF6w",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "Draw the validation curve. Use the median of the scores over the different cross validation folds. What you think about (underfitting/overfitting)? Is it useful to use a more complex model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-13T18:51:30.740793Z",
          "start_time": "2024-10-13T18:51:30.173887Z"
        },
        "id": "Of-SWsvNpF6w",
        "outputId": "0648cacb-3fd1-4c9f-b161-94d2a3e8d6de"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'polynomial_regression' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m degree \u001b[38;5;129;01min\u001b[39;00m degrees:\n\u001b[0;32m----> 2\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mpolynomial_regression\u001b[49m(degree\u001b[38;5;241m=\u001b[39mdegree)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# Gebruik validation_curve om training en validation scores te krijgen\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     train_scores, val_scores \u001b[38;5;241m=\u001b[39m validation_curve(\n\u001b[1;32m      6\u001b[0m         model, X, y, \n\u001b[1;32m      7\u001b[0m         param_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpolynomialfeatures__degree\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m         scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr2\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     11\u001b[0m     )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'polynomial_regression' is not defined"
          ]
        }
      ],
      "source": [
        "for degree in degrees:\n",
        "    model = polynomial_regression(degree=degree)\n",
        "    \n",
        "    # Gebruik validation_curve om training en validation scores te krijgen\n",
        "    train_scores, val_scores = validation_curve(\n",
        "        model, X, y, \n",
        "        param_name='polynomialfeatures__degree',\n",
        "        param_range=[degree],\n",
        "        cv=cv_folds,\n",
        "        scoring='r2'\n",
        "    )\n",
        "    \n",
        "    train_scores_all.append(train_scores.flatten())\n",
        "    val_scores_all.append(val_scores.flatten())\n",
        "    \n",
        "    # Print gemiddelde scores\n",
        "    print(f\"Degree {degree}:\")\n",
        "    print(f\"  Training R² (mean): {train_scores.mean():.4f} (±{train_scores.std():.4f})\")\n",
        "    print(f\"  Validation R² (mean): {val_scores.mean():.4f} (±{val_scores.std():.4f})\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "ztyAj1NTpF6y",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "### Task 5 : Grid Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "ztyAj1NTpF6y",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "Use grid search to find the optimal polynomial model. Use a two-dimensional grid of model features, namely the polynomial degree from 1 to 10 and the flag telling us whether to fit the intercept. Use a cross-validation fold value of 7. Print the best parameters and the best scores (mean over the folds)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-13T18:51:37.796285Z",
          "start_time": "2024-10-13T18:51:37.257847Z"
        },
        "id": "KdHdsszdpF6z",
        "outputId": "ac018315-1c2f-4b17-9722-372ed8f70ca6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
