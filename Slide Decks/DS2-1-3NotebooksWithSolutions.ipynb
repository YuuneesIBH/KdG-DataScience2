{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": []
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "vwYphyGpXy_C"
   },
   "source": [
    "\n",
    "# Learning the Python Basics\n",
    "\n",
    "The book \"Python Data Science handbook\" expects basic knowledge of Python. This notebook introduces all the important Python basics needed for this Data Science course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "vda2HWQbXy_I"
   },
   "source": [
    "## Exercise 1 - Basic Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "lVX7m2f0Xy_I"
   },
   "source": [
    "Print *Hello World* with the `print()`-function.\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HapN8zXWRUch",
    "ExecuteTime": {
     "end_time": "2025-01-31T13:41:15.522020Z",
     "start_time": "2025-01-31T13:41:15.510457Z"
    }
   },
   "source": [
    "#SOLUTION_START\n",
    "print('Hello World')\n",
    "#SOLUTION_END"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "YTeZ6DUrRUci"
   },
   "source": [
    "Now, create a variable `name` with your own name and print *Hello your_name*. Use a formatted string (`f'blaba {variable} blabla`) to create it, like `String.format()` in Java does.\n",
    "\n",
    "Here is an example of using an `f` string.\n",
    "```\n",
    "aantal = 3\n",
    "string_een = 'format'\n",
    "string_twee = 'specifiers'\n",
    "print(f'Dit is een string met {aantal} {string_een} {string_twee} erin')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3HtFcQyQXy_J",
    "ExecuteTime": {
     "end_time": "2025-01-31T13:41:15.568516Z",
     "start_time": "2025-01-31T13:41:15.557826Z"
    }
   },
   "source": [
    "#SOLUTION_START\n",
    "name = 'Wouter'\n",
    "print(f'Hello {name}')\n",
    "#SOLUTION_END"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Wouter\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "In Python, you work with modules. A module is similar to a package in Java.\n",
    "To use a module, you perform an import\n",
    "```\n",
    "import math\n",
    "```\n",
    "You then have a namespace 'math' with all the functionalities available in the module. You access them by prefixing your expression with the namespace (e.g., .math.)\n",
    "```\n",
    "print(f'{math.pi}')\n",
    "```\n",
    "You can also give an alias to a namespace. This is done to make your code more readable.\n",
    "```\n",
    "import math as m\n",
    "print(f'{m.exp2(8)}')\n",
    "```\n",
    "Finally, you can also import names directly into the main namespace\n",
    "```\n",
    "from math import sin\n",
    "print(f'{sin(1)}')\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "id": "LAb8jT5dW1a_"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "uYeGUu0EXy_L"
   },
   "source": [
    "Calculate the following and print them out.\n",
    "Print them also once using `f` where you print only 2 decimal places.\n",
    "* $25 \\cdot 10$\n",
    "* $e^4$\n",
    "* $3 \\cdot \\pi$\n",
    "* $sin(\\pi)$\n",
    "\n",
    "By placing `:.2f` between the format specifiers (e.g., {25*10:.2f}), you can limit the output to 2 decimal places. This can be useful for nicer formatting. The [formatting options](https://docs.python.org/3/library/string.html#format-examples) are quite extensive. We do not expect you to apply them yourself, but we often use it in the notebooks to present the output of code nicely."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BBzBL6C0Xy_M",
    "ExecuteTime": {
     "end_time": "2025-01-31T13:41:15.621372Z",
     "start_time": "2025-01-31T13:41:15.615012Z"
    }
   },
   "source": [
    "#SOLUTION_START\n",
    "import math\n",
    "print(f'{25 * 10:.2f}')\n",
    "print(f'{math.exp(4):.2f}')\n",
    "print(f'{3 * math.pi:.2f}')\n",
    "print(f'{math.sin(math.pi):.2f}')\n",
    "#SOLUTION_END"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250.00\n",
      "54.60\n",
      "9.42\n",
      "0.00\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "VRwTWVfDXy_N"
   },
   "source": [
    "Create separate variables for the following data. Then use the `type` function (e.g., type(a)) to print the data types of all variables.\n",
    "\n",
    "* 1\n",
    "* 1.23456\n",
    "* 'Hello World'\n",
    "* \"Hello World\"\n",
    "* 2 > 5\n",
    "* True\n",
    "* NaN (Not a Number)\n",
    "* infinity\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UH8gFYp-Xy_O",
    "ExecuteTime": {
     "end_time": "2025-01-31T13:41:15.678965Z",
     "start_time": "2025-01-31T13:41:15.674175Z"
    }
   },
   "source": [
    "#SOLUTION_START\n",
    "a = 1\n",
    "b = 1.23456\n",
    "c = 'Hello World'\n",
    "d = \"Hello World\"\n",
    "e = 2 > 5\n",
    "f = True\n",
    "g = math.nan\n",
    "h = math.inf\n",
    "print(type(a), type(b), type(c), type(d), type(e), type(f), type(g), type(h), sep='\\n')\n",
    "#SOLUTION_END"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n",
      "<class 'float'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'bool'>\n",
      "<class 'bool'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "so4UKFowRUck"
   },
   "source": [
    "Try the following basic operations on strings:\n",
    "* concatenation: with the `+` operator: `'Hello' + ' World'`\n",
    "* `.upper()`\n",
    "* `.replace( , )`\n",
    "* `in` operator: `'He' in 'Hello'`\n",
    "* `str(28)`: create a string object from `int`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LnkM4I1vRUck",
    "ExecuteTime": {
     "end_time": "2025-01-31T13:41:15.741237Z",
     "start_time": "2025-01-31T13:41:15.734738Z"
    }
   },
   "source": [
    "#SOLUTION_START\n",
    "s = 'Hello' + ' World'\n",
    "print(s.upper())\n",
    "s.replace('e', 'a')\n",
    "'He' in s\n",
    "str(28)\n",
    "#SOLUTION_END"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HELLO WORLD\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'28'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "gmoD7ByjRUck"
   },
   "source": [
    "## Exercise 2 - Data Structures in Python\n",
    "### List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "nKurA73XXy_P"
   },
   "source": [
    "First, create an empty Python **list** `a`.\n",
    "\n",
    "You can create an empty list with the `[]` operator, like this:\n",
    "\n",
    "```python\n",
    "a=[]\n",
    "```\n",
    "You can also create a list with the list() function, but usually, you use the square brackets where possible (see further for an example of using the list() function). Create your empty list below. Try both methods."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2UoFuQ2uXy_Q",
    "ExecuteTime": {
     "end_time": "2025-01-31T13:41:15.784435Z",
     "start_time": "2025-01-31T13:41:15.778938Z"
    }
   },
   "source": [
    "#SOLUTION_START\n",
    "a = list()\n",
    "a = []\n",
    "#SOLUTION_END"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "bQpNgC7FXy_Q"
   },
   "source": [
    "Now expand list a with the elements True and 10. Does this work? Could this also be done in Java? Use the append() method."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "q8T35VeyXy_R",
    "ExecuteTime": {
     "end_time": "2025-01-31T13:41:15.848606Z",
     "start_time": "2025-01-31T13:41:15.842552Z"
    }
   },
   "source": [
    "#SOLUTION_START\n",
    "a.append(True)\n",
    "a.append(10)\n",
    "a\n",
    "#SOLUTION_END\n",
    "# In Java, the elements must be of the same type. So only if they have a common supertype can this be done.\n",
    "# Since all classes inherit from Object, this can be done as List<object> a = new ArrayList<>(); but this has serious limitations in terms of using the elements. Unless you use instanceof and casts."
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, 10]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "4nHLgsVDXy_R"
   },
   "source": [
    "Insert the following list ['Hello', 10.3] between True and 10 using the insert method. Thus, you are going to add a list to a list."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KEzBQRl_Xy_R",
    "ExecuteTime": {
     "end_time": "2025-01-31T13:41:15.895652Z",
     "start_time": "2025-01-31T13:41:15.880156Z"
    }
   },
   "source": [
    "#SOLUTION_START\n",
    "a.insert(1, ['Hello', 10.3])\n",
    "a\n",
    "#SOLUTION_END"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, ['Hello', 10.3], 10]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "The range function is handy. It allows you to quickly create a list with consecutive numbers rl = list(range(3)\n",
    "```\n",
    "l_range1 = list(range(3))  # [0,1,2]\n",
    "l_range2 = list(range(3,6))  # start, stop [3,4,5] (6 not included)\n",
    "l_range3 = list(range(10,20,2)) # start, stop, step [10,12,14,16,18] (6 not included)\n",
    "```\n",
    "\n",
    "Create a range from 0 to 100.\n",
    "Create a second range from 101 to 1000 with steps of 10.\n",
    "Create a list where the two previous ranges are stored in one list. (Tip: Use the list method extend)"
   ],
   "metadata": {
    "collapsed": false,
    "id": "0VCU8zEIW1bF"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#SOLUTION_START\n",
    "l_appended = list(range(0,101)) # start, stop, step [10,12,14,16,18] (6 not included)\n",
    "l_appended.extend(range(101,1001,10))\n",
    "print(l_appended)\n",
    "#SOLUTION_END"
   ],
   "metadata": {
    "id": "lLYxf_BUW1bF",
    "ExecuteTime": {
     "end_time": "2025-01-31T13:41:15.945733Z",
     "start_time": "2025-01-31T13:41:15.941336Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 211, 221, 231, 241, 251, 261, 271, 281, 291, 301, 311, 321, 331, 341, 351, 361, 371, 381, 391, 401, 411, 421, 431, 441, 451, 461, 471, 481, 491, 501, 511, 521, 531, 541, 551, 561, 571, 581, 591, 601, 611, 621, 631, 641, 651, 661, 671, 681, 691, 701, 711, 721, 731, 741, 751, 761, 771, 781, 791, 801, 811, 821, 831, 841, 851, 861, 871, 881, 891, 901, 911, 921, 931, 941, 951, 961, 971, 981, 991]\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "xAAJSP8uXy_R"
   },
   "source": [
    "### Dictionary\n",
    "A dictionary can be created with the {} operator. It works the same as a Map in Java.\n",
    "```python\n",
    "d = {\n",
    "    # here come the key : value pairs.\n",
    "    # keys are often strings\n",
    "}\n",
    "```\n",
    "Now create a dictionary d with two keys:\n",
    "* 'a' : ['e','f']\n",
    "* 'b' : ['a','b']\n",
    "\n",
    "and print it out."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#SOLUTION_START\n",
    "d = {\n",
    "'a': ['e','f'],\n",
    "'b': ['a', 'b']\n",
    "}\n",
    "d\n",
    "#SOLUTION_END"
   ],
   "metadata": {
    "id": "nwIscY5qW1bF",
    "ExecuteTime": {
     "end_time": "2025-01-31T13:41:15.996137Z",
     "start_time": "2025-01-31T13:41:15.991296Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': ['e', 'f'], 'b': ['a', 'b']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "Try the methods .keys() and .values() on dictionary d. What does .items() do? Do you see a connection with the Map interface from Java? What does .items() do? Do you see a connection with the Map interface from Java?"
   ],
   "metadata": {
    "collapsed": false,
    "id": "bGdSI0VvW1bF"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#SOLUTION_START\n",
    "d.keys()\n",
    "d.values()\n",
    "d.items()\n",
    "\n",
    "#Yes, the keys and values are the keys and values of the map. The items are the entries of the map.\n",
    "#In Java, you can also get the keys with map.keySet() and the values with map.values()\n",
    "#In Java, you can also get the entries with map.entrySet(). This is the same as the items of the dictionary.\n",
    "#SOLUTION_END"
   ],
   "metadata": {
    "id": "zlPYigkiW1bG",
    "ExecuteTime": {
     "end_time": "2025-01-31T13:41:16.046300Z",
     "start_time": "2025-01-31T13:41:16.040187Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('a', ['e', 'f']), ('b', ['a', 'b'])])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "Add the dictionary to the list a. Now look at list a. What do you see?"
   ],
   "metadata": {
    "collapsed": false,
    "id": "Z9dsrDdmW1bG"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "j6R2Tn_eXy_S",
    "ExecuteTime": {
     "end_time": "2025-01-31T13:41:16.081451Z",
     "start_time": "2025-01-31T13:41:16.076202Z"
    }
   },
   "source": [
    "#SOLUTION_START\n",
    "a.append(d)\n",
    "a\n",
    "#SOLUTION_END"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, ['Hello', 10.3], 10, {'a': ['e', 'f'], 'b': ['a', 'b']}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "XIw9hPikRUcm"
   },
   "source": [
    "Print the length of the list with the len() function."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VexcDl4oRUcn",
    "ExecuteTime": {
     "end_time": "2025-01-31T13:41:16.108502Z",
     "start_time": "2025-01-31T13:41:16.103088Z"
    }
   },
   "source": [
    "#SOLUTION_START\n",
    "len(a)\n",
    "#SOLUTION_END"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "xBXaCMrnRUcn"
   },
   "source": [
    "Check if an element is in a list with the in operator: e in [...] Test this on list a."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "euxDiB7PRUcn",
    "ExecuteTime": {
     "end_time": "2025-01-31T13:41:16.146591Z",
     "start_time": "2025-01-31T13:41:16.141143Z"
    }
   },
   "source": [
    "#SOLUTION_START\n",
    "[1, 2, 3, 4] in a\n",
    "#SOLUTION_END"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "EUm_CEYpRUcn"
   },
   "source": [
    "Create a list b with the statement b=a. Change the first element of b to 10. Now print a. What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "IYesP4FcRUco",
    "ExecuteTime": {
     "end_time": "2025-01-31T13:41:16.181907Z",
     "start_time": "2025-01-31T13:41:16.159998Z"
    }
   },
   "source": [
    "#SOLUTION_START\n",
    "b = a\n",
    "b[0] = 10\n",
    "a\n",
    "#a is also changed. b is therefore a reference to a and not a copy.\n",
    "#SOLUTION_END"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, ['Hello', 10.3], 10, {'a': ['e', 'f'], 'b': ['a', 'b']}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "3hTNOovMRUco"
   },
   "source": [
    "Test the following methods on list a:\n",
    "* `.copy()`\n",
    "* `.remove()`\n",
    "* `.pop()`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "P2H6j-ToRUco",
    "ExecuteTime": {
     "end_time": "2025-01-31T13:41:16.245174Z",
     "start_time": "2025-01-31T13:41:16.240123Z"
    }
   },
   "source": [
    "#SOLUTION_START\n",
    "b = a.copy()\n",
    "b.remove(10)\n",
    "b.pop()\n",
    "b\n",
    "#SOLUTION_END"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Hello', 10.3], 10]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "source": [
    "### If-else\n",
    "In Pyhon if structures are written as follows:\n",
    "```python\n",
    "if condition:\n",
    "    a = 1\n",
    "elif condition:\n",
    "    a =2     \n",
    "else:\n",
    "    a = 3\n",
    "```\n",
    "Python uses indentation to indicate the code block. This is different from Java, where you use curly braces {}.\n",
    "Now write an if-else structure that prints 'True' if n1 is greater than n2, 'False' if n1 is less than n2, and 'Equal' if they are equal. Create two variables n1 and n2 and test your if-else structure.\n"
   ],
   "metadata": {
    "collapsed": false,
    "id": "cAD6kMppW1bH"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#SOLUTION_START\n",
    "n1 = 0\n",
    "n2 = 10\n",
    "if n1 > n2:\n",
    "    print('True')\n",
    "elif n1 < n2:\n",
    "    print('False')\n",
    "else:\n",
    "    print('Equal')\n",
    "#SOLUTION_END"
   ],
   "metadata": {
    "id": "NJ3FC2e8W1bH",
    "ExecuteTime": {
     "end_time": "2025-01-31T13:41:16.293863Z",
     "start_time": "2025-01-31T13:41:16.280443Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now adjust the if-else structure so that the first if also prints 'True' if n1 is 0. Use the `or` operator and use == for comparison."
   ],
   "metadata": {
    "collapsed": false,
    "id": "jdwrqKUsW1bH"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#SOLUTION_START\n",
    "if (n1 > n2) or n1==0 :\n",
    "    print('True')\n",
    "elif n1 < n2:\n",
    "    print('False')\n",
    "else:\n",
    "    print('Equal')\n",
    "#SOLUTION_END"
   ],
   "metadata": {
    "id": "mtMeCPPhW1bM",
    "ExecuteTime": {
     "end_time": "2025-01-31T13:41:16.343848Z",
     "start_time": "2025-01-31T13:41:16.324759Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "vqgFSU5mXy_S"
   },
   "source": [
    "### Iterating over data\n",
    "#### for-loop\n",
    "Create a new list and iterate over it with a for-loop. You can do this as follows:\n",
    "```python\n",
    "a = je_lijst\n",
    "\n",
    "for element in a:\n",
    "    # doe iets met het element\n",
    "```\n",
    "\n",
    "\n",
    "Iterate over the list of letters of the alphabet and print them with their index. The list of letters of the alphabet is available in the string library.\n",
    "\n",
    "```python\n",
    "import string\n",
    "string.ascii_letters  # this is a list of letters.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7qBtQ26sXy_T",
    "ExecuteTime": {
     "end_time": "2025-01-31T13:41:16.380154Z",
     "start_time": "2025-01-31T13:41:16.375184Z"
    }
   },
   "source": [
    "#SOLUTION_START\n",
    "import string\n",
    "\n",
    "for letter in string.ascii_letters:\n",
    "    print(letter)\n",
    "#SOLUTION_END"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "b\n",
      "c\n",
      "d\n",
      "e\n",
      "f\n",
      "g\n",
      "h\n",
      "i\n",
      "j\n",
      "k\n",
      "l\n",
      "m\n",
      "n\n",
      "o\n",
      "p\n",
      "q\n",
      "r\n",
      "s\n",
      "t\n",
      "u\n",
      "v\n",
      "w\n",
      "x\n",
      "y\n",
      "z\n",
      "A\n",
      "B\n",
      "C\n",
      "D\n",
      "E\n",
      "F\n",
      "G\n",
      "H\n",
      "I\n",
      "J\n",
      "K\n",
      "L\n",
      "M\n",
      "N\n",
      "O\n",
      "P\n",
      "Q\n",
      "R\n",
      "S\n",
      "T\n",
      "U\n",
      "V\n",
      "W\n",
      "X\n",
      "Y\n",
      "Z\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "fL5tlfUmXy_T"
   },
   "source": [
    "#### List comprehension\n",
    "\n",
    "A handy way to create a list is by using a list comprehension. A simple list comprehension is shown below. It is nothing more than a for-loop within square brackets ([]) where the function to be applied to the element comes before the for. List comprehensions provide compact code.\n",
    "\n",
    "```python\n",
    "[do_something_with(x) for x in list]\n",
    "```\n",
    "The example below creates a list of strings with a sequence number. It uses a formatted string.\n",
    "\n",
    "```python\n",
    "['column {i}' for i in range(1,21)]\n",
    "```\n",
    "\n",
    "\n",
    "Now create a list of squares, called squares, of all even numbers between 0 and 50 (inclusive)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Y4atNpxkXy_U",
    "ExecuteTime": {
     "end_time": "2025-01-31T13:41:16.423143Z",
     "start_time": "2025-01-31T13:41:16.417500Z"
    }
   },
   "source": [
    "#SOLUTION_START\n",
    "squares = [math.pow(i, 2) for i in range(0, 51, 2)]\n",
    "squares\n",
    "#SOLUTION_END"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 4.0,\n",
       " 16.0,\n",
       " 36.0,\n",
       " 64.0,\n",
       " 100.0,\n",
       " 144.0,\n",
       " 196.0,\n",
       " 256.0,\n",
       " 324.0,\n",
       " 400.0,\n",
       " 484.0,\n",
       " 576.0,\n",
       " 676.0,\n",
       " 784.0,\n",
       " 900.0,\n",
       " 1024.0,\n",
       " 1156.0,\n",
       " 1296.0,\n",
       " 1444.0,\n",
       " 1600.0,\n",
       " 1764.0,\n",
       " 1936.0,\n",
       " 2116.0,\n",
       " 2304.0,\n",
       " 2500.0]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "NzB9CKihRUcq"
   },
   "source": [
    "## Exercise 3 - Multi-dimensional lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "VKUCgJYJRUcq"
   },
   "source": [
    "Create a new Python list a that consists of two lists. You can do this by using square brackets twice.\n",
    "\n",
    "```python\n",
    "a = [\n",
    "        [1,2,3],\n",
    "        [4,5,6],\n",
    "        ...\n",
    "    ]\n",
    "```\n",
    "Create a two-dimensional list with 3 rows and 4 columns with the numbers 1 to 12. Do this in three ways:  \n",
    "by writing out all the values yourself\n",
    "by using the range() function\n",
    "by using a double list comprehension (this is more difficult). [[func(e) for e in l1] for i in l2]"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ecvABmFaRUcq",
    "ExecuteTime": {
     "end_time": "2025-01-31T13:41:16.466976Z",
     "start_time": "2025-01-31T13:41:16.460429Z"
    }
   },
   "source": [
    "#SOLUTION_START\n",
    "a = [[1, 2, 3, 4],\n",
    "     [5, 6, 7, 8],\n",
    "     [9, 10, 11, 12]]\n",
    "b = [list(range(1, 5)), list(range(5, 9)), list(range(9, 13))]\n",
    "c = [[e + i for e in range(0, 4)] for i in range(1, 10, 4)]\n",
    "\n",
    "print(a, b, c, sep='\\n')\n",
    "#SOLUTION_END"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]]\n",
      "[[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]]\n",
      "[[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]]\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "oIAerhtURUcq"
   },
   "source": [
    "Print the lengths of the different dimensions of your two-dimensional list. Apply the len() function to your entire list and to the rows of your list. Can you determine the dimensions (3 x 4)?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "W1ovPHhWRUcr",
    "ExecuteTime": {
     "end_time": "2025-01-31T13:41:16.514038Z",
     "start_time": "2025-01-31T13:41:16.508766Z"
    }
   },
   "source": [
    "#SOLUTION_START\n",
    "print(len(a))\n",
    "print(len(a[0]))\n",
    "#SOLUTION_END"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "b5pvzs_MXy_V"
   },
   "source": [
    "## Exercise 4 - Python functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "t49--hSMXy_V"
   },
   "source": [
    "As you probably know by now, Python is a complete object-oriented programming language, and of course, that includes user-defined functions. Here is an example of a function definition:\n",
    "\n",
    "```python\n",
    "def my_function(arg1, arg2, ..., argn):\n",
    "    # here you can calculate anything\n",
    "    # and possibly return one or more values with\n",
    "    return a,b,c,d      # we return 4 values at once (this is actually a 4-tuple)\n",
    "\n",
    "a,b,c,d = my_function(1, 2,..., 3)        # example of a call\n",
    "```\n",
    "Python is a dynamically typed language, which means that the data type of variables is only known during the execution of the program. This makes programming a bit more difficult because you are more likely to write errors (unlike Java). You can improve this somewhat by writing type hints yourself. You do this as follows, applied to the above example:\n",
    "\n",
    "```python\n",
    "def my_function(arg1 : int,arg2 : bool, ... ,argn: float):\n",
    "    # here you can calculate anything\n",
    "    # and possibly return one or more values with\n",
    "    return a,b,c,d      # we return 4 values\n",
    "\n",
    "a,b,c,d = my_function(1, True,..., 3.3)       # example of a call     # voorbeeld van een aanroep\n",
    "```\n",
    "PyCharm can take this into account and provide you with better code completion.\n",
    "Now write a function that calculates the BMI of a person based on their height (in meters, float), and their weight (in kg, float). and then execute it"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Szh_b-5vW1bO",
    "ExecuteTime": {
     "end_time": "2025-01-31T13:41:16.551968Z",
     "start_time": "2025-01-31T13:41:16.547458Z"
    }
   },
   "source": [
    "#SOLUTION_START\n",
    "def bmi(height: float, weight: float):\n",
    "    return weight / math.pow(height, 2)\n",
    "\n",
    "bmi(1.43, 70)\n",
    "#SOLUTION_END"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.231502762971296"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "source": [
    "You do not have to pass the parameters in order, but then you name the parameters\n",
    "```\n",
    "my_function(arg2=False, arg1=1)\n",
    "```\n",
    "\n",
    "You can also provide defaults for the parameters in the function. If you do not provide the parameter when executing, the function will use the default value. The parameters with defaults must always be placed after the non-default parameters\n",
    "\n",
    "```\n",
    "def my_function(arg2 :bool, arg1 : int = 1): ...\n",
    "\n",
    "my_function(arg2 = True)\n",
    "```\n",
    "\n",
    "Modify your bmi function so that the height defaults to 1.75. Call the function with only the weight as a parameter."
   ],
   "metadata": {
    "collapsed": false,
    "id": "a2VqtqW7W1bO"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#SOLUTION_START\n",
    "def bmi(weight: float, height: float = 1.75, ):\n",
    "    return weight / math.pow(height, 2)\n",
    "\n",
    "bmi(weight =  80)\n",
    "#SOLUTION_END"
   ],
   "metadata": {
    "id": "dIAUx4QnXy_V",
    "ExecuteTime": {
     "end_time": "2025-01-31T13:41:16.577013Z",
     "start_time": "2025-01-31T13:41:16.571993Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.122448979591837"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<!--BOOK_INFORMATION-->\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"figures/PDSH-cover-small.png\">\n",
    "\n",
    "*This notebook contains an excerpt from the [Python Data Science Handbook](http://shop.oreilly.com/product/0636920034919.do) by Jake VanderPlas; the content is available [on GitHub](https://github.com/jakevdp/PythonDataScienceHandbook).*\n",
    "\n",
    "*The text is released under the [CC-BY-NC-ND license](https://creativecommons.org/licenses/by-nc-nd/3.0/us/legalcode), and code is released under the [MIT license](https://opensource.org/licenses/MIT). If you find this content useful, please consider supporting the work by [buying the book](http://shop.oreilly.com/product/0636920034919.do)!*"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<!--NAVIGATION-->\n",
    "< [More IPython Resources](01.08-More-IPython-Resources.ipynb) | [Contents](Index.ipynb) | [Understanding Data Types in Python](02.01-Understanding-Data-Types.ipynb) >\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/02.00-Introduction-to-NumPy.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Introduction to NumPy"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This chapter, along with chapter 3, outlines techniques for effectively loading, storing, and manipulating in-memory data in Python.\n",
    "The topic is very broad: datasets can come from a wide range of sources and a wide range of formats, including be collections of documents, collections of images, collections of sound clips, collections of numerical measurements, or nearly anything else.\n",
    "Despite this apparent heterogeneity, it will help us to think of all data fundamentally as arrays of numbers.\n",
    "\n",
    "For example, images–particularly digital images–can be thought of as simply two-dimensional arrays of numbers representing pixel brightness across the area.\n",
    "Sound clips can be thought of as one-dimensional arrays of intensity versus time.\n",
    "Text can be converted in various ways into numerical representations, perhaps binary digits representing the frequency of certain words or pairs of words.\n",
    "No matter what the data are, the first step in making it analyzable will be to transform them into arrays of numbers.\n",
    "(We will discuss some specific examples of this process later in [Feature Engineering](05.04-Feature-Engineering.ipynb))\n",
    "\n",
    "For this reason, efficient storage and manipulation of numerical arrays is absolutely fundamental to the process of doing data science.\n",
    "We'll now take a look at the specialized tools that Python has for handling such numerical arrays: the NumPy package, and the Pandas package (discussed in Chapter 3).\n",
    "\n",
    "This chapter will cover NumPy in detail. NumPy (short for *Numerical Python*) provides an efficient interface to store and operate on dense data buffers.\n",
    "In some ways, NumPy arrays are like Python's built-in ``list`` type, but NumPy arrays provide much more efficient storage and data operations as the arrays grow larger in size.\n",
    "NumPy arrays form the core of nearly the entire ecosystem of data science tools in Python, so time spent learning to use NumPy effectively will be valuable no matter what aspect of data science interests you.\n",
    "\n",
    "If you followed the advice outlined in the Preface and installed the Anaconda stack, you already have NumPy installed and ready to go.\n",
    "If you're more the do-it-yourself type, you can go to http://www.numpy.org/ and follow the installation instructions found there.\n",
    "Once you do, you can import NumPy and double-check the version:"
   ]
  },
  {
   "metadata": {
    "deletable": true,
    "editable": true,
    "ExecuteTime": {
     "end_time": "2024-08-16T12:30:29.022075800Z",
     "start_time": "2024-08-16T12:30:28.565158700Z"
    },
    "id": "pv3PX68q8CIq",
    "outputId": "3e266391-4de1-46f8-800c-bab80c55f3b6"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'1.26.4'"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "import numpy\n",
    "numpy.__version__"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "For the pieces of the package discussed here, I'd recommend NumPy version 1.8 or later.\n",
    "By convention, you'll find that most people in the SciPy/PyData world will import NumPy using ``np`` as an alias:"
   ]
  },
  {
   "metadata": {
    "deletable": true,
    "editable": true,
    "id": "0eHM0R9X8CIr"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "import numpy as np"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Throughout this chapter, and indeed the rest of the book, you'll find that this is the way we will import and use NumPy."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Reminder about Built In Documentation\n",
    "\n",
    "As you read through this chapter, don't forget that IPython gives you the ability to quickly explore the contents of a package (by using the tab-completion feature), as well as the documentation of various functions (using the ``?`` character – Refer back to [Help and Documentation in IPython](01.01-Help-And-Documentation.ipynb)).\n",
    "\n",
    "For example, to display all the contents of the numpy namespace, you can type this:\n",
    "\n",
    "```ipython\n",
    "In [3]: np.<TAB>\n",
    "```\n",
    "\n",
    "And to display NumPy's built-in documentation, you can use this:\n",
    "\n",
    "```ipython\n",
    "In [4]: np?\n",
    "```\n",
    "\n",
    "More detailed documentation, along with tutorials and other resources, can be found at http://www.numpy.org."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<!--NAVIGATION-->\n",
    "< [More IPython Resources](01.08-More-IPython-Resources.ipynb) | [Contents](Index.ipynb) | [Understanding Data Types in Python](02.01-Understanding-Data-Types.ipynb) >\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/02.00-Introduction-to-NumPy.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<!--BOOK_INFORMATION-->\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"figures/PDSH-cover-small.png\">\n",
    "\n",
    "*This notebook contains an excerpt from the [Python Data Science Handbook](http://shop.oreilly.com/product/0636920034919.do) by Jake VanderPlas; the content is available [on GitHub](https://github.com/jakevdp/PythonDataScienceHandbook).*\n",
    "\n",
    "*The text is released under the [CC-BY-NC-ND license](https://creativecommons.org/licenses/by-nc-nd/3.0/us/legalcode), and code is released under the [MIT license](https://opensource.org/licenses/MIT). If you find this content useful, please consider supporting the work by [buying the book](http://shop.oreilly.com/product/0636920034919.do)!*"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<!--NAVIGATION-->\n",
    "< [Introduction to NumPy](02.00-Introduction-to-NumPy.ipynb) | [Contents](Index.ipynb) | [The Basics of NumPy Arrays](02.02-The-Basics-Of-NumPy-Arrays.ipynb) >\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/02.01-Understanding-Data-Types.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Understanding Data Types in Python"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Effective data-driven science and computation requires understanding how data is stored and manipulated.\n",
    "This section outlines and contrasts how arrays of data are handled in the Python language itself, and how NumPy improves on this.\n",
    "Understanding this difference is fundamental to understanding much of the material throughout the rest of the book.\n",
    "\n",
    "Users of Python are often drawn-in by its ease of use, one piece of which is dynamic typing.\n",
    "While a statically-typed language like C or Java requires each variable to be explicitly declared, a dynamically-typed language like Python skips this specification. For example, in C you might specify a particular operation as follows:\n",
    "\n",
    "```C\n",
    "/* C code */\n",
    "int result = 0;\n",
    "for(int i=0; i<100; i++){\n",
    "    result += i;\n",
    "}\n",
    "```\n",
    "\n",
    "While in Python the equivalent operation could be written this way:\n",
    "\n",
    "```python\n",
    "# Python code\n",
    "result = 0\n",
    "for i in range(100):\n",
    "    result += i\n",
    "```\n",
    "\n",
    "Notice the main difference: in C, the data types of each variable are explicitly declared, while in Python the types are dynamically inferred. This means, for example, that we can assign any kind of data to any variable:\n",
    "\n",
    "```python\n",
    "# Python code\n",
    "x = 4\n",
    "x = \"four\"\n",
    "```\n",
    "\n",
    "Here we've switched the contents of ``x`` from an integer to a string. The same thing in C would lead (depending on compiler settings) to a compilation error or other unintented consequences:\n",
    "\n",
    "```C\n",
    "/* C code */\n",
    "int x = 4;\n",
    "x = \"four\";  // FAILS\n",
    "```\n",
    "\n",
    "This sort of flexibility is one piece that makes Python and other dynamically-typed languages convenient and easy to use.\n",
    "Understanding *how* this works is an important piece of learning to analyze data efficiently and effectively with Python.\n",
    "But what this type-flexibility also points to is the fact that Python variables are more than just their value; they also contain extra information about the type of the value. We'll explore this more in the sections that follow."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## A Python Integer Is More Than Just an Integer\n",
    "\n",
    "The standard Python implementation is written in C.\n",
    "This means that every Python object is simply a cleverly-disguised C structure, which contains not only its value, but other information as well. For example, when we define an integer in Python, such as ``x = 10000``, ``x`` is not just a \"raw\" integer. It's actually a pointer to a compound C structure, which contains several values.\n",
    "Looking through the Python 3.4 source code, we find that the integer (long) type definition effectively looks like this (once the C macros are expanded):\n",
    "\n",
    "```C\n",
    "struct _longobject {\n",
    "    long ob_refcnt;\n",
    "    PyTypeObject *ob_type;\n",
    "    size_t ob_size;\n",
    "    long ob_digit[1];\n",
    "};\n",
    "```\n",
    "\n",
    "A single integer in Python 3.4 actually contains four pieces:\n",
    "\n",
    "- ``ob_refcnt``, a reference count that helps Python silently handle memory allocation and deallocation\n",
    "- ``ob_type``, which encodes the type of the variable\n",
    "- ``ob_size``, which specifies the size of the following data members\n",
    "- ``ob_digit``, which contains the actual integer value that we expect the Python variable to represent.\n",
    "\n",
    "This means that there is some overhead in storing an integer in Python as compared to an integer in a compiled language like C, as illustrated in the following figure:"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![Integer Memory Layout](figures/cint_vs_pyint.png)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Here ``PyObject_HEAD`` is the part of the structure containing the reference count, type code, and other pieces mentioned before.\n",
    "\n",
    "Notice the difference here: a C integer is essentially a label for a position in memory whose bytes encode an integer value.\n",
    "A Python integer is a pointer to a position in memory containing all the Python object information, including the bytes that contain the integer value.\n",
    "This extra information in the Python integer structure is what allows Python to be coded so freely and dynamically.\n",
    "All this additional information in Python types comes at a cost, however, which becomes especially apparent in structures that combine many of these objects."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## A Python List Is More Than Just a List\n",
    "\n",
    "Let's consider now what happens when we use a Python data structure that holds many Python objects.\n",
    "The standard mutable multi-element container in Python is the list.\n",
    "We can create a list of integers as follows:"
   ]
  },
  {
   "metadata": {
    "id": "wCimrA-Y_5dt",
    "outputId": "ab340270-bc61-4728-c37d-e68e10100286"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "L = list(range(10))\n",
    "L"
   ]
  },
  {
   "metadata": {
    "id": "0fGW6G3D_5dt",
    "outputId": "8e66aeff-f15e-43a3-d198-c77242d7a6bb"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "type(L[0])"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Or, similarly, a list of strings:"
  },
  {
   "metadata": {
    "id": "64HmlAuh_5du",
    "outputId": "a0d53d9e-bb56-4672-f825-ab03794dc892"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "L2 = [str(c) for c in L]\n",
    "L2"
   ]
  },
  {
   "metadata": {
    "id": "RqfuIj3p_5du",
    "outputId": "2a1b36dc-4bdd-4825-bf05-072057405691"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "type(L2[0])"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Because of Python's dynamic typing, we can even create heterogeneous lists:"
  },
  {
   "metadata": {
    "id": "X-zY1QYe_5dv",
    "outputId": "d1f88710-13c2-43cb-dc9f-c398af5285b0"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[bool, str, float, int]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "L3 = [True, \"2\", 3.0, 4]\n",
    "[type(item) for item in L3]"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "But this flexibility comes at a cost: to allow these flexible types, each item in the list must contain its own type info, reference count, and other information–that is, each item is a complete Python object.\n",
    "In the special case that all variables are of the same type, much of this information is redundant: it can be much more efficient to store data in a fixed-type array.\n",
    "The difference between a dynamic-type list and a fixed-type (NumPy-style) array is illustrated in the following figure:"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![Array Memory Layout](figures/array_vs_list.png)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "At the implementation level, the array essentially contains a single pointer to one contiguous block of data.\n",
    "The Python list, on the other hand, contains a pointer to a block of pointers, each of which in turn points to a full Python object like the Python integer we saw earlier.\n",
    "Again, the advantage of the list is flexibility: because each list element is a full structure containing both data and type information, the list can be filled with data of any desired type.\n",
    "Fixed-type NumPy-style arrays lack this flexibility, but are much more efficient for storing and manipulating data."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Fixed-Type Arrays in Python\n",
    "\n",
    "Python offers several different options for storing data in efficient, fixed-type data buffers.\n",
    "The built-in ``array`` module (available since Python 3.3) can be used to create dense arrays of a uniform type:"
   ]
  },
  {
   "metadata": {
    "id": "BJTw082w_5dw",
    "outputId": "317e43e2-099e-4ebc-d493-fa336b2f9c38"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array('i', [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "import array\n",
    "L = list(range(10))\n",
    "A = array.array('i', L)\n",
    "A"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Here ``'i'`` is a type code indicating the contents are integers.\n",
    "\n",
    "Much more useful, however, is the ``ndarray`` object of the NumPy package.\n",
    "While Python's ``array`` object provides efficient storage of array-based data, NumPy adds to this efficient *operations* on that data.\n",
    "We will explore these operations in later sections; here we'll demonstrate several ways of creating a NumPy array.\n",
    "\n",
    "We'll start with the standard NumPy import, under the alias ``np``:"
   ]
  },
  {
   "metadata": {
    "id": "-G7WD9Qy_5dw"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "import numpy as np"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Creating Arrays from Python Lists\n",
    "\n",
    "First, we can use ``np.array`` to create arrays from Python lists:"
   ]
  },
  {
   "metadata": {
    "id": "e3S_myPt_5dw",
    "outputId": "844b113e-26ca-48dc-8f0f-748e0aa5d0f3"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 2, 5, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "# integer array:\n",
    "np.array([1, 4, 2, 5, 3])"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Remember that unlike Python lists, NumPy is constrained to arrays that all contain the same type.\n",
    "If types do not match, NumPy will upcast if possible (here, integers are up-cast to floating point):"
   ]
  },
  {
   "metadata": {
    "id": "j2Q60JIM_5dw",
    "outputId": "6aa0553c-a6e7-4e35-f6cb-25ad5332ff7d"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.14,  4.  ,  2.  ,  3.  ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "np.array([3.14, 4, 2, 3])"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "If we want to explicitly set the data type of the resulting array, we can use the ``dtype`` keyword:"
  },
  {
   "metadata": {
    "id": "H70zksZ0_5dx",
    "outputId": "936d9234-c302-43fb-b497-58072fdd4146"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  2.,  3.,  4.], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "np.array([1, 2, 3, 4], dtype='float32')"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Finally, unlike Python lists, NumPy arrays can explicitly be multi-dimensional; here's one way of initializing a multidimensional array using a list of lists:"
  },
  {
   "metadata": {
    "id": "1dPAl_Jk_5dx",
    "outputId": "c3328c91-d09c-46a9-e4d5-7262feed899d"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 3, 4],\n",
       "       [4, 5, 6],\n",
       "       [6, 7, 8]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "# nested lists result in multi-dimensional arrays\n",
    "np.array([range(i, i + 3) for i in [2, 4, 6]])"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The inner lists are treated as rows of the resulting two-dimensional array."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Creating Arrays from Scratch\n",
    "\n",
    "Especially for larger arrays, it is more efficient to create arrays from scratch using routines built into NumPy.\n",
    "Here are several examples:"
   ]
  },
  {
   "metadata": {
    "id": "JXLIn6Pc_5dy",
    "outputId": "e3ccb05b-5c99-427b-a4e7-0aaa331cb4c0"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "# Create a length-10 integer array filled with zeros\n",
    "np.zeros(10, dtype=int)"
   ]
  },
  {
   "metadata": {
    "id": "B0S0oyFG_5dy",
    "outputId": "c7d8d1e8-74c7-4e83-dc0d-e39115a4ace9"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "# Create a 3x5 floating-point array filled with ones\n",
    "np.ones((3, 5), dtype=float)"
   ]
  },
  {
   "metadata": {
    "id": "ixG_XbW2_5dy",
    "outputId": "05843f70-47ec-4ed5-c9a0-0a24d64618e1"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.14,  3.14,  3.14,  3.14,  3.14],\n",
       "       [ 3.14,  3.14,  3.14,  3.14,  3.14],\n",
       "       [ 3.14,  3.14,  3.14,  3.14,  3.14]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "# Create a 3x5 array filled with 3.14\n",
    "np.full((3, 5), 3.14)"
   ]
  },
  {
   "metadata": {
    "id": "FKbUnQxR_5dy",
    "outputId": "0edb358e-8e4e-4c5c-c862-7b078c0e2879"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "# Create an array filled with a linear sequence\n",
    "# Starting at 0, ending at 20, stepping by 2\n",
    "# (this is similar to the built-in range() function)\n",
    "np.arange(0, 20, 2)"
   ]
  },
  {
   "metadata": {
    "id": "t-YHHC_-_5dy",
    "outputId": "8061e10a-5a53-4140-8085-3e126c53183e"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.  ,  0.25,  0.5 ,  0.75,  1.  ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "# Create an array of five values evenly spaced between 0 and 1\n",
    "np.linspace(0, 1, 5)"
   ]
  },
  {
   "metadata": {
    "id": "zknHCiKI_5dy",
    "outputId": "d2c180e7-2080-4ca1-8e55-96a8312cce9a"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99844933,  0.52183819,  0.22421193],\n",
       "       [ 0.08007488,  0.45429293,  0.20941444],\n",
       "       [ 0.14360941,  0.96910973,  0.946117  ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "# Create a 3x3 array of uniformly distributed\n",
    "# random values between 0 and 1\n",
    "np.random.random((3, 3))"
   ]
  },
  {
   "metadata": {
    "id": "RInYo-bV_5dz",
    "outputId": "f70ed96d-ef56-420d-ce5a-c2577046e853"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.51772646,  0.39614948, -0.10634696],\n",
       "       [ 0.25671348,  0.00732722,  0.37783601],\n",
       "       [ 0.68446945,  0.15926039, -0.70744073]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "# Create a 3x3 array of normally distributed random values\n",
    "# with mean 0 and standard deviation 1\n",
    "np.random.normal(0, 1, (3, 3))"
   ]
  },
  {
   "metadata": {
    "id": "WoT1OTic_5d0",
    "outputId": "2bc312f8-30b0-460b-95b2-55c976cfc55d"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 3, 4],\n",
       "       [5, 7, 8],\n",
       "       [0, 5, 0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "# Create a 3x3 array of random integers in the interval [0, 10)\n",
    "np.random.randint(0, 10, (3, 3))"
   ]
  },
  {
   "metadata": {
    "id": "KdVjScAW_5d0",
    "outputId": "bec84671-db82-4adc-9772-043649980f54"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "# Create a 3x3 identity matrix\n",
    "np.eye(3)"
   ]
  },
  {
   "metadata": {
    "id": "3L6zTMc5_5d0",
    "outputId": "d31afb22-d76d-40e4-9f66-a629d944b567"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "# Create an uninitialized array of three integers\n",
    "# The values will be whatever happens to already exist at that memory location\n",
    "np.empty(3)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## NumPy Standard Data Types\n",
    "\n",
    "NumPy arrays contain values of a single type, so it is important to have detailed knowledge of those types and their limitations.\n",
    "Because NumPy is built in C, the types will be familiar to users of C, Fortran, and other related languages.\n",
    "\n",
    "The standard NumPy data types are listed in the following table.\n",
    "Note that when constructing an array, they can be specified using a string:\n",
    "\n",
    "```python\n",
    "np.zeros(10, dtype='int16')\n",
    "```\n",
    "\n",
    "Or using the associated NumPy object:\n",
    "\n",
    "```python\n",
    "np.zeros(10, dtype=np.int16)\n",
    "```"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "| Data type\t    | Description |\n",
    "|---------------|-------------|\n",
    "| ``bool_``     | Boolean (True or False) stored as a byte |\n",
    "| ``int_``      | Default integer type (same as C ``long``; normally either ``int64`` or ``int32``)|\n",
    "| ``intc``      | Identical to C ``int`` (normally ``int32`` or ``int64``)|\n",
    "| ``intp``      | Integer used for indexing (same as C ``ssize_t``; normally either ``int32`` or ``int64``)|\n",
    "| ``int8``      | Byte (-128 to 127)|\n",
    "| ``int16``     | Integer (-32768 to 32767)|\n",
    "| ``int32``     | Integer (-2147483648 to 2147483647)|\n",
    "| ``int64``     | Integer (-9223372036854775808 to 9223372036854775807)|\n",
    "| ``uint8``     | Unsigned integer (0 to 255)|\n",
    "| ``uint16``    | Unsigned integer (0 to 65535)|\n",
    "| ``uint32``    | Unsigned integer (0 to 4294967295)|\n",
    "| ``uint64``    | Unsigned integer (0 to 18446744073709551615)|\n",
    "| ``float_``    | Shorthand for ``float64``.|\n",
    "| ``float16``   | Half precision float: sign bit, 5 bits exponent, 10 bits mantissa|\n",
    "| ``float32``   | Single precision float: sign bit, 8 bits exponent, 23 bits mantissa|\n",
    "| ``float64``   | Double precision float: sign bit, 11 bits exponent, 52 bits mantissa|\n",
    "| ``complex_``  | Shorthand for ``complex128``.|\n",
    "| ``complex64`` | Complex number, represented by two 32-bit floats|\n",
    "| ``complex128``| Complex number, represented by two 64-bit floats|"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "More advanced type specification is possible, such as specifying big or little endian numbers; for more information, refer to the [NumPy documentation](http://numpy.org/).\n",
    "NumPy also supports compound data types, which will be covered in [Structured Data: NumPy's Structured Arrays](02.09-Structured-Data-NumPy.ipynb)."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<!--NAVIGATION-->\n",
    "< [Introduction to NumPy](02.00-Introduction-to-NumPy.ipynb) | [Contents](Index.ipynb) | [The Basics of NumPy Arrays](02.02-The-Basics-Of-NumPy-Arrays.ipynb) >\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/02.01-Understanding-Data-Types.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 1. Understanding how integers and other datatypes are stored in Python\n",
    "a. Create an integer with value 1.\\\n",
    "b. Check how many bytes the variable occupies in memory (use getsizeof() of the sys module)\\\n",
    "c. Can you explain the difference with an integer in C which occupies 2 or 4 bytes in memory?\\"
   ]
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-22T08:15:32.006439800Z",
     "start_time": "2024-08-22T08:15:31.924495100Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "28"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3,
   "source": [
    "#SOLUTION_START\n",
    "# #a\n",
    "i = 1\n",
    "#b\n",
    "import sys\n",
    "sys.getsizeof(i)\n",
    "#c\n",
    "# Data types in Python are complex by default. It's'not only a reference to a memory location, it is a struct-type containing information like the count, size...\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 2. Understanding the difference between lists and np arrays\n",
    "a. Create a Python list with 3 one-digit integers. \\\n",
    "b. Append one item to the list with string value \"X\".\\\n",
    "c. Check how many bytes the list occupies in memory. \\\n",
    "_In case of a list, the total size is the sum of the list-object + the size of each seperate object in the list (as the list object only contain references to the list objects). You can use a __[list-comprehension](https://www.w3schools.com/python/python_lists_comprehension.asp)__ to loop through all the items_\\\n",
    "d. Now create a Numpy ndarray with the same 3 integers. Check the objectsize with getsizeof(). How many bytes does the ndarray occupy\\\n",
    "e. Also check the size of an indivdual element in the array with the 'itemsize' property of the ndarray object. How many bytes does one integer occupy? Explain the difference with a list object. _Using the list-comprehension as done with the list object will give confusing results as Python will convert the stored integer to a fully fledged \"int\" python object and will show the 28 byes of that object).\\\n",
    "f. Now 'append' an extra item with value 4 to the ndarray. Check the size of the ndarray again. How many bytes where added? Why?\\"
   ]
  },
  {
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-22T08:15:32.495729300Z",
     "start_time": "2024-08-22T08:15:32.018407800Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 'X']\n",
      "The size of the list is: 88 bytes\n",
      "The sizes of the elements are: [28, 28, 28, 50] bytes\n",
      "The total size is : 222 bytes\n",
      "The size of the array is: 124 bytes\n",
      "The sizes of the elements are: 4 bytes\n",
      "The size of the array is: 128 bytes\n"
     ]
    }
   ],
   "execution_count": 4,
   "source": [
    "#SOLUTION_START\n",
    "import math\n",
    "#a\n",
    "L_size = 3\n",
    "L = list(range(L_size))\n",
    "#b\n",
    "L.append(\"X\")\n",
    "print(L)\n",
    "#c\n",
    "#When using f before the string, you can use variables in the string by using curly brackets {}.\n",
    "print(f\"The size of the list is: {sys.getsizeof(L)} bytes\")\n",
    "print(f\"The sizes of the elements are: {[sys.getsizeof(E) for E in L]} bytes\")\n",
    "print(f\"The total size is : {sum([sys.getsizeof(E) for E in L]) + sys.getsizeof(L)} bytes\")\n",
    "#d\n",
    "import numpy as np\n",
    "A_size= 3\n",
    "A = np.array(range(A_size))\n",
    "print(f\"The size of the array is: {sys.getsizeof(A)} bytes\")\n",
    "#e\n",
    "print(f\"The sizes of the elements are: {A.itemsize} bytes\")\n",
    "#f\n",
    "A= np.append(4, A)\n",
    "print(f\"The size of the array is: {sys.getsizeof(A)} bytes\")\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 3. Creating Numpy arrays\n",
    "a. Array a1 has 10 ones of type float\\\n",
    "b. Array a2 has a range of numbers from 50 to (and including) 100 with steps of 2\\\n",
    "c. Array a3 has 10 random integers between 0 and 100. To do so, first create a random number generator with the default seed, then use the 'integers' method to create the array. _The seed makes sure that the random numbers are the same each time the code is executed._\\\n",
    "d. Array a4 has to contain the values of list 'l_ex3' \\\n",
    "e. Array a5 is a compact copy a2. Look for a dtype with a smaller size knowing that the values will never be higher then 100. _As you will be working with big datasets, reducing the size of the arrays will have a big impact on processing the data._\\\n",
    "f. Array a6 is an array of ones with 2 dimensions of 2 by 4. \\\n"
   ]
  },
  {
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-22T08:19:28.054521400Z",
     "start_time": "2024-08-22T08:19:27.996472300Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1=[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "a2=[50 52 54 56 58 60 62 64 66 68 70 72 74 76 78 80 82 84 86 88 90 92 94 96\n",
      " 98]\n",
      "a3=[ 9 78 66 44 43 86  8 70 20  9]\n",
      "a4=[1.   2.   3.14 4.  ]\n",
      "a5=[50 52 54 56 58 60 62 64 66 68 70 72 74 76 78 80 82 84 86 88 90 92 94 96\n",
      " 98]\n",
      "The size of a2 was reduced from 212 to 137 bytes\n",
      "a6=[[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "execution_count": 7,
   "source": [
    "l_oef3= [1,2,3.14,4]\n",
    "#SOLUTION_START\n",
    "a1= np.ones(10,dtype= 'float')\n",
    "print(f\"a1={a1}\")\n",
    "a2 = np.arange(50,100,2)\n",
    "print(f\"a2={a2}\")\n",
    "rng= np.random.default_rng(42)\n",
    "a3 = rng.integers(0,101,10) #high must be one above the to be drawn integer\"\n",
    "print(f\"a3={a3}\")\n",
    "a4 = np.array(l_oef3, dtype=np.float16)\n",
    "print(f\"a4={a4}\")\n",
    "a5 = np.array(a2,dtype= np.int8)\n",
    "print(f\"a5={a5}\")\n",
    "print(f\"The size of a2 was reduced from {sys.getsizeof(a2)} to {sys.getsizeof(a5)} bytes\")\n",
    "a6 = np.ones((2,4))\n",
    "print(f\"a6={a6}\")\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<!--BOOK_INFORMATION-->\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"figures/PDSH-cover-small.png\">\n",
    "\n",
    "*This notebook contains an excerpt from the [Python Data Science Handbook](http://shop.oreilly.com/product/0636920034919.do) by Jake VanderPlas; the content is available [on GitHub](https://github.com/jakevdp/PythonDataScienceHandbook).*\n",
    "\n",
    "*The text is released under the [CC-BY-NC-ND license](https://creativecommons.org/licenses/by-nc-nd/3.0/us/legalcode), and code is released under the [MIT license](https://opensource.org/licenses/MIT). If you find this content useful, please consider supporting the work by [buying the book](http://shop.oreilly.com/product/0636920034919.do)!*"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<!--NAVIGATION-->\n",
    "< [Understanding Data Types in Python](02.01-Understanding-Data-Types.ipynb) | [Contents](Index.ipynb) | [Computation on NumPy Arrays: Universal Functions](02.03-Computation-on-arrays-ufuncs.ipynb) >\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/02.02-The-Basics-Of-NumPy-Arrays.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# The Basics of NumPy Arrays"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Data manipulation in Python is nearly synonymous with NumPy array manipulation: even newer tools like Pandas ([Chapter 3](03.00-Introduction-to-Pandas.ipynb)) are built around the NumPy array.\n",
    "This section will present several examples of using NumPy array manipulation to access data and subarrays, and to split, reshape, and join the arrays.\n",
    "While the types of operations shown here may seem a bit dry and pedantic, they comprise the building blocks of many other examples used throughout the book.\n",
    "Get to know them well!\n",
    "\n",
    "We'll cover a few categories of basic array manipulations here:\n",
    "\n",
    "- *Attributes of arrays*: Determining the size, shape, memory consumption, and data types of arrays\n",
    "- *Indexing of arrays*: Getting and setting the value of individual array elements\n",
    "- *Slicing of arrays*: Getting and setting smaller subarrays within a larger array\n",
    "- *Reshaping of arrays*: Changing the shape of a given array\n",
    "- *Joining and splitting of arrays*: Combining multiple arrays into one, and splitting one array into many"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## NumPy Array Attributes"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "First let's discuss some useful array attributes.\n",
    "We'll start by defining three random arrays, a one-dimensional, two-dimensional, and three-dimensional array.\n",
    "We'll use NumPy's random number generator, which we will *seed* with a set value in order to ensure that the same random arrays are generated each time this code is run:"
   ]
  },
  {
   "metadata": {
    "id": "_zOgU318OdbE",
    "ExecuteTime": {
     "end_time": "2025-01-24T13:42:08.047938Z",
     "start_time": "2025-01-24T13:42:08.039843Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)  # seed for reproducibility\n",
    "\n",
    "x1 = np.random.randint(10, size=6)  # One-dimensional array\n",
    "x2 = np.random.randint(10, size=(3, 4))  # Two-dimensional array\n",
    "x3 = np.random.randint(10, size=(3, 4, 5))  # Three-dimensional array"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Each array has attributes ``ndim`` (the number of dimensions), ``shape`` (the\n",
    "\n",
    "---\n",
    "\n",
    "size of each dimension), and ``size`` (the total size of the array):"
   ]
  },
  {
   "metadata": {
    "id": "fEI3csvMOdbF",
    "outputId": "2b360d98-eeae-4c85-a472-73d0a2ef5bea",
    "ExecuteTime": {
     "end_time": "2025-01-24T13:42:08.131987Z",
     "start_time": "2025-01-24T13:42:08.126898Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1739114030967,
     "user_tz": -60,
     "elapsed": 33,
     "user": {
      "displayName": "Kjente Valgaeren",
      "userId": "12276948538992078824"
     }
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x3 ndim:  3\n",
      "x3 shape: (3, 4, 5)\n",
      "x3 size:  60\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "print(\"x3 ndim: \", x3.ndim)\n",
    "print(\"x3 shape:\", x3.shape)\n",
    "print(\"x3 size: \", x3.size)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Another useful attribute is the ``dtype``, the data type of the array (which we discussed previously in [Understanding Data Types in Python](02.01-Understanding-Data-Types.ipynb)):"
  },
  {
   "metadata": {
    "id": "vOC-w2TDOdbG",
    "outputId": "f58ac78a-edf6-4f7e-fd66-0f41c1af47d1",
    "ExecuteTime": {
     "end_time": "2025-01-24T13:42:08.948711Z",
     "start_time": "2025-01-24T13:42:08.942020Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype: int32\n"
     ]
    }
   ],
   "execution_count": null,
   "source": "print(\"dtype:\", x3.dtype)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Other attributes include ``itemsize``, which lists the size (in bytes) of each array element, and ``nbytes``, which lists the total size (in bytes) of the array:"
  },
  {
   "metadata": {
    "id": "H-3Z_TBoOdbG",
    "outputId": "5a96cb41-1286-4d15-bd48-8e0e94374c95",
    "ExecuteTime": {
     "end_time": "2025-01-24T13:42:08.971405Z",
     "start_time": "2025-01-24T13:42:08.963607Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "itemsize: 4 bytes\n",
      "nbytes: 240 bytes\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "print(\"itemsize:\", x3.itemsize, \"bytes\")\n",
    "print(\"nbytes:\", x3.nbytes, \"bytes\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In general, we expect that ``nbytes`` is equal to ``itemsize`` times ``size``."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Array Indexing: Accessing Single Elements"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "If you are familiar with Python's standard list indexing, indexing in NumPy will feel quite familiar.\n",
    "In a one-dimensional array, the $i^{th}$ value (counting from zero) can be accessed by specifying the desired index in square brackets, just as with Python lists:"
   ]
  },
  {
   "metadata": {
    "id": "0ZCYmq74OdbH",
    "outputId": "0529d666-db35-4575-9935-93f7240d3eeb",
    "ExecuteTime": {
     "end_time": "2025-01-24T13:42:09.072046Z",
     "start_time": "2025-01-24T13:42:09.063120Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 3, 3, 7, 9])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "x1"
  },
  {
   "metadata": {
    "id": "G8LDp5ZDOdbH",
    "outputId": "a34fe34a-9ddd-423a-9f84-4988c9ad695b",
    "ExecuteTime": {
     "end_time": "2025-01-24T13:42:09.212632Z",
     "start_time": "2025-01-24T13:42:09.202285Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "x1[0]"
  },
  {
   "metadata": {
    "id": "3KPfBLqkOdbH",
    "outputId": "11a438e2-2c65-42c2-d9e5-1570466c62d8",
    "ExecuteTime": {
     "end_time": "2025-01-24T13:42:09.342684Z",
     "start_time": "2025-01-24T13:42:09.330135Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "x1[4]"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "To index from the end of the array, you can use negative indices:"
  },
  {
   "metadata": {
    "id": "jwvAjFxqOdbH",
    "outputId": "3659a1fd-d668-4c29-c24c-94fadaeae63e",
    "ExecuteTime": {
     "end_time": "2025-01-24T13:42:09.464295Z",
     "start_time": "2025-01-24T13:42:09.456611Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "x1[-1]"
  },
  {
   "metadata": {
    "id": "_XSRb_1fOdbI",
    "outputId": "cc41297e-af48-4463-8cb7-cf6c0fe3c037",
    "ExecuteTime": {
     "end_time": "2025-01-24T13:42:09.542696Z",
     "start_time": "2025-01-24T13:42:09.529577Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "x1[-2]"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In a multi-dimensional array, items can be accessed using a comma-separated tuple of indices:"
  },
  {
   "metadata": {
    "id": "I3rXibXzOdbI",
    "outputId": "fd750006-5b9c-4d01-e4b8-788bbc5ea20d",
    "ExecuteTime": {
     "end_time": "2025-01-24T13:42:09.680101Z",
     "start_time": "2025-01-24T13:42:09.672571Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 5, 2, 4],\n",
       "       [7, 6, 8, 8],\n",
       "       [1, 6, 7, 7]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "x2"
  },
  {
   "metadata": {
    "id": "-_2MS48gOdbI",
    "outputId": "d25286c3-c155-42ed-ef77-6c442bcffa50",
    "ExecuteTime": {
     "end_time": "2025-01-24T13:42:09.806723Z",
     "start_time": "2025-01-24T13:42:09.797234Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "x2[0, 0]"
  },
  {
   "metadata": {
    "id": "CLh23LOcOdbI",
    "outputId": "17817835-d231-4721-dddc-5c52c1ad0bce",
    "ExecuteTime": {
     "end_time": "2025-01-24T13:42:09.958861Z",
     "start_time": "2025-01-24T13:42:09.952046Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "x2[2, 0]"
  },
  {
   "metadata": {
    "id": "mnSx0TyYOdbI",
    "outputId": "ae4d0f0c-41a0-4b78-9bd4-f1681ae243c6",
    "ExecuteTime": {
     "end_time": "2025-01-24T13:42:10.481192Z",
     "start_time": "2025-01-24T13:42:10.471541Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "x2[2, -1]"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Values can also be modified using any of the above index notation:"
  },
  {
   "metadata": {
    "id": "1g4olmCMOdbJ",
    "outputId": "272b85a8-e9f5-46a8-ae6b-413bb1b7c870",
    "ExecuteTime": {
     "end_time": "2025-01-24T13:42:12.496381Z",
     "start_time": "2025-01-24T13:42:12.489247Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12,  5,  2,  4],\n",
       "       [ 7,  6,  8,  8],\n",
       "       [ 1,  6,  7,  7]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "x2[0, 0] = 12\n",
    "x2"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Keep in mind that, unlike Python lists, NumPy arrays have a fixed type.\n",
    "This means, for example, that if you attempt to insert a floating-point value to an integer array, the value will be silently truncated. Don't be caught unaware by this behavior!"
   ]
  },
  {
   "metadata": {
    "id": "UmpAQ2CGOdbJ",
    "outputId": "ef62eed7-c140-47da-a944-893af742fbc4",
    "ExecuteTime": {
     "end_time": "2025-01-24T13:42:12.684677Z",
     "start_time": "2025-01-24T13:42:12.669366Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0, 3, 3, 7, 9])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "x1[0] = 3.14159  # this will be truncated!\n",
    "x1"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Array Slicing: Accessing Subarrays"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Just as we can use square brackets to access individual array elements, we can also use them to access subarrays with the *slice* notation, marked by the colon (``:``) character.\n",
    "The NumPy slicing syntax follows that of the standard Python list; to access a slice of an array ``x``, use this:\n",
    "``` python\n",
    "x[start:stop:step]\n",
    "```\n",
    "If any of these are unspecified, they default to the values ``start=0``, ``stop=``*``size of dimension``*, ``step=1``.\n",
    "We'll take a look at accessing sub-arrays in one dimension and in multiple dimensions."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### One-dimensional subarrays"
  },
  {
   "metadata": {
    "id": "Sg25rbwAOdbK",
    "outputId": "7b7ca5cc-33c1-48b8-8c90-0c8ffd5a07bf",
    "ExecuteTime": {
     "end_time": "2025-01-24T13:42:13.002253Z",
     "start_time": "2025-01-24T13:42:12.989916Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "x = np.arange(10)\n",
    "x"
   ]
  },
  {
   "metadata": {
    "id": "HRrZfpXIOdbK",
    "outputId": "1c959dc6-d4f0-4aa3-e995-d8f8de5d189c",
    "ExecuteTime": {
     "end_time": "2025-01-24T13:42:13.391775Z",
     "start_time": "2025-01-24T13:42:13.384531Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "x[:5]  # first five elements"
  },
  {
   "metadata": {
    "id": "ngroEcraOdbK",
    "outputId": "0dae7faa-1733-4faa-8ac3-7f7610431e8d",
    "ExecuteTime": {
     "end_time": "2025-01-24T13:42:13.694186Z",
     "start_time": "2025-01-24T13:42:13.683032Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "x[5:]  # elements after index 5"
  },
  {
   "metadata": {
    "id": "hxouqWrDOdbK",
    "outputId": "d534b6fe-c12f-4956-8492-135140b5d69f",
    "ExecuteTime": {
     "end_time": "2025-01-24T13:42:13.870533Z",
     "start_time": "2025-01-24T13:42:13.861845Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 5, 6])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "x[4:7]  # middle sub-array"
  },
  {
   "metadata": {
    "id": "mzWhUmouOdbK",
    "outputId": "81a8db5c-099f-447f-c928-09c1e9e04610",
    "ExecuteTime": {
     "end_time": "2025-01-24T13:42:14.004783Z",
     "start_time": "2025-01-24T13:42:13.988812Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 4, 6, 8])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "x[::2]  # every other element"
  },
  {
   "metadata": {
    "id": "YvF285lWOdbL",
    "outputId": "d12a7a75-48a5-4914-e2eb-71572c870897",
    "ExecuteTime": {
     "end_time": "2025-01-24T13:42:14.119677Z",
     "start_time": "2025-01-24T13:42:14.104451Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 5, 7, 9])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "x[1::2]  # every other element, starting at index 1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "A potentially confusing case is when the ``step`` value is negative.\n",
    "In this case, the defaults for ``start`` and ``stop`` are swapped.\n",
    "This becomes a convenient way to reverse an array:"
   ]
  },
  {
   "metadata": {
    "id": "xxAdtLGeOdbL",
    "outputId": "7ab51518-d8b8-4468-df8c-8ed1c072e680",
    "ExecuteTime": {
     "end_time": "2025-01-24T13:42:14.287933Z",
     "start_time": "2025-01-24T13:42:14.280224Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 8, 7, 6, 5, 4, 3, 2, 1, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "x[::-1]  # all elements, reversed"
  },
  {
   "metadata": {
    "id": "a8HSo-ZFOdbL",
    "outputId": "dffcbab8-7fc8-4fb2-835a-2b2b2d049cbe",
    "ExecuteTime": {
     "end_time": "2025-01-24T13:42:14.460501Z",
     "start_time": "2025-01-24T13:42:14.453035Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 3, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "x[5::-2]  # reversed every other from index 5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Multi-dimensional subarrays\n",
    "\n",
    "Multi-dimensional slices work in the same way, with multiple slices separated by commas.\n",
    "For example:"
   ]
  },
  {
   "metadata": {
    "id": "1D36rVVrOdbM",
    "outputId": "c59057ba-de89-4c1f-8b8c-0a3727a010ba",
    "ExecuteTime": {
     "end_time": "2025-01-24T13:42:14.583996Z",
     "start_time": "2025-01-24T13:42:14.576051Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12,  5,  2,  4],\n",
       "       [ 7,  6,  8,  8],\n",
       "       [ 1,  6,  7,  7]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "x2"
  },
  {
   "metadata": {
    "id": "LTS3ILlHOdbM",
    "outputId": "515cba3e-8620-432f-9a9e-3cc95839896a",
    "ExecuteTime": {
     "end_time": "2025-01-24T13:42:14.883879Z",
     "start_time": "2025-01-24T13:42:14.869168Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12,  5,  2],\n",
       "       [ 7,  6,  8]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "x2[:2, :3]  # two rows, three columns"
  },
  {
   "metadata": {
    "id": "h2nVqK64OdbM",
    "outputId": "07f1f76f-76ee-408b-e5f0-f195e8c0cf5e",
    "ExecuteTime": {
     "end_time": "2025-01-24T13:42:15.178397Z",
     "start_time": "2025-01-24T13:42:15.168369Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12,  2],\n",
       "       [ 7,  8],\n",
       "       [ 1,  7]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "x2[:3, ::2]  # all rows, every other column"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Finally, subarray dimensions can even be reversed together:"
  },
  {
   "metadata": {
    "id": "g-B2MESbOdbM",
    "outputId": "8b03faf5-0c9e-458c-aa4c-0e79c0fb1c58",
    "ExecuteTime": {
     "end_time": "2025-01-24T13:42:15.916745Z",
     "start_time": "2025-01-24T13:42:15.903157Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7,  7,  6,  1],\n",
       "       [ 8,  8,  6,  7],\n",
       "       [ 4,  2,  5, 12]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "x2[::-1, ::-1]"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Accessing array rows and columns\n",
    "\n",
    "One commonly needed routine is accessing of single rows or columns of an array.\n",
    "This can be done by combining indexing and slicing, using an empty slice marked by a single colon (``:``):"
   ]
  },
  {
   "metadata": {
    "id": "u1xpWH6DOdbN",
    "outputId": "b47cc9c9-c2dd-4963-d0fa-8fd9e33ef02f",
    "ExecuteTime": {
     "end_time": "2025-01-24T13:42:16.266779Z",
     "start_time": "2025-01-24T13:42:16.261817Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12  7  1]\n"
     ]
    }
   ],
   "execution_count": null,
   "source": "print(x2[:, 0])  # first column of x2"
  },
  {
   "metadata": {
    "id": "xm2VkXKPOdbN",
    "outputId": "962c2394-386b-4fd3-8dc5-69cf37290e5d",
    "ExecuteTime": {
     "end_time": "2025-01-24T13:42:16.901064Z",
     "start_time": "2025-01-24T13:42:16.895448Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12  5  2  4]\n"
     ]
    }
   ],
   "execution_count": null,
   "source": "print(x2[0, :])  # first row of x2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In the case of row access, the empty slice can be omitted for a more compact syntax:"
  },
  {
   "metadata": {
    "id": "-gU8-XJaOdbN",
    "outputId": "36e2c41a-7550-4c41-c7cd-09cb62877cda",
    "ExecuteTime": {
     "end_time": "2025-01-24T13:42:17.217817Z",
     "start_time": "2025-01-24T13:42:17.208139Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12  5  2  4]\n"
     ]
    }
   ],
   "execution_count": null,
   "source": "print(x2[0])  # equivalent to x2[0, :]"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Subarrays as no-copy views\n",
    "\n",
    "One important–and extremely useful–thing to know about array slices is that they return *views* rather than *copies* of the array data.\n",
    "This is one area in which NumPy array slicing differs from Python list slicing: in lists, slices will be copies.\n",
    "Consider our two-dimensional array from before:"
   ]
  },
  {
   "metadata": {
    "id": "4uPFDNEGOdbO",
    "outputId": "3578e30b-2a0a-4f31-891c-b7efaeca274f",
    "ExecuteTime": {
     "end_time": "2025-01-24T13:42:17.528677Z",
     "start_time": "2025-01-24T13:42:17.522408Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12  5  2  4]\n",
      " [ 7  6  8  8]\n",
      " [ 1  6  7  7]]\n"
     ]
    }
   ],
   "execution_count": null,
   "source": "print(x2)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's extract a $2 \\times 2$ subarray from this:"
  },
  {
   "metadata": {
    "id": "tCaALbkpOdbO",
    "outputId": "ada3fb76-413d-4a44-8d01-39a17cb8e074",
    "ExecuteTime": {
     "end_time": "2025-01-24T13:42:17.749570Z",
     "start_time": "2025-01-24T13:42:17.739792Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12  5]\n",
      " [ 7  6]]\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "x2_sub = x2[:2, :2]\n",
    "print(x2_sub)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now if we modify this subarray, we'll see that the original array is changed! Observe:"
  },
  {
   "metadata": {
    "id": "LNRsqEfcOdbO",
    "outputId": "9e0e7c6d-0558-4b2d-9d12-acd014cccf23",
    "ExecuteTime": {
     "end_time": "2025-01-24T13:42:17.896749Z",
     "start_time": "2025-01-24T13:42:17.890371Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[99  5]\n",
      " [ 7  6]]\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "x2_sub[0, 0] = 99\n",
    "print(x2_sub)"
   ]
  },
  {
   "metadata": {
    "id": "u7RYvUzOOdbP",
    "outputId": "0ff83a19-810d-421d-cd49-9590f256b87a",
    "ExecuteTime": {
     "end_time": "2025-01-24T13:42:18.020874Z",
     "start_time": "2025-01-24T13:42:18.012102Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[99  5  2  4]\n",
      " [ 7  6  8  8]\n",
      " [ 1  6  7  7]]\n"
     ]
    }
   ],
   "execution_count": null,
   "source": "print(x2)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This default behavior is actually quite useful: it means that when we work with large datasets, we can access and process pieces of these datasets without the need to copy the underlying data buffer."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Creating copies of arrays\n",
    "\n",
    "Despite the nice features of array views, it is sometimes useful to instead explicitly copy the data within an array or a subarray. This can be most easily done with the ``copy()`` method:"
   ]
  },
  {
   "metadata": {
    "id": "iO2pS3MTOdbP",
    "outputId": "ff2c6c78-d710-49d1-94f2-c1e0b5644b8a",
    "ExecuteTime": {
     "end_time": "2025-01-24T13:42:18.150523Z",
     "start_time": "2025-01-24T13:42:18.144526Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[99  5]\n",
      " [ 7  6]]\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "x2_sub_copy = x2[:2, :2].copy()\n",
    "print(x2_sub_copy)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "If we now modify this subarray, the original array is not touched:"
  },
  {
   "metadata": {
    "id": "JEq8KDnkOdbP",
    "outputId": "5da29220-e1cd-4316-caa7-cebb3e30ed86",
    "ExecuteTime": {
     "end_time": "2025-01-24T13:42:18.271273Z",
     "start_time": "2025-01-24T13:42:18.264490Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42  5]\n",
      " [ 7  6]]\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "x2_sub_copy[0, 0] = 42\n",
    "print(x2_sub_copy)"
   ]
  },
  {
   "metadata": {
    "id": "16AaUmC_OdbQ",
    "outputId": "ac832756-222c-44e6-ba72-493f49d2de64",
    "ExecuteTime": {
     "end_time": "2025-01-24T13:42:18.347942Z",
     "start_time": "2025-01-24T13:42:18.341463Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[99  5  2  4]\n",
      " [ 7  6  8  8]\n",
      " [ 1  6  7  7]]\n"
     ]
    }
   ],
   "execution_count": null,
   "source": "print(x2)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Reshaping of Arrays\n",
    "\n",
    "Another useful type of operation is reshaping of arrays.\n",
    "The most flexible way of doing this is with the ``reshape`` method.\n",
    "For example, if you want to put the numbers 1 through 9 in a $3 \\times 3$ grid, you can do the following:"
   ]
  },
  {
   "metadata": {
    "id": "EVmX2VcxOdbQ",
    "outputId": "10c982ea-1a4f-4d67-f5e6-3a58a46a7187",
    "ExecuteTime": {
     "end_time": "2025-01-24T13:42:18.519058Z",
     "start_time": "2025-01-24T13:42:18.508864Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "grid = np.arange(1, 10).reshape((3, 3))\n",
    "print(grid)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Note that for this to work, the size of the initial array must match the size of the reshaped array.\n",
    "Where possible, the ``reshape`` method will use a no-copy view of the initial array, but with non-contiguous memory buffers this is not always the case.\n",
    "\n",
    "Another common reshaping pattern is the conversion of a one-dimensional array into a two-dimensional row or column matrix.\n",
    "This can be done with the ``reshape`` method, or more easily done by making use of the ``newaxis`` keyword within a slice operation:"
   ]
  },
  {
   "metadata": {
    "id": "dtm2dxkPOdbQ",
    "outputId": "fd5f8f36-2716-408d-b783-4ce8d40ece8f",
    "ExecuteTime": {
     "end_time": "2025-01-24T13:42:18.770329Z",
     "start_time": "2025-01-24T13:42:18.763343Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "x = np.array([1, 2, 3])\n",
    "\n",
    "# row vector via reshape\n",
    "x.reshape((1, 3))"
   ]
  },
  {
   "metadata": {
    "id": "p0SxGVG4OdbQ",
    "outputId": "698ccf9e-156c-4c11-e921-691ee2a36d4a",
    "ExecuteTime": {
     "end_time": "2025-01-24T13:42:18.931758Z",
     "start_time": "2025-01-24T13:42:18.923067Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "# row vector via newaxis\n",
    "x[np.newaxis, :]"
   ]
  },
  {
   "metadata": {
    "id": "xYVNiQBHOdbR",
    "outputId": "7d941f9f-4f2d-4d7e-c205-458518bb9159",
    "ExecuteTime": {
     "end_time": "2025-01-24T13:42:19.231894Z",
     "start_time": "2025-01-24T13:42:19.225630Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [2],\n",
       "       [3]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "# column vector via reshape\n",
    "x.reshape((3, 1))"
   ]
  },
  {
   "metadata": {
    "id": "7REUxwBKOdbR",
    "outputId": "f5ee2a5c-1c61-41a2-9d58-f3fcd70c328e",
    "ExecuteTime": {
     "end_time": "2025-01-24T13:42:19.915861Z",
     "start_time": "2025-01-24T13:42:19.901496Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [2],\n",
       "       [3]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "# column vector via newaxis\n",
    "x[:, np.newaxis]"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We will see this type of transformation often throughout the remainder of the book."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Array Concatenation and Splitting\n",
    "\n",
    "All of the preceding routines worked on single arrays. It's also possible to combine multiple arrays into one, and to conversely split a single array into multiple arrays. We'll take a look at those operations here."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Concatenation of arrays\n",
    "\n",
    "Concatenation, or joining of two arrays in NumPy, is primarily accomplished using the routines ``np.concatenate``, ``np.vstack``, and ``np.hstack``.\n",
    "``np.concatenate`` takes a tuple or list of arrays as its first argument, as we can see here:"
   ]
  },
  {
   "metadata": {
    "id": "VTa2vZTqOdbR",
    "outputId": "ccc7f0a9-3fde-4b59-a404-ab7c346e0df8",
    "ExecuteTime": {
     "end_time": "2025-01-24T13:42:20.317997Z",
     "start_time": "2025-01-24T13:42:20.304759Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 3, 2, 1])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "x = np.array([1, 2, 3])\n",
    "y = np.array([3, 2, 1])\n",
    "np.concatenate([x, y])"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "You can also concatenate more than two arrays at once:"
  },
  {
   "metadata": {
    "id": "DPfa0HsaOdbS",
    "outputId": "141164a7-c5e7-4c25-d743-2bd09c5d8e45",
    "ExecuteTime": {
     "end_time": "2025-01-24T13:42:20.900701Z",
     "start_time": "2025-01-24T13:42:20.893774Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  3  2  1 99 99 99]\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "z = [99, 99, 99]\n",
    "print(np.concatenate([x, y, z]))"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "It can also be used for two-dimensional arrays:"
  },
  {
   "metadata": {
    "id": "3lDSk8AQOdbS",
    "ExecuteTime": {
     "end_time": "2025-01-24T13:42:21.244637Z",
     "start_time": "2025-01-24T13:42:21.238531Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "grid = np.array([[1, 2, 3],\n",
    "                 [4, 5, 6]])"
   ]
  },
  {
   "metadata": {
    "id": "GewmfV8mOdbS",
    "outputId": "6dc72556-d44a-49f8-8303-44afd321f64b",
    "ExecuteTime": {
     "end_time": "2025-01-24T13:42:21.656220Z",
     "start_time": "2025-01-24T13:42:21.633051Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6],\n",
       "       [1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "# concatenate along the first axis\n",
    "np.concatenate([grid, grid])"
   ]
  },
  {
   "metadata": {
    "id": "gF8t22lLOdbS",
    "outputId": "f41ce126-33e1-475c-ea77-e43a844fd571",
    "ExecuteTime": {
     "end_time": "2025-01-24T13:42:21.916050Z",
     "start_time": "2025-01-24T13:42:21.909347Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 1, 2, 3],\n",
       "       [4, 5, 6, 4, 5, 6]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "# concatenate along the second axis (zero-indexed)\n",
    "np.concatenate([grid, grid], axis=1)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div style=\"border: 2px solid red; padding: 10px; border-radius: 5px; background-color: #f8d7da; color: #721c24;\">\n",
    "<strong>!</strong> hstack and vstack and Splitting of arrays are not part of the course and are deleted from this notebook.</div>\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<!--NAVIGATION-->\n",
    "< [Understanding Data Types in Python](02.01-Understanding-Data-Types.ipynb) | [Contents](Index.ipynb) | [Computation on NumPy Arrays: Universal Functions](02.03-Computation-on-arrays-ufuncs.ipynb) >\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/02.02-The-Basics-Of-NumPy-Arrays.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>\n"
   ]
  },
  {
   "metadata": {
    "collapsed": true,
    "id": "initial_id",
    "ExecuteTime": {
     "end_time": "2025-01-24T15:17:53.957157Z",
     "start_time": "2025-01-24T15:17:53.945461Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "execution_count": 5,
   "source": [
    "import numpy as np\n",
    "import sklearn.datasets as ds\n",
    "\n",
    "a = np.array(ds.load_iris().data)\n",
    "b= a[:,1]\n",
    "\n",
    "print(ds.load_iris().feature_names)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 1. Numpy Array Attributes\n",
    "In this exercise we will use the `iris` dataset from the sklearn module. The features (independent variables) define properties of the flowers (see output above). The target (dependent variable) is the species of the flower. We stored the features in the array a.\n",
    "\n",
    " a. Get the number of dimensions of array a. Use the correct attribute\\\n",
    " b. Get the shape of the array. How many rows and columns does the array have.\\\n",
    " c. What datatype is used in the array?\\"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T13:24:32.430492100Z",
     "start_time": "2024-08-19T13:24:32.419357900Z"
    },
    "id": "973cb3606c20de7d",
    "outputId": "ed2af434-549a-4879-d43c-a83bb1e0858d"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of dimensions is 2. The array has  150 rows and 4 columns  with dtype float64\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "print(f'The number of dimensions is {a.ndim}. '\n",
    "      f'The array has  {a.shape[0]} rows and {a.shape[1]} columns '\n",
    "      f'with dtype {a.dtype}')\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 2. Indexing\n",
    "Array b contains the second column of array a.\\\n",
    "\n",
    "a. From array b, get the 3th value (should be 3.2)\\\n",
    "b. From array b, get the 3th last value  (should be 3.0)\\\n",
    "c. From array a, get the value of the 3th column of the 91st row of array a (should be 4.4)\\\n",
    "d. From array a, from the last row get the first column (should be 5.9)\\"
   ]
  },
  {
   "metadata": {
    "id": "bc2d4d0124abf621",
    "outputId": "942ef322-6aae-4277-fa50-144ac2b8a018",
    "ExecuteTime": {
     "end_time": "2025-01-24T15:23:24.664196Z",
     "start_time": "2025-01-24T15:23:24.657906Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2\n",
      "3.0\n",
      "4.4\n",
      "5.9\n"
     ]
    }
   ],
   "execution_count": 6,
   "source": [
    "#SOLUTION_START\n",
    "#a\n",
    "print(b[2])\n",
    "#b\n",
    "print(b[-3])\n",
    "#c\n",
    "print(a[90,2])\n",
    "#d\n",
    "print(a[-1,0])\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Slicing\n",
    "a. From array b, get the first 10 elements. (The features of the first 10 flowers.)\\\n",
    "b. From array b, get the flowers starting from the 10th row until the 20th row (including the 20th elemement)\\\n",
    "b. From array b, get all the flowers after the 50th row\\\n",
    "d. From array b, display the last 5 flowers\\\n",
    "e. From array b, display only every 3th flower\\\n",
    "f. From array b, display each 5th flower from the first 100 flowers\\\n",
    "g. From array a, display the rows of the first 10 elements (flowers)\\\n",
    "h. From array a, display the last two columns of the rows with index 10 to 20 (20 not included)\\\n",
    "i. From array a, display the second column of each second element.\\\n",
    "j. Based on array a, make a new array c with the 20 first rows with column 1 and 2. Make sure changes in the new array are not applied on the original aray.\\\n",
    "k. change element c[0,0] to 1. Check if a[0,0] is not changed\\\n",
    "l. Based on array a, make a new array l with 100 by 6 instead of 150 by 4.\\\n",
    "The outputs should look like this:\n",
    "```\n",
    "a=[3.5 3.  3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1]\n",
    "b=[3.1 3.7 3.4 3.  3.  4.  4.4 3.9 3.5 3.8 3.8]\n",
    "c=[3.2 3.2 3.1 2.3 2.8 2.8 3.3 2.4 2.9 2.7 2.  3.  2.2 2.9 2.9 3.1 3.  2.7\n",
    " 2.2 2.5 3.2 2.8 2.5 2.8 2.9 3.  2.8 3.  2.9 2.6 2.4 2.4 2.7 2.7 3.  3.4\n",
    " 3.1 2.3 3.  2.5 2.6 3.  2.6 2.3 2.7 3.  2.9 2.9 2.5 2.8 3.3 2.7 3.  2.9\n",
    " 3.  3.  2.5 2.9 2.5 3.6 3.2 2.7 3.  2.5 2.8 3.2 3.  3.8 2.6 2.2 3.2 2.8\n",
    " 2.8 2.7 3.3 3.2 2.8 3.  2.8 3.  2.8 3.8 2.8 2.8 2.6 3.  3.4 3.1 3.  3.1\n",
    " 3.1 3.1 2.7 3.2 3.3 3.  2.5 3.  3.4 3. ]\n",
    "d=[3.  2.5 3.  3.4 3. ]\n",
    "e=[3.5 3.1 3.4 3.1 3.  4.4 3.8 3.7 3.4 3.5 3.1 4.2 3.5 3.4 3.2 3.  3.7 3.2\n",
    " 2.8 2.4 2.  2.9 3.  2.5 2.5 3.  2.9 2.4 3.  2.3 2.6 2.3 2.9 2.8 3.  3.\n",
    " 2.5 2.7 2.8 3.8 3.2 2.7 2.8 3.  2.8 3.  3.  3.1 3.3 3. ]\n",
    "f=[3.6 3.1 4.  3.8 3.4 3.2 3.1 3.4 3.8 3.3 2.8 2.7 2.9 2.5 2.9 2.6 3.  2.5\n",
    " 2.7 2.8]\n",
    "g1=[[5.1 3.5 1.4 0.2]\n",
    " [4.9 3.  1.4 0.2]\n",
    " [4.7 3.2 1.3 0.2]\n",
    " [4.6 3.1 1.5 0.2]\n",
    " [5.  3.6 1.4 0.2]\n",
    " [5.4 3.9 1.7 0.4]\n",
    " [4.6 3.4 1.4 0.3]\n",
    " [5.  3.4 1.5 0.2]\n",
    " [4.4 2.9 1.4 0.2]\n",
    " [4.9 3.1 1.5 0.1]]\n",
    "g2=[[5.1 3.5 1.4 0.2]\n",
    " [4.9 3.  1.4 0.2]\n",
    " [4.7 3.2 1.3 0.2]\n",
    " [4.6 3.1 1.5 0.2]\n",
    " [5.  3.6 1.4 0.2]\n",
    " [5.4 3.9 1.7 0.4]\n",
    " [4.6 3.4 1.4 0.3]\n",
    " [5.  3.4 1.5 0.2]\n",
    " [4.4 2.9 1.4 0.2]\n",
    " [4.9 3.1 1.5 0.1]]\n",
    "h=[[1.5 0.2]\n",
    " [1.6 0.2]\n",
    " [1.4 0.1]\n",
    " [1.1 0.1]\n",
    " [1.2 0.2]\n",
    " [1.5 0.4]\n",
    " [1.3 0.4]\n",
    " [1.4 0.3]\n",
    " [1.7 0.3]\n",
    " [1.5 0.3]]\n",
    "i=[3.5 3.2 3.6 3.4 2.9 3.7 3.  4.  3.9 3.8 3.4 3.6 3.4 3.4 3.4 3.1 4.1 3.1\n",
    " 3.5 3.  3.5 3.2 3.8 3.8 3.7 3.2 3.1 2.8 3.3 2.9 2.  2.2 2.9 3.  2.2 3.2\n",
    " 2.5 2.9 2.8 2.9 2.4 2.7 3.  3.1 3.  2.6 2.6 2.7 2.9 2.5 3.3 3.  3.  2.5\n",
    " 2.5 3.2 3.  2.8 3.  2.6 3.2 2.8 3.3 2.8 2.8 2.8 2.8 2.6 3.4 3.  3.1 2.7\n",
    " 3.3 2.5 3.4]\n",
    "c[0,0]=1.0, a[0,0]=5.1\n",
    "l. The shape of array l is (100, 6)\n",
    "```\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T08:27:25.073485700Z",
     "start_time": "2024-08-20T08:27:25.049331100Z"
    },
    "id": "c0bb63c59f6b93",
    "outputId": "8db65784-acb8-4a97-d760-a9b2fc9b000f"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=[3.5 3.  3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1]\n",
      "b=[3.1 3.7 3.4 3.  3.  4.  4.4 3.9 3.5 3.8 3.8]\n",
      "c=[3.2 3.2 3.1 2.3 2.8 2.8 3.3 2.4 2.9 2.7 2.  3.  2.2 2.9 2.9 3.1 3.  2.7\n",
      " 2.2 2.5 3.2 2.8 2.5 2.8 2.9 3.  2.8 3.  2.9 2.6 2.4 2.4 2.7 2.7 3.  3.4\n",
      " 3.1 2.3 3.  2.5 2.6 3.  2.6 2.3 2.7 3.  2.9 2.9 2.5 2.8 3.3 2.7 3.  2.9\n",
      " 3.  3.  2.5 2.9 2.5 3.6 3.2 2.7 3.  2.5 2.8 3.2 3.  3.8 2.6 2.2 3.2 2.8\n",
      " 2.8 2.7 3.3 3.2 2.8 3.  2.8 3.  2.8 3.8 2.8 2.8 2.6 3.  3.4 3.1 3.  3.1\n",
      " 3.1 3.1 2.7 3.2 3.3 3.  2.5 3.  3.4 3. ]\n",
      "d=[3.  2.5 3.  3.4 3. ]\n",
      "e=[3.5 3.1 3.4 3.1 3.  4.4 3.8 3.7 3.4 3.5 3.1 4.2 3.5 3.4 3.2 3.  3.7 3.2\n",
      " 2.8 2.4 2.  2.9 3.  2.5 2.5 3.  2.9 2.4 3.  2.3 2.6 2.3 2.9 2.8 3.  3.\n",
      " 2.5 2.7 2.8 3.8 3.2 2.7 2.8 3.  2.8 3.  3.  3.1 3.3 3. ]\n",
      "f=[3.6 3.1 4.  3.8 3.4 3.2 3.1 3.4 3.8 3.3 2.8 2.7 2.9 2.5 2.9 2.6 3.  2.5\n",
      " 2.7 2.8]\n",
      "g1=[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]]\n",
      "g2=[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]]\n",
      "h=[[1.5 0.2]\n",
      " [1.6 0.2]\n",
      " [1.4 0.1]\n",
      " [1.1 0.1]\n",
      " [1.2 0.2]\n",
      " [1.5 0.4]\n",
      " [1.3 0.4]\n",
      " [1.4 0.3]\n",
      " [1.7 0.3]\n",
      " [1.5 0.3]]\n",
      "i=[3.5 3.2 3.6 3.4 2.9 3.7 3.  4.  3.9 3.8 3.4 3.6 3.4 3.4 3.4 3.1 4.1 3.1\n",
      " 3.5 3.  3.5 3.2 3.8 3.8 3.7 3.2 3.1 2.8 3.3 2.9 2.  2.2 2.9 3.  2.2 3.2\n",
      " 2.5 2.9 2.8 2.9 2.4 2.7 3.  3.1 3.  2.6 2.6 2.7 2.9 2.5 3.3 3.  3.  2.5\n",
      " 2.5 3.2 3.  2.8 3.  2.6 3.2 2.8 3.3 2.8 2.8 2.8 2.8 2.6 3.4 3.  3.1 2.7\n",
      " 3.3 2.5 3.4]\n",
      "c[0,0]=1.0, a[0,0]=5.1\n",
      "The shape of array d is (100, 6)\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "print(f'a={b[0:10]}') #Elements with index 0 to 9 (excluding the element with index 10)\n",
    "print(f'b={b[9:20]}') #Elements with index 9 to 18\n",
    "print(f'c={b[50:]}') #AFter 50th element = starting from index 50\n",
    "print(f'd={b[-5:]}')\n",
    "print(f'e={b[::3]}')\n",
    "print(f'f={b[4:100:5]}') #The first 5th element has index. We take steps of 5 from there and we stop before index 100 (which is the 101th element)\n",
    "print(f'g1={a[0:10,:]}')  #or shorter\n",
    "print(f'g2={a[0:10]}')\n",
    "print(f'h={a[10:20,-2:]}')\n",
    "print(f'i={a[::2,1]}')\n",
    "#j\n",
    "j= a[:20,0:2].copy()\n",
    "#k\n",
    "j[0,0]=1\n",
    "print(f'c[0,0]={j[0,0]}, a[0,0]={a[0,0]}')\n",
    "#l\n",
    "l = a.reshape((100,6))\n",
    "print(f\"The shape of array d is {l.shape}\")\n",
    "#m\n",
    "#SOLUTION_START"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Concatenation\n",
    "a. Create a new array ca that concatenates the second column of array a with array b\n",
    "b. Create a new array cb that concatenates the first 10 and last then rows of array a\n",
    "\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T08:46:36.212214300Z",
     "start_time": "2024-08-20T08:46:36.172108200Z"
    },
    "id": "6e20f37efcefc3c2",
    "outputId": "07b4c1d0-e880-48fe-8eda-bd47538ed2a9"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "dtype('float64')"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "dtype('float64')"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "a.dtype\n",
    "b.dtype\n",
    "ca = np.concatenate([a[:,0], b])\n",
    "cb = np.concatenate([a[0:10], a[-10:]])\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<!--BOOK_INFORMATION-->\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"figures/PDSH-cover-small.png\">\n",
    "\n",
    "*This notebook contains an excerpt from the [Python Data Science Handbook](http://shop.oreilly.com/product/0636920034919.do) by Jake VanderPlas; the content is available [on GitHub](https://github.com/jakevdp/PythonDataScienceHandbook).*\n",
    "\n",
    "*The text is released under the [CC-BY-NC-ND license](https://creativecommons.org/licenses/by-nc-nd/3.0/us/legalcode), and code is released under the [MIT license](https://opensource.org/licenses/MIT). If you find this content useful, please consider supporting the work by [buying the book](http://shop.oreilly.com/product/0636920034919.do)!*"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<!--NAVIGATION-->\n",
    "< [The Basics of NumPy Arrays](02.02-The-Basics-Of-NumPy-Arrays.ipynb) | [Contents](Index.ipynb) | [Aggregations: Min, Max, and Everything In Between](02.04-Computation-on-arrays-aggregates.ipynb) >\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/02.03-Computation-on-arrays-ufuncs.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Computation on NumPy Arrays: Universal Functions"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Up until now, we have been discussing some of the basic nuts and bolts of NumPy; in the next few sections, we will dive into the reasons that NumPy is so important in the Python data science world.\n",
    "Namely, it provides an easy and flexible interface to optimized computation with arrays of data.\n",
    "\n",
    "Computation on NumPy arrays can be very fast, or it can be very slow.\n",
    "The key to making it fast is to use *vectorized* operations, generally implemented through NumPy's *universal functions* (ufuncs).\n",
    "This section motivates the need for NumPy's ufuncs, which can be used to make repeated calculations on array elements much more efficient.\n",
    "It then introduces many of the most common and useful arithmetic ufuncs available in the NumPy package."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## The Slowness of Loops\n",
    "\n",
    "Python's default implementation (known as CPython) does some operations very slowly.\n",
    "This is in part due to the dynamic, interpreted nature of the language: the fact that types are flexible, so that sequences of operations cannot be compiled down to efficient machine code as in languages like C and Fortran.\n",
    "Recently there have been various attempts to address this weakness: well-known examples are the [PyPy](http://pypy.org/) project, a just-in-time compiled implementation of Python; the [Cython](http://cython.org) project, which converts Python code to compilable C code; and the [Numba](http://numba.pydata.org/) project, which converts snippets of Python code to fast LLVM bytecode.\n",
    "Each of these has its strengths and weaknesses, but it is safe to say that none of the three approaches has yet surpassed the reach and popularity of the standard CPython engine.\n",
    "\n",
    "The relative sluggishness of Python generally manifests itself in situations where many small operations are being repeated – for instance looping over arrays to operate on each element.\n",
    "For example, imagine we have an array of values and we'd like to compute the reciprocal of each.\n",
    "A straightforward approach might look like this:"
   ]
  },
  {
   "metadata": {
    "id": "sOMB7K5LhxPk",
    "outputId": "d0bbfa99-242f-4bbe-a3fd-cef9af2fe317"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.16666667,  1.        ,  0.25      ,  0.25      ,  0.125     ])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "def compute_reciprocals(values):\n",
    "    output = np.empty(len(values))\n",
    "    for i in range(len(values)):\n",
    "        output[i] = 1.0 / values[i]\n",
    "    return output\n",
    "\n",
    "values = np.random.randint(1, 10, size=5)\n",
    "compute_reciprocals(values)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This implementation probably feels fairly natural to someone from, say, a C or Java background.\n",
    "But if we measure the execution time of this code for a large input, we see that this operation is very slow, perhaps surprisingly so!\n",
    "We'll benchmark this with IPython's ``%timeit`` magic (discussed in [Profiling and Timing Code](01.07-Timing-and-Profiling.ipynb)):"
   ]
  },
  {
   "metadata": {
    "id": "Z-Jl0CiqhxPo",
    "outputId": "64be925a-d0ae-4fdf-ef9e-9964fefebab0"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 2.91 s per loop\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "big_array = np.random.randint(1, 100, size=1000000)\n",
    "%timeit compute_reciprocals(big_array)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "It takes several seconds to compute these million operations and to store the result!\n",
    "When even cell phones have processing speeds measured in Giga-FLOPS (i.e., billions of numerical operations per second), this seems almost absurdly slow.\n",
    "It turns out that the bottleneck here is not the operations themselves, but the type-checking and function dispatches that CPython must do at each cycle of the loop.\n",
    "Each time the reciprocal is computed, Python first examines the object's type and does a dynamic lookup of the correct function to use for that type.\n",
    "If we were working in compiled code instead, this type specification would be known before the code executes and the result could be computed much more efficiently."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Introducing UFuncs\n",
    "\n",
    "For many types of operations, NumPy provides a convenient interface into just this kind of statically typed, compiled routine. This is known as a *vectorized* operation.\n",
    "This can be accomplished by simply performing an operation on the array, which will then be applied to each element.\n",
    "This vectorized approach is designed to push the loop into the compiled layer that underlies NumPy, leading to much faster execution.\n",
    "\n",
    "Compare the results of the following two:"
   ]
  },
  {
   "metadata": {
    "id": "zBAFNiRThxPp",
    "outputId": "0967c9ac-352a-4f0f-8bb8-392bc3b21280"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.16666667  1.          0.25        0.25        0.125     ]\n",
      "[ 0.16666667  1.          0.25        0.25        0.125     ]\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "print(compute_reciprocals(values))\n",
    "print(1.0 / values)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Looking at the execution time for our big array, we see that it completes orders of magnitude faster than the Python loop:"
  },
  {
   "metadata": {
    "id": "vLLrG1tYhxPq",
    "outputId": "22505222-911e-4074-c019-e503bdc9b982"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 4.6 ms per loop\n"
     ]
    }
   ],
   "execution_count": null,
   "source": "%timeit (1.0 / big_array)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Vectorized operations in NumPy are implemented via *ufuncs*, whose main purpose is to quickly execute repeated operations on values in NumPy arrays.\n",
    "Ufuncs are extremely flexible – before we saw an operation between a scalar and an array, but we can also operate between two arrays:"
   ]
  },
  {
   "metadata": {
    "id": "BUirh6nXhxPq",
    "outputId": "2d93cd53-1f02-4760-be8d-7dafc3f562dd"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.5       ,  0.66666667,  0.75      ,  0.8       ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "np.arange(5) / np.arange(1, 6)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "And ufunc operations are not limited to one-dimensional arrays–they can also act on multi-dimensional arrays as well:"
  },
  {
   "metadata": {
    "id": "OhrC8b3mhxPr",
    "outputId": "6efe7532-9191-4f04-ea26-a55832fd653a"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1,   2,   4],\n",
       "       [  8,  16,  32],\n",
       "       [ 64, 128, 256]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "x = np.arange(9).reshape((3, 3))\n",
    "2 ** x"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Computations using vectorization through ufuncs are nearly always more efficient than their counterpart implemented using Python loops, especially as the arrays grow in size.\n",
    "Any time you see such a loop in a Python script, you should consider whether it can be replaced with a vectorized expression."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Exploring NumPy's UFuncs\n",
    "\n",
    "Ufuncs exist in two flavors: *unary ufuncs*, which operate on a single input, and *binary ufuncs*, which operate on two inputs.\n",
    "We'll see examples of both these types of functions here."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Array arithmetic\n",
    "\n",
    "NumPy's ufuncs feel very natural to use because they make use of Python's native arithmetic operators.\n",
    "The standard addition, subtraction, multiplication, and division can all be used:"
   ]
  },
  {
   "metadata": {
    "id": "zBNqyhtqhxPr",
    "outputId": "e320aeee-f8d8-4ff0-bca3-5e875d3ab86e"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x     = [0 1 2 3]\n",
      "x + 5 = [5 6 7 8]\n",
      "x - 5 = [-5 -4 -3 -2]\n",
      "x * 2 = [0 2 4 6]\n",
      "x / 2 = [ 0.   0.5  1.   1.5]\n",
      "x // 2 = [0 0 1 1]\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "x = np.arange(4)\n",
    "print(\"x     =\", x)\n",
    "print(\"x + 5 =\", x + 5)\n",
    "print(\"x - 5 =\", x - 5)\n",
    "print(\"x * 2 =\", x * 2)\n",
    "print(\"x / 2 =\", x / 2)\n",
    "print(\"x // 2 =\", x // 2)  # floor division"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "There is also a unary ufunc for negation, and a ``**`` operator for exponentiation, and a ``%`` operator for modulus:"
  },
  {
   "metadata": {
    "id": "Jj2WDcQphxPs",
    "outputId": "fdb19d75-c531-485d-fa10-5cfaac8d91ab"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-x     =  [ 0 -1 -2 -3]\n",
      "x ** 2 =  [0 1 4 9]\n",
      "x % 2  =  [0 1 0 1]\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "print(\"-x     = \", -x)\n",
    "print(\"x ** 2 = \", x ** 2)\n",
    "print(\"x % 2  = \", x % 2)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In addition, these can be strung together however you wish, and the standard order of operations is respected:"
  },
  {
   "metadata": {
    "id": "6foHW-BdhxPt",
    "outputId": "90ccbe36-91a6-4d21-ea9e-bd00c885b8a1"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.  , -2.25, -4.  , -6.25])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "-(0.5*x + 1) ** 2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Each of these arithmetic operations are simply convenient wrappers around specific functions built into NumPy; for example, the ``+`` operator is a wrapper for the ``add`` function:"
  },
  {
   "metadata": {
    "id": "wCNt88hmhxPu",
    "outputId": "6ee37c91-cb9f-4305-adb3-ba245ebb51ba"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 4, 5])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "np.add(x, 2)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The following table lists the arithmetic operators implemented in NumPy:\n",
    "\n",
    "| Operator\t    | Equivalent ufunc    | Description                           |\n",
    "|---------------|---------------------|---------------------------------------|\n",
    "|``+``          |``np.add``           |Addition (e.g., ``1 + 1 = 2``)         |\n",
    "|``-``          |``np.subtract``      |Subtraction (e.g., ``3 - 2 = 1``)      |\n",
    "|``-``          |``np.negative``      |Unary negation (e.g., ``-2``)          |\n",
    "|``*``          |``np.multiply``      |Multiplication (e.g., ``2 * 3 = 6``)   |\n",
    "|``/``          |``np.divide``        |Division (e.g., ``3 / 2 = 1.5``)       |\n",
    "|``//``         |``np.floor_divide``  |Floor division (e.g., ``3 // 2 = 1``)  |\n",
    "|``**``         |``np.power``         |Exponentiation (e.g., ``2 ** 3 = 8``)  |\n",
    "|``%``          |``np.mod``           |Modulus/remainder (e.g., ``9 % 4 = 1``)|\n",
    "\n",
    "Additionally there are Boolean/bitwise operators; we will explore these in [Comparisons, Masks, and Boolean Logic](02.06-Boolean-Arrays-and-Masks.ipynb)."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Absolute value\n",
    "\n",
    "Just as NumPy understands Python's built-in arithmetic operators, it also understands Python's built-in absolute value function:"
   ]
  },
  {
   "metadata": {
    "id": "MTe-_BQAhxPu",
    "outputId": "9135cff2-39e1-46bd-ec7b-416f262c92ea"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 1, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "x = np.array([-2, -1, 0, 1, 2])\n",
    "abs(x)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The corresponding NumPy ufunc is ``np.absolute``, which is also available under the alias ``np.abs``:"
  },
  {
   "metadata": {
    "id": "g6y8uofthxPv",
    "outputId": "3beb99e3-1f48-455d-9326-1269a6072b2c"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 1, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "np.absolute(x)"
  },
  {
   "metadata": {
    "id": "jwZky3M8hxPv",
    "outputId": "53fbdd21-9ffa-46d2-a83f-5e26af74cf35"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 1, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "np.abs(x)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This ufunc can also handle complex data, in which the absolute value returns the magnitude:"
  },
  {
   "metadata": {
    "id": "CFf3_OxRhxPw",
    "outputId": "8f0094ac-9edc-44cf-8c57-a43a9ad83d63"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.,  5.,  2.,  1.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "x = np.array([3 - 4j, 4 - 3j, 2 + 0j, 0 + 1j])\n",
    "np.abs(x)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Trigonometric functions\n",
    "<div style=\"border: 2px solid red; padding: 10px; border-radius: 5px; background-color: #f8d7da; color: #721c24;\">\n",
    "<strong>!</strong> Trigonometric functions are not part of the course and deleted in this notebook.</div>"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Exponents and logarithms\n",
    "\n",
    "Another common type of operation available in a NumPy ufunc are the exponentials:"
   ]
  },
  {
   "metadata": {
    "id": "fyjzQ8tWhxPy",
    "outputId": "fed9262f-e436-4bab-a124-56fabcb3701f"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x     = [1, 2, 3]\n",
      "e^x   = [  2.71828183   7.3890561   20.08553692]\n",
      "2^x   = [ 2.  4.  8.]\n",
      "3^x   = [ 3  9 27]\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "x = [1, 2, 3]\n",
    "print(\"x     =\", x)\n",
    "print(\"e^x   =\", np.exp(x))\n",
    "print(\"2^x   =\", np.exp2(x))\n",
    "print(\"3^x   =\", np.power(3, x))"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The inverse of the exponentials, the logarithms, are also available.\n",
    "The basic ``np.log`` gives the natural logarithm; if you prefer to compute the base-2 logarithm or the base-10 logarithm, these are available as well:"
   ]
  },
  {
   "metadata": {
    "id": "T7bdZoSshxPy",
    "outputId": "4711b1b3-a240-4d2e-94d4-6bc76945ecf4"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x        = [1, 2, 4, 10]\n",
      "ln(x)    = [ 0.          0.69314718  1.38629436  2.30258509]\n",
      "log2(x)  = [ 0.          1.          2.          3.32192809]\n",
      "log10(x) = [ 0.          0.30103     0.60205999  1.        ]\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "x = [1, 2, 4, 10]\n",
    "print(\"x        =\", x)\n",
    "print(\"ln(x)    =\", np.log(x))\n",
    "print(\"log2(x)  =\", np.log2(x))\n",
    "print(\"log10(x) =\", np.log10(x))"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "There are also some specialized versions that are useful for maintaining precision with very small input:"
  },
  {
   "metadata": {
    "id": "aV8cWfAOhxPz",
    "outputId": "e03cb4d1-0f15-4f48-af28-095aa1ced861"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp(x) - 1 = [ 0.          0.0010005   0.01005017  0.10517092]\n",
      "log(1 + x) = [ 0.          0.0009995   0.00995033  0.09531018]\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "x = [0, 0.001, 0.01, 0.1]\n",
    "print(\"exp(x) - 1 =\", np.expm1(x))\n",
    "print(\"log(1 + x) =\", np.log1p(x))"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "When ``x`` is very small, these functions give more precise values than if the raw ``np.log`` or ``np.exp`` were to be used."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Specialized ufuncs\n",
    "<div style=\"border: 2px solid red; padding: 10px; border-radius: 5px; background-color: #f8d7da; color: #721c24;\">\n",
    "<strong>!</strong> Specialized ufuncts are not part of the course and deleted in this notebook.</div>\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Advanced Ufunc Features\n",
    "<div style=\"border: 2px solid red; padding: 10px; border-radius: 5px; background-color: #f8d7da; color: #721c24;\">\n",
    "<strong>!</strong> Advanced ufunc Features are not part of the course and deleted in this notebook.</div>\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<!--NAVIGATION-->\n",
    "< [The Basics of NumPy Arrays](02.02-The-Basics-Of-NumPy-Arrays.ipynb) | [Contents](Index.ipynb) | [Aggregations: Min, Max, and Everything In Between](02.04-Computation-on-arrays-aggregates.ipynb) >\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/02.03-Computation-on-arrays-ufuncs.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T12:23:18.995982Z",
     "start_time": "2025-01-24T12:23:18.982976Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "id": "initial_id"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import sklearn.datasets as ds\n",
    "import numpy as np\n",
    "large_array, _ = ds.make_gaussian_quantiles(n_samples=10000, n_features=1, random_state=42)\n",
    "large_array= large_array.reshape((10000,))\n",
    "a = np.array(ds.load_iris().data)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Efficiency of numpy operations\n",
    "large_array is generated with dummy data. You do not have to understand how it's done.\n",
    "\n",
    "a. Check the dtype and shape of `large_array`"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T12:23:19.044968Z",
     "start_time": "2025-01-24T12:23:19.031831Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "id": "fcc8a3e835c29d34",
    "outputId": "8eae3891-f550-4171-87c2-e89d35f1bfc1"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of large_array is (10000,) and its dtype is float64\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "print(f'The shape of large_array is {large_array.shape} and its dtype is {large_array.dtype}')\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "b. Create a for-loop in which you calculate the power of 2 for each element. `%%timeit` is  placed at the beginning of the cell. By doing this, Jupiter will do several runs and measure the speed of the operation. The result is shown below the cell. Run the cell and wait for the result. Look how long running the for-loop takes."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T12:23:20.725876Z",
     "start_time": "2025-01-24T12:23:19.229767Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "id": "1a3d1ecaa69acfe0",
    "outputId": "78fd2cd1-3290-47e2-9136-0d16e0b3f25e"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.76 ms ± 106 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "%%timeit\n",
    "#SOLUTION_START\n",
    "for e in large_array:\n",
    "    e**2\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "c. In the cell below, do the same with the Ufuncs functionality instead of a for-loop. Use %%timeit again. Compare the duration. How big is the difference?"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T12:23:24.171399Z",
     "start_time": "2025-01-24T12:23:20.734391Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "id": "2fcaa1e7c1ebdc52",
    "outputId": "06f55c17-15d8-422d-e10d-d5426478652e"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.27 μs ± 600 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "%%timeit\n",
    "#SOLUTION_START\n",
    "large_array**2\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div style=\"border: 2px solid red; padding: 10px; border-radius: 5px; background-color: #f8d7da; color: #721c24;\">\n",
    "<strong>! </strong>As you can see for yourself there is a big difference.\n",
    "From now on, where possible, you have to use UFuncs instead of for-loops. The code is more lean and will be excecuted more efficiently. During evaluations for-loops will influence your score negatively and are even not allowed in most cases..</div>\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Using UFuncs\n",
    "Us UFuncs to perform the following operations on array a.\\\n",
    "a. From array a, calculate the square root of each element.\\\n",
    "b. From array a, round the first column to the nearest integer.\\\n",
    "c. From array a, add 1 to every value of the first row.\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T12:23:24.250661Z",
     "start_time": "2025-01-24T12:23:24.238960Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "id": "3e4c1bb4c1aa1a4b",
    "outputId": "756fe601-df9a-4aa4-82ad-d9a3043e4d73"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a. The square root of each element in a is [[2.25831796 1.87082869 1.18321596 0.4472136 ]\n",
      " [2.21359436 1.73205081 1.18321596 0.4472136 ]\n",
      " [2.16794834 1.78885438 1.14017543 0.4472136 ]\n",
      " [2.14476106 1.76068169 1.22474487 0.4472136 ]\n",
      " [2.23606798 1.8973666  1.18321596 0.4472136 ]\n",
      " [2.32379001 1.97484177 1.30384048 0.63245553]\n",
      " [2.14476106 1.84390889 1.18321596 0.54772256]\n",
      " [2.23606798 1.84390889 1.22474487 0.4472136 ]\n",
      " [2.0976177  1.70293864 1.18321596 0.4472136 ]\n",
      " [2.21359436 1.76068169 1.22474487 0.31622777]\n",
      " [2.32379001 1.92353841 1.22474487 0.4472136 ]\n",
      " [2.19089023 1.84390889 1.26491106 0.4472136 ]\n",
      " [2.19089023 1.73205081 1.18321596 0.31622777]\n",
      " [2.07364414 1.73205081 1.04880885 0.31622777]\n",
      " [2.40831892 2.         1.09544512 0.4472136 ]\n",
      " [2.38746728 2.0976177  1.22474487 0.63245553]\n",
      " [2.32379001 1.97484177 1.14017543 0.63245553]\n",
      " [2.25831796 1.87082869 1.18321596 0.54772256]\n",
      " [2.38746728 1.94935887 1.30384048 0.54772256]\n",
      " [2.25831796 1.94935887 1.22474487 0.54772256]\n",
      " [2.32379001 1.84390889 1.30384048 0.4472136 ]\n",
      " [2.25831796 1.92353841 1.22474487 0.63245553]\n",
      " [2.14476106 1.8973666  1.         0.4472136 ]\n",
      " [2.25831796 1.81659021 1.30384048 0.70710678]\n",
      " [2.19089023 1.84390889 1.37840488 0.4472136 ]\n",
      " [2.23606798 1.73205081 1.26491106 0.4472136 ]\n",
      " [2.23606798 1.84390889 1.26491106 0.63245553]\n",
      " [2.28035085 1.87082869 1.22474487 0.4472136 ]\n",
      " [2.28035085 1.84390889 1.18321596 0.4472136 ]\n",
      " [2.16794834 1.78885438 1.26491106 0.4472136 ]\n",
      " [2.19089023 1.76068169 1.26491106 0.4472136 ]\n",
      " [2.32379001 1.84390889 1.22474487 0.63245553]\n",
      " [2.28035085 2.02484567 1.22474487 0.31622777]\n",
      " [2.34520788 2.04939015 1.18321596 0.4472136 ]\n",
      " [2.21359436 1.76068169 1.22474487 0.4472136 ]\n",
      " [2.23606798 1.78885438 1.09544512 0.4472136 ]\n",
      " [2.34520788 1.87082869 1.14017543 0.4472136 ]\n",
      " [2.21359436 1.8973666  1.18321596 0.31622777]\n",
      " [2.0976177  1.73205081 1.14017543 0.4472136 ]\n",
      " [2.25831796 1.84390889 1.22474487 0.4472136 ]\n",
      " [2.23606798 1.87082869 1.14017543 0.54772256]\n",
      " [2.12132034 1.51657509 1.14017543 0.54772256]\n",
      " [2.0976177  1.78885438 1.14017543 0.4472136 ]\n",
      " [2.23606798 1.87082869 1.26491106 0.77459667]\n",
      " [2.25831796 1.94935887 1.37840488 0.63245553]\n",
      " [2.19089023 1.73205081 1.18321596 0.54772256]\n",
      " [2.25831796 1.94935887 1.26491106 0.4472136 ]\n",
      " [2.14476106 1.78885438 1.18321596 0.4472136 ]\n",
      " [2.30217289 1.92353841 1.22474487 0.4472136 ]\n",
      " [2.23606798 1.81659021 1.18321596 0.4472136 ]\n",
      " [2.64575131 1.78885438 2.16794834 1.18321596]\n",
      " [2.52982213 1.78885438 2.12132034 1.22474487]\n",
      " [2.62678511 1.76068169 2.21359436 1.22474487]\n",
      " [2.34520788 1.51657509 2.         1.14017543]\n",
      " [2.54950976 1.67332005 2.14476106 1.22474487]\n",
      " [2.38746728 1.67332005 2.12132034 1.14017543]\n",
      " [2.50998008 1.81659021 2.16794834 1.26491106]\n",
      " [2.21359436 1.54919334 1.81659021 1.        ]\n",
      " [2.56904652 1.70293864 2.14476106 1.14017543]\n",
      " [2.28035085 1.64316767 1.97484177 1.18321596]\n",
      " [2.23606798 1.41421356 1.87082869 1.        ]\n",
      " [2.42899156 1.73205081 2.04939015 1.22474487]\n",
      " [2.44948974 1.4832397  2.         1.        ]\n",
      " [2.46981781 1.70293864 2.16794834 1.18321596]\n",
      " [2.36643191 1.70293864 1.8973666  1.14017543]\n",
      " [2.58843582 1.76068169 2.0976177  1.18321596]\n",
      " [2.36643191 1.73205081 2.12132034 1.22474487]\n",
      " [2.40831892 1.64316767 2.02484567 1.        ]\n",
      " [2.48997992 1.4832397  2.12132034 1.22474487]\n",
      " [2.36643191 1.58113883 1.97484177 1.04880885]\n",
      " [2.42899156 1.78885438 2.19089023 1.34164079]\n",
      " [2.46981781 1.67332005 2.         1.14017543]\n",
      " [2.50998008 1.58113883 2.21359436 1.22474487]\n",
      " [2.46981781 1.67332005 2.16794834 1.09544512]\n",
      " [2.52982213 1.70293864 2.07364414 1.14017543]\n",
      " [2.56904652 1.73205081 2.0976177  1.18321596]\n",
      " [2.60768096 1.67332005 2.19089023 1.18321596]\n",
      " [2.58843582 1.73205081 2.23606798 1.30384048]\n",
      " [2.44948974 1.70293864 2.12132034 1.22474487]\n",
      " [2.38746728 1.61245155 1.87082869 1.        ]\n",
      " [2.34520788 1.54919334 1.94935887 1.04880885]\n",
      " [2.34520788 1.54919334 1.92353841 1.        ]\n",
      " [2.40831892 1.64316767 1.97484177 1.09544512]\n",
      " [2.44948974 1.64316767 2.25831796 1.26491106]\n",
      " [2.32379001 1.73205081 2.12132034 1.22474487]\n",
      " [2.44948974 1.84390889 2.12132034 1.26491106]\n",
      " [2.58843582 1.76068169 2.16794834 1.22474487]\n",
      " [2.50998008 1.51657509 2.0976177  1.14017543]\n",
      " [2.36643191 1.73205081 2.02484567 1.14017543]\n",
      " [2.34520788 1.58113883 2.         1.14017543]\n",
      " [2.34520788 1.61245155 2.0976177  1.09544512]\n",
      " [2.46981781 1.73205081 2.14476106 1.18321596]\n",
      " [2.40831892 1.61245155 2.         1.09544512]\n",
      " [2.23606798 1.51657509 1.81659021 1.        ]\n",
      " [2.36643191 1.64316767 2.04939015 1.14017543]\n",
      " [2.38746728 1.73205081 2.04939015 1.09544512]\n",
      " [2.38746728 1.70293864 2.04939015 1.14017543]\n",
      " [2.48997992 1.70293864 2.07364414 1.14017543]\n",
      " [2.25831796 1.58113883 1.73205081 1.04880885]\n",
      " [2.38746728 1.67332005 2.02484567 1.14017543]\n",
      " [2.50998008 1.81659021 2.44948974 1.58113883]\n",
      " [2.40831892 1.64316767 2.25831796 1.37840488]\n",
      " [2.66458252 1.73205081 2.42899156 1.44913767]\n",
      " [2.50998008 1.70293864 2.36643191 1.34164079]\n",
      " [2.54950976 1.73205081 2.40831892 1.4832397 ]\n",
      " [2.75680975 1.73205081 2.56904652 1.44913767]\n",
      " [2.21359436 1.58113883 2.12132034 1.30384048]\n",
      " [2.70185122 1.70293864 2.50998008 1.34164079]\n",
      " [2.58843582 1.58113883 2.40831892 1.34164079]\n",
      " [2.68328157 1.8973666  2.46981781 1.58113883]\n",
      " [2.54950976 1.78885438 2.25831796 1.41421356]\n",
      " [2.52982213 1.64316767 2.30217289 1.37840488]\n",
      " [2.60768096 1.73205081 2.34520788 1.44913767]\n",
      " [2.38746728 1.58113883 2.23606798 1.41421356]\n",
      " [2.40831892 1.67332005 2.25831796 1.54919334]\n",
      " [2.52982213 1.78885438 2.30217289 1.51657509]\n",
      " [2.54950976 1.73205081 2.34520788 1.34164079]\n",
      " [2.77488739 1.94935887 2.58843582 1.4832397 ]\n",
      " [2.77488739 1.61245155 2.62678511 1.51657509]\n",
      " [2.44948974 1.4832397  2.23606798 1.22474487]\n",
      " [2.62678511 1.78885438 2.38746728 1.51657509]\n",
      " [2.36643191 1.67332005 2.21359436 1.41421356]\n",
      " [2.77488739 1.67332005 2.58843582 1.41421356]\n",
      " [2.50998008 1.64316767 2.21359436 1.34164079]\n",
      " [2.58843582 1.81659021 2.38746728 1.44913767]\n",
      " [2.68328157 1.78885438 2.44948974 1.34164079]\n",
      " [2.48997992 1.67332005 2.19089023 1.34164079]\n",
      " [2.46981781 1.73205081 2.21359436 1.34164079]\n",
      " [2.52982213 1.67332005 2.36643191 1.44913767]\n",
      " [2.68328157 1.73205081 2.40831892 1.26491106]\n",
      " [2.7202941  1.67332005 2.46981781 1.37840488]\n",
      " [2.81069386 1.94935887 2.52982213 1.41421356]\n",
      " [2.52982213 1.67332005 2.36643191 1.4832397 ]\n",
      " [2.50998008 1.67332005 2.25831796 1.22474487]\n",
      " [2.46981781 1.61245155 2.36643191 1.18321596]\n",
      " [2.77488739 1.73205081 2.46981781 1.51657509]\n",
      " [2.50998008 1.84390889 2.36643191 1.54919334]\n",
      " [2.52982213 1.76068169 2.34520788 1.34164079]\n",
      " [2.44948974 1.73205081 2.19089023 1.34164079]\n",
      " [2.62678511 1.76068169 2.32379001 1.44913767]\n",
      " [2.58843582 1.76068169 2.36643191 1.54919334]\n",
      " [2.62678511 1.76068169 2.25831796 1.51657509]\n",
      " [2.40831892 1.64316767 2.25831796 1.37840488]\n",
      " [2.60768096 1.78885438 2.42899156 1.51657509]\n",
      " [2.58843582 1.81659021 2.38746728 1.58113883]\n",
      " [2.58843582 1.73205081 2.28035085 1.51657509]\n",
      " [2.50998008 1.58113883 2.23606798 1.37840488]\n",
      " [2.54950976 1.73205081 2.28035085 1.41421356]\n",
      " [2.48997992 1.84390889 2.32379001 1.51657509]\n",
      " [2.42899156 1.73205081 2.25831796 1.34164079]]\n",
      "b. The first column rounded to the nearest integer is [5. 5. 5. 5. 5. 5. 5. 5. 4. 5. 5. 5. 5. 4. 6. 6. 5. 5. 6. 5. 5. 5. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5. 5. 5. 5. 6. 5. 5. 6. 5. 4. 5. 5. 4. 4. 5. 5. 5. 5. 5.\n",
      " 5. 5. 7. 6. 7. 6. 6. 6. 6. 5. 7. 5. 5. 6. 6. 6. 6. 7. 6. 6. 6. 6. 6. 6.\n",
      " 6. 6. 6. 7. 7. 7. 6. 6. 6. 6. 6. 6. 5. 6. 7. 6. 6. 6. 6. 6. 6. 5. 6. 6.\n",
      " 6. 6. 5. 6. 6. 6. 7. 6. 6. 8. 5. 7. 7. 7. 6. 6. 7. 6. 6. 6. 6. 8. 8. 6.\n",
      " 7. 6. 8. 6. 7. 7. 6. 6. 6. 7. 7. 8. 6. 6. 6. 8. 6. 6. 6. 7. 7. 7. 6. 7.\n",
      " 7. 7. 6. 6. 6. 6.]\n",
      "c. The first row with 1 added to every element is [6.1 4.5 2.4 1.2]\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "print(f'a. The square root of each element in a is {np.sqrt(a)}')\n",
    "print(f'b. The first column rounded to the nearest integer is {np.round(a[:,0])}')\n",
    "print(f'c. The first row with 1 added to every element is {a[0,:]+1}')\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<!--BOOK_INFORMATION-->\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"figures/PDSH-cover-small.png\">\n",
    "\n",
    "*This notebook contains an excerpt from the [Python Data Science Handbook](http://shop.oreilly.com/product/0636920034919.do) by Jake VanderPlas; the content is available [on GitHub](https://github.com/jakevdp/PythonDataScienceHandbook).*\n",
    "\n",
    "*The text is released under the [CC-BY-NC-ND license](https://creativecommons.org/licenses/by-nc-nd/3.0/us/legalcode), and code is released under the [MIT license](https://opensource.org/licenses/MIT). If you find this content useful, please consider supporting the work by [buying the book](http://shop.oreilly.com/product/0636920034919.do)!*"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<!--NAVIGATION-->\n",
    "< [Computation on NumPy Arrays: Universal Functions](02.03-Computation-on-arrays-ufuncs.ipynb) | [Contents](Index.ipynb) | [Computation on Arrays: Broadcasting](02.05-Computation-on-arrays-broadcasting.ipynb) >\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/02.04-Computation-on-arrays-aggregates.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Aggregations: Min, Max, and Everything In Between"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Often when faced with a large amount of data, a first step is to compute summary statistics for the data in question.\n",
    "Perhaps the most common summary statistics are the mean and standard deviation, which allow you to summarize the \"typical\" values in a dataset, but other aggregates are useful as well (the sum, product, median, minimum and maximum, quantiles, etc.).\n",
    "\n",
    "NumPy has fast built-in aggregation functions for working on arrays; we'll discuss and demonstrate some of them here."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Summing the Values in an Array\n",
    "\n",
    "As a quick example, consider computing the sum of all values in an array.\n",
    "Python itself can do this using the built-in ``sum`` function:"
   ]
  },
  {
   "metadata": {
    "id": "nE54I-5As6l3"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "import numpy as np"
  },
  {
   "metadata": {
    "id": "SXav3JHBs6l4",
    "outputId": "a26b96ad-fbef-48fe-903e-8e2a14aed857"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55.61209116604941"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "L = np.random.random(100)\n",
    "sum(L)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The syntax is quite similar to that of NumPy's ``sum`` function, and the result is the same in the simplest case:"
  },
  {
   "metadata": {
    "id": "Bjtuvvbys6l5",
    "outputId": "8ab1cb0c-72a0-4147-9674-09c30935a176"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55.612091166049424"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "np.sum(L)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "However, because it executes the operation in compiled code, NumPy's version of the operation is computed much more quickly:"
  },
  {
   "metadata": {
    "id": "Q3eTniNos6l5",
    "outputId": "12657b30-172c-48dc-cef4-8b830ee33e80"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 104 ms per loop\n",
      "1000 loops, best of 3: 442 µs per loop\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "big_array = np.random.rand(1000000)\n",
    "%timeit sum(big_array)\n",
    "%timeit np.sum(big_array)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Be careful, though: the ``sum`` function and the ``np.sum`` function are not identical, which can sometimes lead to confusion!\n",
    "In particular, their optional arguments have different meanings, and ``np.sum`` is aware of multiple array dimensions, as we will see in the following section."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Minimum and Maximum\n",
    "\n",
    "Similarly, Python has built-in ``min`` and ``max`` functions, used to find the minimum value and maximum value of any given array:"
   ]
  },
  {
   "metadata": {
    "id": "8HK05SUes6l7",
    "outputId": "61213db0-04ae-413e-be88-fefd1014cd82"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.1717128136634614e-06, 0.9999976784968716)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "min(big_array), max(big_array)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "NumPy's corresponding functions have similar syntax, and again operate much more quickly:"
  },
  {
   "metadata": {
    "id": "gtDZxfTBs6l7",
    "outputId": "23075349-9283-445c-c878-668bc9dc6117"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.1717128136634614e-06, 0.9999976784968716)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "np.min(big_array), np.max(big_array)"
  },
  {
   "metadata": {
    "id": "Rf-6Qffls6l7",
    "outputId": "12901870-75c2-4427-eff8-af63f4f74cbc"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 82.3 ms per loop\n",
      "1000 loops, best of 3: 497 µs per loop\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "%timeit min(big_array)\n",
    "%timeit np.min(big_array)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "For ``min``, ``max``, ``sum``, and several other NumPy aggregates, a shorter syntax is to use methods of the array object itself:"
  },
  {
   "metadata": {
    "id": "lyz00avrs6l8",
    "outputId": "df0d04ae-3efa-45c4-9a35-fefe77db4936"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.17171281366e-06 0.999997678497 499911.628197\n"
     ]
    }
   ],
   "execution_count": null,
   "source": "print(big_array.min(), big_array.max(), big_array.sum())"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Whenever possible, make sure that you are using the NumPy version of these aggregates when operating on NumPy arrays!"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Multi dimensional aggregates\n",
    "\n",
    "One common type of aggregation operation is an aggregate along a row or column.\n",
    "Say you have some data stored in a two-dimensional array:"
   ]
  },
  {
   "metadata": {
    "id": "RyIDjvpqs6l9",
    "outputId": "f7b9c606-1ca2-4dff-90e2-c1486de3fa2b"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.8967576   0.03783739  0.75952519  0.06682827]\n",
      " [ 0.8354065   0.99196818  0.19544769  0.43447084]\n",
      " [ 0.66859307  0.15038721  0.37911423  0.6687194 ]]\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "M = np.random.random((3, 4))\n",
    "print(M)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "By default, each NumPy aggregation function will return the aggregate over the entire array:"
  },
  {
   "metadata": {
    "id": "MxDPoPo9s6l-",
    "outputId": "63c0eabc-efb4-4fa6-9cec-2dfa4005797b"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0850555667307118"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "M.sum()"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Aggregation functions take an additional argument specifying the *axis* along which the aggregate is computed. For example, we can find the minimum value within each column by specifying ``axis=0``:"
  },
  {
   "metadata": {
    "id": "RbO7CVOos6l-",
    "outputId": "dd1c687f-c79c-47e9-e0a5-7890f4e000f0"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.66859307,  0.03783739,  0.19544769,  0.06682827])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "M.min(axis=0)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The function returns four values, corresponding to the four columns of numbers.\n",
    "\n",
    "Similarly, we can find the maximum value within each row:"
   ]
  },
  {
   "metadata": {
    "id": "VfoImg2Gs6l-",
    "outputId": "0ccc0bb8-6c3e-4634-bb23-6a611421ce93"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.8967576 ,  0.99196818,  0.6687194 ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "M.max(axis=1)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The way the axis is specified here can be confusing to users coming from other languages.\n",
    "The ``axis`` keyword specifies the *dimension of the array that will be collapsed*, rather than the dimension that will be returned.\n",
    "So specifying ``axis=0`` means that the first axis will be collapsed: for two-dimensional arrays, this means that values within each column will be aggregated."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Other aggregation functions\n",
    "\n",
    "NumPy provides many other aggregation functions, but we won't discuss them in detail here.\n",
    "Additionally, most aggregates have a ``NaN``-safe counterpart that computes the result while ignoring missing values, which are marked by the special IEEE floating-point ``NaN`` value (for a fuller discussion of missing data, see [Handling Missing Data](03.04-Missing-Values.ipynb)).\n",
    "Some of these ``NaN``-safe functions were not added until NumPy 1.8, so they will not be available in older NumPy versions.\n",
    "\n",
    "The following table provides a list of useful aggregation functions available in NumPy:\n",
    "\n",
    "|Function Name      |   NaN-safe Version  | Description                                   |\n",
    "|-------------------|---------------------|-----------------------------------------------|\n",
    "| ``np.sum``        | ``np.nansum``       | Compute sum of elements                       |\n",
    "| ``np.prod``       | ``np.nanprod``      | Compute product of elements                   |\n",
    "| ``np.mean``       | ``np.nanmean``      | Compute mean of elements                      |\n",
    "| ``np.std``        | ``np.nanstd``       | Compute standard deviation                    |\n",
    "| ``np.var``        | ``np.nanvar``       | Compute variance                              |\n",
    "| ``np.min``        | ``np.nanmin``       | Find minimum value                            |\n",
    "| ``np.max``        | ``np.nanmax``       | Find maximum value                            |\n",
    "| ``np.argmin``     | ``np.nanargmin``    | Find index of minimum value                   |\n",
    "| ``np.argmax``     | ``np.nanargmax``    | Find index of maximum value                   |\n",
    "| ``np.median``     | ``np.nanmedian``    | Compute median of elements                    |\n",
    "| ``np.percentile`` | ``np.nanpercentile``| Compute rank-based statistics of elements     |\n",
    "| ``np.any``        | N/A                 | Evaluate whether any elements are true        |\n",
    "| ``np.all``        | N/A                 | Evaluate whether all elements are true        |\n",
    "\n",
    "We will see these aggregates often throughout the rest of the book."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Example: What is the Average Height of US Presidents?"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Aggregates available in NumPy can be extremely useful for summarizing a set of values.\n",
    "As a simple example, let's consider the heights of all US presidents.\n",
    "This data is available in the file *president_heights.csv*, which is a simple comma-separated list of labels and values:"
   ]
  },
  {
   "metadata": {
    "id": "WNgM4oJDs6mA",
    "outputId": "0bbc008d-aa5b-4ab7-8486-529927650a88"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order,name,height(cm)\r\n",
      "1,George Washington,189\r\n",
      "2,John Adams,170\r\n",
      "3,Thomas Jefferson,189\r\n"
     ]
    }
   ],
   "execution_count": null,
   "source": "!head -4 data/president_heights.csv"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We'll use the Pandas package, which we'll explore more fully in [Chapter 3](03.00-Introduction-to-Pandas.ipynb), to read the file and extract this information (note that the heights are measured in centimeters)."
  },
  {
   "metadata": {
    "id": "uRx_0G_fs6mA",
    "outputId": "ffe6c0cd-702f-4d43-93b6-9ec6df4eac4a"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[189 170 189 163 183 171 185 168 173 183 173 173 175 178 183 193 178 173\n",
      " 174 183 183 168 170 178 182 180 183 178 182 188 175 179 183 193 182 183\n",
      " 177 185 188 188 182 185]\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('data/president_heights.csv')\n",
    "heights = np.array(data['height(cm)'])\n",
    "print(heights)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now that we have this data array, we can compute a variety of summary statistics:"
  },
  {
   "metadata": {
    "id": "lHH7BzZ1s6mB",
    "outputId": "e0d349f8-e1cc-4374-80f8-16593eefe46e"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean height:        179.738095238\n",
      "Standard deviation: 6.93184344275\n",
      "Minimum height:     163\n",
      "Maximum height:     193\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "print(\"Mean height:       \", heights.mean())\n",
    "print(\"Standard deviation:\", heights.std())\n",
    "print(\"Minimum height:    \", heights.min())\n",
    "print(\"Maximum height:    \", heights.max())"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Note that in each case, the aggregation operation reduced the entire array to a single summarizing value, which gives us information about the distribution of values.\n",
    "We may also wish to compute quantiles:"
   ]
  },
  {
   "metadata": {
    "id": "JHKWz-Jts6mC",
    "outputId": "ba6998bf-4ccb-4b1c-9c3f-1f1cf4b4aa41"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25th percentile:    174.25\n",
      "Median:             182.0\n",
      "75th percentile:    183.0\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "print(\"25th percentile:   \", np.percentile(heights, 25))\n",
    "print(\"Median:            \", np.median(heights))\n",
    "print(\"75th percentile:   \", np.percentile(heights, 75))"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We see that the median height of US presidents is 182 cm, or just shy of six feet.\n",
    "\n",
    "Of course, sometimes it's more useful to see a visual representation of this data, which we can accomplish using tools in Matplotlib (we'll discuss Matplotlib more fully in [Chapter 4](DS2-4NotebooksWithSolutions.ipynb)). For example, this code generates the following chart:"
   ]
  },
  {
   "metadata": {
    "id": "TdEwiTa1s6mD"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn; seaborn.set()  # set plot style"
   ]
  },
  {
   "metadata": {
    "id": "mn67v85Ls6mD",
    "outputId": "f79c0cfb-81e5-49c2-a359-806ced008a6f"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfYAAAFtCAYAAAD1Skg8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116102f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": null,
   "source": [
    "plt.hist(heights)\n",
    "plt.title('Height Distribution of US Presidents')\n",
    "plt.xlabel('height (cm)')\n",
    "plt.ylabel('number');"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "These aggregates are some of the fundamental pieces of exploratory data analysis that we'll explore in more depth in later chapters of the book."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<!--NAVIGATION-->\n",
    "< [Computation on NumPy Arrays: Universal Functions](02.03-Computation-on-arrays-ufuncs.ipynb) | [Contents](Index.ipynb) | [Computation on Arrays: Broadcasting](02.05-Computation-on-arrays-broadcasting.ipynb) >\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/02.04-Computation-on-arrays-aggregates.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>\n"
   ]
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-27T08:39:10.150073Z",
     "start_time": "2025-01-27T08:39:10.133980Z"
    },
    "id": "initial_id",
    "outputId": "6be043d6-1b85-42d7-ae53-f94c92ad8969"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of large_array is (10000,) and its dtype is float64\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import sklearn.datasets as ds\n",
    "import numpy as np\n",
    "large_array, _ = ds.make_gaussian_quantiles(n_samples=10000, n_features=1, random_state=42)\n",
    "large_array= large_array.reshape((10000,))\n",
    "a = np.array(ds.load_iris().data)\n",
    "print(f\"The shape of large_array is {large_array.shape} and its dtype is {large_array.dtype}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Aggregations\n",
    "large_array is generated with dummy data. You do not have to understand how it's done. You can consult the shape and dtype of large_array in the output above.\\\n",
    "a. Calculate the mean of array a.\\\n",
    "b. Calculate the sum of all the columns in a.\\\n",
    "c. Calculate the product of all the rows in a.\n",
    "\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T12:28:57.337368Z",
     "start_time": "2025-01-24T12:28:57.322256Z"
    },
    "id": "3e4c1bb4c1aa1a4b",
    "outputId": "619e703d-4bf4-4d77-83ba-ad305ec2fbca"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a. The square root of each element in a is [[2.25831796 1.87082869 1.18321596 0.4472136 ]\n",
      " [2.21359436 1.73205081 1.18321596 0.4472136 ]\n",
      " [2.16794834 1.78885438 1.14017543 0.4472136 ]\n",
      " [2.14476106 1.76068169 1.22474487 0.4472136 ]\n",
      " [2.23606798 1.8973666  1.18321596 0.4472136 ]\n",
      " [2.32379001 1.97484177 1.30384048 0.63245553]\n",
      " [2.14476106 1.84390889 1.18321596 0.54772256]\n",
      " [2.23606798 1.84390889 1.22474487 0.4472136 ]\n",
      " [2.0976177  1.70293864 1.18321596 0.4472136 ]\n",
      " [2.21359436 1.76068169 1.22474487 0.31622777]\n",
      " [2.32379001 1.92353841 1.22474487 0.4472136 ]\n",
      " [2.19089023 1.84390889 1.26491106 0.4472136 ]\n",
      " [2.19089023 1.73205081 1.18321596 0.31622777]\n",
      " [2.07364414 1.73205081 1.04880885 0.31622777]\n",
      " [2.40831892 2.         1.09544512 0.4472136 ]\n",
      " [2.38746728 2.0976177  1.22474487 0.63245553]\n",
      " [2.32379001 1.97484177 1.14017543 0.63245553]\n",
      " [2.25831796 1.87082869 1.18321596 0.54772256]\n",
      " [2.38746728 1.94935887 1.30384048 0.54772256]\n",
      " [2.25831796 1.94935887 1.22474487 0.54772256]\n",
      " [2.32379001 1.84390889 1.30384048 0.4472136 ]\n",
      " [2.25831796 1.92353841 1.22474487 0.63245553]\n",
      " [2.14476106 1.8973666  1.         0.4472136 ]\n",
      " [2.25831796 1.81659021 1.30384048 0.70710678]\n",
      " [2.19089023 1.84390889 1.37840488 0.4472136 ]\n",
      " [2.23606798 1.73205081 1.26491106 0.4472136 ]\n",
      " [2.23606798 1.84390889 1.26491106 0.63245553]\n",
      " [2.28035085 1.87082869 1.22474487 0.4472136 ]\n",
      " [2.28035085 1.84390889 1.18321596 0.4472136 ]\n",
      " [2.16794834 1.78885438 1.26491106 0.4472136 ]\n",
      " [2.19089023 1.76068169 1.26491106 0.4472136 ]\n",
      " [2.32379001 1.84390889 1.22474487 0.63245553]\n",
      " [2.28035085 2.02484567 1.22474487 0.31622777]\n",
      " [2.34520788 2.04939015 1.18321596 0.4472136 ]\n",
      " [2.21359436 1.76068169 1.22474487 0.4472136 ]\n",
      " [2.23606798 1.78885438 1.09544512 0.4472136 ]\n",
      " [2.34520788 1.87082869 1.14017543 0.4472136 ]\n",
      " [2.21359436 1.8973666  1.18321596 0.31622777]\n",
      " [2.0976177  1.73205081 1.14017543 0.4472136 ]\n",
      " [2.25831796 1.84390889 1.22474487 0.4472136 ]\n",
      " [2.23606798 1.87082869 1.14017543 0.54772256]\n",
      " [2.12132034 1.51657509 1.14017543 0.54772256]\n",
      " [2.0976177  1.78885438 1.14017543 0.4472136 ]\n",
      " [2.23606798 1.87082869 1.26491106 0.77459667]\n",
      " [2.25831796 1.94935887 1.37840488 0.63245553]\n",
      " [2.19089023 1.73205081 1.18321596 0.54772256]\n",
      " [2.25831796 1.94935887 1.26491106 0.4472136 ]\n",
      " [2.14476106 1.78885438 1.18321596 0.4472136 ]\n",
      " [2.30217289 1.92353841 1.22474487 0.4472136 ]\n",
      " [2.23606798 1.81659021 1.18321596 0.4472136 ]\n",
      " [2.64575131 1.78885438 2.16794834 1.18321596]\n",
      " [2.52982213 1.78885438 2.12132034 1.22474487]\n",
      " [2.62678511 1.76068169 2.21359436 1.22474487]\n",
      " [2.34520788 1.51657509 2.         1.14017543]\n",
      " [2.54950976 1.67332005 2.14476106 1.22474487]\n",
      " [2.38746728 1.67332005 2.12132034 1.14017543]\n",
      " [2.50998008 1.81659021 2.16794834 1.26491106]\n",
      " [2.21359436 1.54919334 1.81659021 1.        ]\n",
      " [2.56904652 1.70293864 2.14476106 1.14017543]\n",
      " [2.28035085 1.64316767 1.97484177 1.18321596]\n",
      " [2.23606798 1.41421356 1.87082869 1.        ]\n",
      " [2.42899156 1.73205081 2.04939015 1.22474487]\n",
      " [2.44948974 1.4832397  2.         1.        ]\n",
      " [2.46981781 1.70293864 2.16794834 1.18321596]\n",
      " [2.36643191 1.70293864 1.8973666  1.14017543]\n",
      " [2.58843582 1.76068169 2.0976177  1.18321596]\n",
      " [2.36643191 1.73205081 2.12132034 1.22474487]\n",
      " [2.40831892 1.64316767 2.02484567 1.        ]\n",
      " [2.48997992 1.4832397  2.12132034 1.22474487]\n",
      " [2.36643191 1.58113883 1.97484177 1.04880885]\n",
      " [2.42899156 1.78885438 2.19089023 1.34164079]\n",
      " [2.46981781 1.67332005 2.         1.14017543]\n",
      " [2.50998008 1.58113883 2.21359436 1.22474487]\n",
      " [2.46981781 1.67332005 2.16794834 1.09544512]\n",
      " [2.52982213 1.70293864 2.07364414 1.14017543]\n",
      " [2.56904652 1.73205081 2.0976177  1.18321596]\n",
      " [2.60768096 1.67332005 2.19089023 1.18321596]\n",
      " [2.58843582 1.73205081 2.23606798 1.30384048]\n",
      " [2.44948974 1.70293864 2.12132034 1.22474487]\n",
      " [2.38746728 1.61245155 1.87082869 1.        ]\n",
      " [2.34520788 1.54919334 1.94935887 1.04880885]\n",
      " [2.34520788 1.54919334 1.92353841 1.        ]\n",
      " [2.40831892 1.64316767 1.97484177 1.09544512]\n",
      " [2.44948974 1.64316767 2.25831796 1.26491106]\n",
      " [2.32379001 1.73205081 2.12132034 1.22474487]\n",
      " [2.44948974 1.84390889 2.12132034 1.26491106]\n",
      " [2.58843582 1.76068169 2.16794834 1.22474487]\n",
      " [2.50998008 1.51657509 2.0976177  1.14017543]\n",
      " [2.36643191 1.73205081 2.02484567 1.14017543]\n",
      " [2.34520788 1.58113883 2.         1.14017543]\n",
      " [2.34520788 1.61245155 2.0976177  1.09544512]\n",
      " [2.46981781 1.73205081 2.14476106 1.18321596]\n",
      " [2.40831892 1.61245155 2.         1.09544512]\n",
      " [2.23606798 1.51657509 1.81659021 1.        ]\n",
      " [2.36643191 1.64316767 2.04939015 1.14017543]\n",
      " [2.38746728 1.73205081 2.04939015 1.09544512]\n",
      " [2.38746728 1.70293864 2.04939015 1.14017543]\n",
      " [2.48997992 1.70293864 2.07364414 1.14017543]\n",
      " [2.25831796 1.58113883 1.73205081 1.04880885]\n",
      " [2.38746728 1.67332005 2.02484567 1.14017543]\n",
      " [2.50998008 1.81659021 2.44948974 1.58113883]\n",
      " [2.40831892 1.64316767 2.25831796 1.37840488]\n",
      " [2.66458252 1.73205081 2.42899156 1.44913767]\n",
      " [2.50998008 1.70293864 2.36643191 1.34164079]\n",
      " [2.54950976 1.73205081 2.40831892 1.4832397 ]\n",
      " [2.75680975 1.73205081 2.56904652 1.44913767]\n",
      " [2.21359436 1.58113883 2.12132034 1.30384048]\n",
      " [2.70185122 1.70293864 2.50998008 1.34164079]\n",
      " [2.58843582 1.58113883 2.40831892 1.34164079]\n",
      " [2.68328157 1.8973666  2.46981781 1.58113883]\n",
      " [2.54950976 1.78885438 2.25831796 1.41421356]\n",
      " [2.52982213 1.64316767 2.30217289 1.37840488]\n",
      " [2.60768096 1.73205081 2.34520788 1.44913767]\n",
      " [2.38746728 1.58113883 2.23606798 1.41421356]\n",
      " [2.40831892 1.67332005 2.25831796 1.54919334]\n",
      " [2.52982213 1.78885438 2.30217289 1.51657509]\n",
      " [2.54950976 1.73205081 2.34520788 1.34164079]\n",
      " [2.77488739 1.94935887 2.58843582 1.4832397 ]\n",
      " [2.77488739 1.61245155 2.62678511 1.51657509]\n",
      " [2.44948974 1.4832397  2.23606798 1.22474487]\n",
      " [2.62678511 1.78885438 2.38746728 1.51657509]\n",
      " [2.36643191 1.67332005 2.21359436 1.41421356]\n",
      " [2.77488739 1.67332005 2.58843582 1.41421356]\n",
      " [2.50998008 1.64316767 2.21359436 1.34164079]\n",
      " [2.58843582 1.81659021 2.38746728 1.44913767]\n",
      " [2.68328157 1.78885438 2.44948974 1.34164079]\n",
      " [2.48997992 1.67332005 2.19089023 1.34164079]\n",
      " [2.46981781 1.73205081 2.21359436 1.34164079]\n",
      " [2.52982213 1.67332005 2.36643191 1.44913767]\n",
      " [2.68328157 1.73205081 2.40831892 1.26491106]\n",
      " [2.7202941  1.67332005 2.46981781 1.37840488]\n",
      " [2.81069386 1.94935887 2.52982213 1.41421356]\n",
      " [2.52982213 1.67332005 2.36643191 1.4832397 ]\n",
      " [2.50998008 1.67332005 2.25831796 1.22474487]\n",
      " [2.46981781 1.61245155 2.36643191 1.18321596]\n",
      " [2.77488739 1.73205081 2.46981781 1.51657509]\n",
      " [2.50998008 1.84390889 2.36643191 1.54919334]\n",
      " [2.52982213 1.76068169 2.34520788 1.34164079]\n",
      " [2.44948974 1.73205081 2.19089023 1.34164079]\n",
      " [2.62678511 1.76068169 2.32379001 1.44913767]\n",
      " [2.58843582 1.76068169 2.36643191 1.54919334]\n",
      " [2.62678511 1.76068169 2.25831796 1.51657509]\n",
      " [2.40831892 1.64316767 2.25831796 1.37840488]\n",
      " [2.60768096 1.78885438 2.42899156 1.51657509]\n",
      " [2.58843582 1.81659021 2.38746728 1.58113883]\n",
      " [2.58843582 1.73205081 2.28035085 1.51657509]\n",
      " [2.50998008 1.58113883 2.23606798 1.37840488]\n",
      " [2.54950976 1.73205081 2.28035085 1.41421356]\n",
      " [2.48997992 1.84390889 2.32379001 1.51657509]\n",
      " [2.42899156 1.73205081 2.25831796 1.34164079]]\n",
      "b. The first column rounded to the nearest integer is [5. 5. 5. 5. 5. 5. 5. 5. 4. 5. 5. 5. 5. 4. 6. 6. 5. 5. 6. 5. 5. 5. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5. 5. 5. 5. 6. 5. 5. 6. 5. 4. 5. 5. 4. 4. 5. 5. 5. 5. 5.\n",
      " 5. 5. 7. 6. 7. 6. 6. 6. 6. 5. 7. 5. 5. 6. 6. 6. 6. 7. 6. 6. 6. 6. 6. 6.\n",
      " 6. 6. 6. 7. 7. 7. 6. 6. 6. 6. 6. 6. 5. 6. 7. 6. 6. 6. 6. 6. 6. 5. 6. 6.\n",
      " 6. 6. 5. 6. 6. 6. 7. 6. 6. 8. 5. 7. 7. 7. 6. 6. 7. 6. 6. 6. 6. 8. 8. 6.\n",
      " 7. 6. 8. 6. 7. 7. 6. 6. 6. 7. 7. 8. 6. 6. 6. 8. 6. 6. 6. 7. 7. 7. 6. 7.\n",
      " 7. 7. 6. 6. 6. 6.]\n",
      "c. The first row with 1 added to every element is [6.1 4.5 2.4 1.2]\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "print(f'a. The square root of each element in a is {np.sqrt(a)}')\n",
    "print(f'b. The first column rounded to the nearest integer is {np.round(a[:,0])}')\n",
    "print(f'c. The first row with 1 added to every element is {a[0,:]+1}')\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "d. Calculate the standard deviation of the first column in a by calculation the standard deviation of every column of array a and then selecting the first element of the resulting array."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T12:29:01.218762Z",
     "start_time": "2025-01-24T12:28:57.723011Z"
    },
    "id": "8e05d131730b06d",
    "outputId": "4104dcdc-2109-4c31-bab4-2d8845045860"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8253012917851409"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.9 μs ± 2.31 μs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "a.std(axis=0)[0]\n",
    "%timeit a.std(axis=0)[0]\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "e. Calculate the standard deviation of the first column in a by selecting the first column and then calculating the standard deviation."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T12:29:03.752956Z",
     "start_time": "2025-01-24T12:29:01.279769Z"
    },
    "id": "66e5746bca89efa9",
    "outputId": "9e0c8269-32a7-4160-bfc0-460efcd1ace8"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8253012917851409"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.3 μs ± 1.07 μs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "a[:,0].std()\n",
    "%timeit a[:,0].std()\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "f. Compare the time it takes to calculate the standard deviation of the first column in a using the two methods above. Which method is faster? Why"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T12:31:36.085631Z",
     "start_time": "2025-01-24T12:31:30.512944Z"
    },
    "id": "dd9325c76be23450",
    "outputId": "9108c438-74dc-4eef-be3c-3ddec0aacea2"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.1 μs ± 10.2 μs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "27.6 μs ± 3.14 μs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "%timeit a.std(axis=0)[0]\n",
    "%timeit a[:,0].std()\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This is another example where chosing the right method can make a big difference in performance. Chosing an efficient solution will be taken into account when evaluating."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<!--BOOK_INFORMATION-->\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"figures/PDSH-cover-small.png\">\n",
    "\n",
    "*This notebook contains an excerpt from the [Python Data Science Handbook](http://shop.oreilly.com/product/0636920034919.do) by Jake VanderPlas; the content is available [on GitHub](https://github.com/jakevdp/PythonDataScienceHandbook).*\n",
    "\n",
    "*The text is released under the [CC-BY-NC-ND license](https://creativecommons.org/licenses/by-nc-nd/3.0/us/legalcode), and code is released under the [MIT license](https://opensource.org/licenses/MIT). If you find this content useful, please consider supporting the work by [buying the book](http://shop.oreilly.com/product/0636920034919.do)!*"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<!--NAVIGATION-->\n",
    "< [Aggregations: Min, Max, and Everything In Between](02.04-Computation-on-arrays-aggregates.ipynb) | [Contents](Index.ipynb) | [Comparisons, Masks, and Boolean Logic](02.06-Boolean-Arrays-and-Masks.ipynb) >\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/02.05-Computation-on-arrays-broadcasting.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Computation on Arrays: Broadcasting"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We saw in the previous section how NumPy's universal functions can be used to *vectorize* operations and thereby remove slow Python loops.\n",
    "Another means of vectorizing operations is to use NumPy's *broadcasting* functionality.\n",
    "Broadcasting is simply a set of rules for applying binary ufuncs (e.g., addition, subtraction, multiplication, etc.) on arrays of different sizes."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Introducing Broadcasting\n",
    "\n",
    "Recall that for arrays of the same size, binary operations are performed on an element-by-element basis:"
   ]
  },
  {
   "metadata": {
    "id": "HnOexbHJJ3Wl"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "import numpy as np"
  },
  {
   "metadata": {
    "id": "xckK__WmJ3Wn",
    "outputId": "425aaae3-d964-437b-b92e-a50f1655435d"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 6, 7])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "a = np.array([0, 1, 2])\n",
    "b = np.array([5, 5, 5])\n",
    "a + b"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Broadcasting allows these types of binary operations to be performed on arrays of different sizes–for example, we can just as easily add a scalar (think of it as a zero-dimensional array) to an array:"
  },
  {
   "metadata": {
    "id": "hfexxwqEJ3Wo",
    "outputId": "6b5c4622-237e-4e7f-ed0b-04760640fb16"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 6, 7])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "a + 5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We can think of this as an operation that stretches or duplicates the value ``5`` into the array ``[5, 5, 5]``, and adds the results.\n",
    "The advantage of NumPy's broadcasting is that this duplication of values does not actually take place, but it is a useful mental model as we think about broadcasting.\n",
    "\n",
    "We can similarly extend this to arrays of higher dimension. Observe the result when we add a one-dimensional array to a two-dimensional array:"
   ]
  },
  {
   "metadata": {
    "id": "cZx1nAwcJ3Wp",
    "outputId": "82e5e5fd-74fe-46af-dc1a-b0b1b8aaf777"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "M = np.ones((3, 3))\n",
    "M"
   ]
  },
  {
   "metadata": {
    "id": "R3B7eIK9J3Wq",
    "outputId": "fa695ab2-dcc0-4d92-dcec-9bcafe8295f7"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  2.,  3.],\n",
       "       [ 1.,  2.,  3.],\n",
       "       [ 1.,  2.,  3.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "M + a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Here the one-dimensional array ``a`` is stretched, or broadcast across the second dimension in order to match the shape of ``M``.\n",
    "\n",
    "While these examples are relatively easy to understand, more complicated cases can involve broadcasting of both arrays. Consider the following example:"
   ]
  },
  {
   "metadata": {
    "id": "HubMtcfrJ3Wq",
    "outputId": "3053fe8d-4644-45cf-e01b-8a2cd233e5a3"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n",
      "[[0]\n",
      " [1]\n",
      " [2]]\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "a = np.arange(3)\n",
    "b = np.arange(3)[:, np.newaxis]\n",
    "\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "metadata": {
    "id": "bS6XCDN7J3Wq",
    "outputId": "7d589258-a808-4a7b-d632-0cf464425413"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [1, 2, 3],\n",
       "       [2, 3, 4]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "a + b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Just as before we stretched or broadcasted one value to match the shape of the other, here we've stretched *both* ``a`` and ``b`` to match a common shape, and the result is a two-dimensional array!\n",
    "The geometry of these examples is visualized in the following figure (Code to produce this plot can be found in the [appendix](06.00-Figure-Code.ipynb#Broadcasting), and is adapted from source published in the [astroML](http://astroml.org) documentation. Used by permission)."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![Broadcasting Visual](figures/02.05-broadcasting.png)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The light boxes represent the broadcasted values: again, this extra memory is not actually allocated in the course of the operation, but it can be useful conceptually to imagine that it is."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Rules of Broadcasting\n",
    "\n",
    "Broadcasting in NumPy follows a strict set of rules to determine the interaction between the two arrays:\n",
    "\n",
    "- Rule 1: If the two arrays differ in their number of dimensions, the shape of the one with fewer dimensions is *padded* with ones on its leading (left) side.\n",
    "- Rule 2: If the shape of the two arrays does not match in any dimension, the array with shape equal to 1 in that dimension is stretched to match the other shape.\n",
    "- Rule 3: If in any dimension the sizes disagree and neither is equal to 1, an error is raised.\n",
    "\n",
    "To make these rules clear, let's consider a few examples in detail."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Broadcasting example 1\n",
    "\n",
    "Let's look at adding a two-dimensional array to a one-dimensional array:"
   ]
  },
  {
   "metadata": {
    "id": "3B02LhMRJ3Wr"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "M = np.ones((2, 3))\n",
    "a = np.arange(3)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Let's consider an operation on these two arrays. The shape of the arrays are\n",
    "\n",
    "- ``M.shape = (2, 3)``\n",
    "- ``a.shape = (3,)``\n",
    "\n",
    "We see by rule 1 that the array ``a`` has fewer dimensions, so we pad it on the left with ones:\n",
    "\n",
    "- ``M.shape -> (2, 3)``\n",
    "- ``a.shape -> (1, 3)``\n",
    "\n",
    "By rule 2, we now see that the first dimension disagrees, so we stretch this dimension to match:\n",
    "\n",
    "- ``M.shape -> (2, 3)``\n",
    "- ``a.shape -> (2, 3)``\n",
    "\n",
    "The shapes match, and we see that the final shape will be ``(2, 3)``:"
   ]
  },
  {
   "metadata": {
    "id": "9iCMee9-J3Ws",
    "outputId": "c5354427-90b7-487b-8636-9e33d56a60fb"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  2.,  3.],\n",
       "       [ 1.,  2.,  3.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "M + a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Broadcasting example 2\n",
    "\n",
    "Let's take a look at an example where both arrays need to be broadcast:"
   ]
  },
  {
   "metadata": {
    "id": "MCDo9-A9J3Ws"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "a = np.arange(3).reshape((3, 1))\n",
    "b = np.arange(3)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Again, we'll start by writing out the shape of the arrays:\n",
    "\n",
    "- ``a.shape = (3, 1)``\n",
    "- ``b.shape = (3,)``\n",
    "\n",
    "Rule 1 says we must pad the shape of ``b`` with ones:\n",
    "\n",
    "- ``a.shape -> (3, 1)``\n",
    "- ``b.shape -> (1, 3)``\n",
    "\n",
    "And rule 2 tells us that we upgrade each of these ones to match the corresponding size of the other array:\n",
    "\n",
    "- ``a.shape -> (3, 3)``\n",
    "- ``b.shape -> (3, 3)``\n",
    "\n",
    "Because the result matches, these shapes are compatible. We can see this here:"
   ]
  },
  {
   "metadata": {
    "id": "l_6BtVFnJ3Wt",
    "outputId": "f11311a2-802c-4233-beb9-450a8045856d"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [1, 2, 3],\n",
       "       [2, 3, 4]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "a + b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Broadcasting example 3\n",
    "\n",
    "Now let's take a look at an example in which the two arrays are not compatible:"
   ]
  },
  {
   "metadata": {
    "id": "ibch4BZEJ3Wt"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "M = np.ones((3, 2))\n",
    "a = np.arange(3)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This is just a slightly different situation than in the first example: the matrix ``M`` is transposed.\n",
    "How does this affect the calculation? The shape of the arrays are\n",
    "\n",
    "- ``M.shape = (3, 2)``\n",
    "- ``a.shape = (3,)``\n",
    "\n",
    "Again, rule 1 tells us that we must pad the shape of ``a`` with ones:\n",
    "\n",
    "- ``M.shape -> (3, 2)``\n",
    "- ``a.shape -> (1, 3)``\n",
    "\n",
    "By rule 2, the first dimension of ``a`` is stretched to match that of ``M``:\n",
    "\n",
    "- ``M.shape -> (3, 2)``\n",
    "- ``a.shape -> (3, 3)``\n",
    "\n",
    "Now we hit rule 3–the final shapes do not match, so these two arrays are incompatible, as we can observe by attempting this operation:"
   ]
  },
  {
   "metadata": {
    "id": "QXU5V4qEJ3Wt",
    "outputId": "0872acee-f862-4fc0-a952-e82465c543b7"
   },
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (3,2) (3,) ",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-13-9e16e9f98da6>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mM\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0ma\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m: operands could not be broadcast together with shapes (3,2) (3,) "
     ]
    }
   ],
   "execution_count": null,
   "source": "M + a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Note the potential confusion here: you could imagine making ``a`` and ``M`` compatible by, say, padding ``a``'s shape with ones on the right rather than the left.\n",
    "But this is not how the broadcasting rules work!\n",
    "That sort of flexibility might be useful in some cases, but it would lead to potential areas of ambiguity.\n",
    "If right-side padding is what you'd like, you can do this explicitly by reshaping the array (we'll use the ``np.newaxis`` keyword introduced in [The Basics of NumPy Arrays](02.02-The-Basics-Of-NumPy-Arrays.ipynb)):"
   ]
  },
  {
   "metadata": {
    "id": "i3BeekWnJ3Wu",
    "outputId": "9fc3f668-ed02-43bc-f720-fb38e8104e10"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "a[:, np.newaxis].shape"
  },
  {
   "metadata": {
    "id": "Z88bapmlJ3Wu",
    "outputId": "c3097322-52d1-4c5b-e4cb-d547dd4e4d77"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.],\n",
       "       [ 2.,  2.],\n",
       "       [ 3.,  3.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "M + a[:, np.newaxis]"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Also note that while we've been focusing on the ``+`` operator here, these broadcasting rules apply to *any* binary ``ufunc``.\n",
    "For example, here is the ``logaddexp(a, b)`` function, which computes ``log(exp(a) + exp(b))`` with more precision than the naive approach:"
   ]
  },
  {
   "metadata": {
    "id": "IY_UzZstJ3Wu",
    "outputId": "879f6290-b4a8-4c7d-d317-92c0d971fe9b"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.31326169,  1.31326169],\n",
       "       [ 1.69314718,  1.69314718],\n",
       "       [ 2.31326169,  2.31326169]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "np.logaddexp(M, a[:, np.newaxis])"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "For more information on the many available universal functions, refer to [Computation on NumPy Arrays: Universal Functions](02.03-Computation-on-arrays-ufuncs.ipynb)."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Broadcasting in Practice"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Broadcasting operations form the core of many examples we'll see throughout this book.\n",
    "We'll now take a look at a couple simple examples of where they can be useful."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Centering an array"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In the previous section, we saw that ufuncs allow a NumPy user to remove the need to explicitly write slow Python loops. Broadcasting extends this ability.\n",
    "One commonly seen example is when centering an array of data.\n",
    "Imagine you have an array of 10 observations, each of which consists of 3 values.\n",
    "Using the standard convention (see [Data Representation in Scikit-Learn](05.02-Introducing-Scikit-Learn.ipynb#Data-Representation-in-Scikit-Learn)), we'll store this in a $10 \\times 3$ array:"
   ]
  },
  {
   "metadata": {
    "id": "mlYst8DHJ3W0"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "X = np.random.random((10, 3))"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can compute the mean of each feature using the ``mean`` aggregate across the first dimension:"
  },
  {
   "metadata": {
    "id": "KlzNJo54J3W0",
    "outputId": "a2361d79-1018-4f14-9ca4-44dfd4ac8df4"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.53514715,  0.66567217,  0.44385899])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "Xmean = X.mean(0)\n",
    "Xmean"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "And now we can center the ``X`` array by subtracting the mean (this is a broadcasting operation):"
  },
  {
   "metadata": {
    "id": "gZFokZ9hJ3W0"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "X_centered = X - Xmean"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "To double-check that we've done this correctly, we can check that the centered array has near zero mean:"
  },
  {
   "metadata": {
    "id": "eztOpsy5J3W0",
    "outputId": "ab40295b-32f3-4f1d-a7c2-72dd1a38ca44"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.22044605e-17,  -7.77156117e-17,  -1.66533454e-17])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "X_centered.mean(0)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "To within machine precision, the mean is now zero."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Plotting a two-dimensional function"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "One place that broadcasting is very useful is in displaying images based on two-dimensional functions.\n",
    "If we want to define a function $z = f(x, y)$, broadcasting can be used to compute the function across the grid:"
   ]
  },
  {
   "metadata": {
    "id": "k2dtbFIDJ3W1"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# x and y have 50 steps from 0 to 5\n",
    "x = np.linspace(0, 5, 50)\n",
    "y = np.linspace(0, 5, 50)[:, np.newaxis]\n",
    "\n",
    "z = np.sin(x) ** 10 + np.cos(10 + y * x) * np.cos(x)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We'll use Matplotlib to plot this two-dimensional array (these tools will be discussed in full in [Density and Contour Plots](04.04-Density-and-Contour-Plots.ipynb)):"
  },
  {
   "metadata": {
    "id": "sqqMy0xfJ3W2"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "metadata": {
    "id": "pJSgTAomJ3W2",
    "outputId": "cacb6b5b-ec61-432d-deb3-61a7ae4cc953"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATYAAAEACAYAAAA5n1oZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10becee48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": null,
   "source": [
    "plt.imshow(z, origin='lower', extent=[0, 5, 0, 5],\n",
    "           cmap='viridis')\n",
    "plt.colorbar();"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The result is a compelling visualization of the two-dimensional function."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<!--NAVIGATION-->\n",
    "< [Aggregations: Min, Max, and Everything In Between](02.04-Computation-on-arrays-aggregates.ipynb) | [Contents](Index.ipynb) | [Comparisons, Masks, and Boolean Logic](02.06-Boolean-Arrays-and-Masks.ipynb) >\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/02.05-Computation-on-arrays-broadcasting.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>\n"
   ]
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-24T14:10:39.551188Z",
     "start_time": "2025-01-24T14:10:38.676005Z"
    },
    "id": "initial_id"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import sklearn.datasets as ds\n",
    "import numpy as np\n",
    "b, _ = ds.make_gaussian_quantiles(n_samples=10000, n_features=4, random_state=42)\n",
    "a= np.array(ds.load_iris().data)[0:100,:]\n",
    "c = np.arange(1,5)\n",
    "d= a[10:14,0].reshape(4,1)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Broadcasting\n",
    "a,b,c and d arre generated with dummy data. You do not have to understand how it's done.\\\n",
    "a. Print the array a, b, c, and d.\\\n",
    "b. Print the number of dimensions of a, b, c, and d.\\\n",
    "c. print the shape of a, b, c, and d.\\\n",
    "_It is important to understand the shape of the arrays when broadcasting. Make sure you understand the shape of the arrays before you start the next steps._\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T14:21:41.837833Z",
     "start_time": "2025-01-24T14:21:41.823243Z"
    },
    "id": "3e4c1bb4c1aa1a4b",
    "outputId": "4ce08cdb-463d-4940-898a-50c78a8d30fe"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]]\n",
      "b:\n",
      "[[ 0.94469887  1.40606928 -1.87641785 -2.34179744]\n",
      " [-0.66044737 -0.7794562   0.50950138 -1.04046731]\n",
      " [-1.61026312  0.75318995 -1.08201779 -0.33866905]\n",
      " ...\n",
      " [ 0.24690606 -1.12519783 -1.08869341  0.56147263]\n",
      " [ 0.8720902  -0.16624207  2.67962869 -0.60451386]\n",
      " [-0.3361858   0.19108044  2.37722429  0.31854861]]\n",
      "c:\n",
      "[1 2 3 4]\n",
      "d:\n",
      "[[5.4]\n",
      " [4.8]\n",
      " [4.8]\n",
      " [4.3]]\n",
      "The number of dimensions of a is 2, b is 2, c is 1, and d is 2\n",
      "The shape of a is (100, 4), b is (10000, 4), c is (4,), and d is (4, 1))\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "print(\"a:\")\n",
    "print(a)\n",
    "print(\"b:\")\n",
    "print(b)\n",
    "print(\"c:\")\n",
    "print(c)\n",
    "print(\"d:\")\n",
    "print(d)\n",
    "\n",
    "print(f'The number of dimensions of a is {a.ndim}, b is {b.ndim}, c is {c.ndim}, and d is {d.ndim}')\n",
    "print(f'The shape of a is {a.shape}, b is {b.shape}, c is {c.shape}, and d is {d.shape})')\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "c. Pick the first 100 rows of b. Add array a to these rows."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T14:28:14.466858Z",
     "start_time": "2025-01-24T14:28:14.456221Z"
    },
    "id": "8e05d131730b06d",
    "outputId": "98762ad9-543b-46e2-c22d-feea673d0318"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.04469887,  4.90606928, -0.47641785, -2.14179744],\n",
       "       [ 4.23955263,  2.2205438 ,  1.90950138, -0.84046731],\n",
       "       [ 3.08973688,  3.95318995,  0.21798221, -0.13866905],\n",
       "       [ 5.49808069,  2.83028969,  4.79590446,  0.75318059],\n",
       "       [ 4.13196822,  2.18893239,  1.64610642,  1.31636145],\n",
       "       [ 5.43302331,  5.24694124,  2.47402277,  0.3925192 ],\n",
       "       [ 4.25434634,  4.17185049,  2.23173314,  0.1095143 ],\n",
       "       [ 5.59891272,  3.58074389,  0.03707179,  0.70695554],\n",
       "       [ 6.38782091,  2.28860607,  1.19814148, -0.81857062],\n",
       "       [ 6.15522625,  5.0686541 ,  1.69937992, -0.74562849],\n",
       "       [ 5.03686835,  4.554402  ,  1.84121584,  1.70027461],\n",
       "       [ 4.52533987,  4.58758947,  1.06016367,  1.87701268],\n",
       "       [ 3.72924562,  3.96609286,  1.96028089, -1.88629061],\n",
       "       [ 3.39824847,  4.15103014,  1.31202681,  0.4425234 ],\n",
       "       [ 6.55408581,  3.84168039,  3.06803292,  0.19608749],\n",
       "       [ 7.84300705,  3.93023554,  1.65875605,  1.55600667],\n",
       "       [ 4.55355563,  3.7619678 ,  2.58590492,  2.17944859],\n",
       "       [ 5.55962604,  5.21654032, -1.27300364, -0.23446968],\n",
       "       [ 5.64759555,  5.50410552,  2.94689172,  0.23799599],\n",
       "       [ 5.56538408,  3.84323169,  0.59758528, -0.18186432],\n",
       "       [ 6.44487874,  2.71582314,  0.30103857,  0.18629661],\n",
       "       [ 5.78916446,  3.01636572,  1.22627075,  0.38572965],\n",
       "       [ 4.13716948,  4.27245278,  0.39586171, -0.79042636],\n",
       "       [ 4.77725545,  4.00689629,  2.96727365,  0.11376291],\n",
       "       [ 4.12617792,  4.17326621,  1.0245815 ,  0.29298186],\n",
       "       [ 4.10465368,  2.59189916,  0.60418461,  0.85113624],\n",
       "       [ 4.89114612,  3.5680256 ,  0.84567536, -0.92478591],\n",
       "       [ 4.80376469,  3.40857964,  2.49080286, -0.2007358 ],\n",
       "       [ 6.545875  ,  4.01846239,  2.1859741 ,  0.78883195],\n",
       "       [ 3.80641903,  4.78689966, -0.86043582,  0.05982207],\n",
       "       [ 3.97613869,  2.74848662,  0.83085472, -0.7340055 ],\n",
       "       [ 4.19114114,  2.83406287,  1.42432893,  1.93755132],\n",
       "       [ 5.33988723,  5.09611821,  0.10977807,  0.25776144],\n",
       "       [ 5.56244698,  4.75057359,  0.94052457,  1.08292481],\n",
       "       [ 4.51718281,  2.97627105,  1.10232031, -0.98403056],\n",
       "       [ 5.174311  ,  2.97168157, -0.71400583, -0.38012764],\n",
       "       [ 6.95264128,  4.57693607,  2.01096941,  0.29440601],\n",
       "       [ 5.64990024,  3.87926784,  0.44908927,  0.418521  ],\n",
       "       [ 6.9043168 ,  3.03081112,  0.44528935, -0.95449723],\n",
       "       [ 4.07413189,  3.46233135,  1.60716992, -0.87851274],\n",
       "       [ 4.99776188,  2.43256607,  0.04093509, -0.70531513],\n",
       "       [ 5.40827956,  2.58944781,  0.92678182, -0.18545362],\n",
       "       [ 5.16093848,  3.55297857,  1.67744414, -0.3993271 ],\n",
       "       [ 2.99785728,  3.04066488,  1.46595123,  0.69442722],\n",
       "       [ 4.34086734,  3.95039379,  2.24175598,  2.27617084],\n",
       "       [ 3.39739473,  4.74957674,  0.15613676, -0.3929052 ],\n",
       "       [ 3.24834304,  3.25331218,  1.46538457,  1.4539318 ],\n",
       "       [ 4.70485269,  3.65150511,  1.1360157 , -0.27963457],\n",
       "       [ 5.3976761 ,  2.92699022,  1.52451017,  0.69799829],\n",
       "       [ 5.14328667,  2.54321963,  2.87545413, -1.24675711],\n",
       "       [ 8.44996419,  4.02553892,  4.8668103 ,  1.22765293],\n",
       "       [ 5.94769368,  0.77612067,  2.91609718,  2.26041466],\n",
       "       [ 7.35041196,  2.5703918 ,  4.15257575,  2.06041463],\n",
       "       [ 5.3365722 ,  2.45630935,  2.41479864,  0.88134294],\n",
       "       [ 7.37281708,  3.53208095,  4.29093376,  1.90482341],\n",
       "       [ 7.52313913,  1.98351869,  2.50498652,  0.769126  ],\n",
       "       [ 5.84938085,  3.40690693,  3.924621  ,  1.81213174],\n",
       "       [ 4.78254394,  2.62092666,  4.80850553,  1.72368823],\n",
       "       [ 6.23475902,  1.22883023,  6.63587354,  1.76897808],\n",
       "       [ 4.16275385,  2.50966132,  3.02438175,  0.01720027],\n",
       "       [ 6.47912789,  2.74115582,  2.85922473,  1.42593811],\n",
       "       [ 5.27496302,  2.35341978,  4.24469178,  1.57466905],\n",
       "       [ 6.6781157 ,  3.45257537,  4.31737422,  1.48912436],\n",
       "       [ 4.16035318,  2.00980392,  5.12251974,  2.8414489 ],\n",
       "       [ 5.2292294 ,  2.82765252,  3.65202065,  1.42717392],\n",
       "       [ 7.07983346,  3.66730563,  6.08831181,  0.79403702],\n",
       "       [ 6.57278981,  3.70967374,  5.65008526,  2.98654414],\n",
       "       [ 5.93318577,  2.32159847,  5.85192081,  1.95031566],\n",
       "       [ 7.07184457,  2.24929743,  4.98022926,  2.21586463],\n",
       "       [ 3.62070019,  3.24791026,  2.82725697,  1.33924686],\n",
       "       [ 6.60337779,  4.43735972,  5.60224275,  2.08514365],\n",
       "       [ 5.34236513,  2.01908653,  3.09620322,  1.06115354],\n",
       "       [ 8.41161322,  3.02276674,  5.82529055,  2.85489293],\n",
       "       [ 5.72021341,  3.40608518,  3.97452468,  0.40652693],\n",
       "       [ 6.48704707,  2.60099265,  4.39176078, -0.68756891],\n",
       "       [ 7.2380511 ,  3.50084447,  2.59894227,  0.8573262 ],\n",
       "       [ 7.31084198,  2.34384919,  3.92119107, -0.3318037 ],\n",
       "       [ 6.42003387,  3.11274894,  4.25161682,  0.4233818 ],\n",
       "       [ 8.31874227,  2.57460864,  3.82257052,  1.34727101],\n",
       "       [ 6.36253603,  1.7771441 ,  2.46077984,  1.81798154],\n",
       "       [ 6.28142892,  1.97480705,  3.42101593,  1.90977927],\n",
       "       [ 3.58714865,  4.17729477,  4.18384113,  0.9576681 ],\n",
       "       [ 5.2301878 ,  2.1028937 ,  4.24189326,  1.44136957],\n",
       "       [ 6.04138576,  2.5476225 ,  3.55509063, -0.65938626],\n",
       "       [ 7.39203664,  4.83389655,  3.63207754,  2.05713762],\n",
       "       [ 6.88114672,  3.40132569,  4.89542099,  0.64243104],\n",
       "       [ 7.3061497 ,  1.62438725,  4.34832576,  3.44730423],\n",
       "       [ 6.83507157,  2.75709879,  4.62946463,  3.95944026],\n",
       "       [ 5.16941243,  2.1392562 ,  3.04332088,  1.1633734 ],\n",
       "       [ 4.89782065,  2.12331585,  3.07761537,  1.26730236],\n",
       "       [ 5.61092778,  3.10119871,  4.99771532,  1.3782068 ],\n",
       "       [ 4.72792081,  4.17994213,  5.33189807,  2.6545187 ],\n",
       "       [ 6.1616951 ,  2.01424429,  4.9001002 ,  0.24594066],\n",
       "       [ 4.68470334,  1.3589773 ,  3.54608362,  0.19771997],\n",
       "       [ 4.63855556,  3.08200721,  2.97420826,  3.01998453],\n",
       "       [ 4.69155127,  0.91410212,  2.72796293, -0.17383482],\n",
       "       [ 5.87040439,  1.38635438,  5.16776879,  0.03756691],\n",
       "       [ 4.40585649,  3.43976451,  3.97346415,  0.12907511],\n",
       "       [ 5.38347251,  2.38981281,  0.72117228,  3.09553544],\n",
       "       [ 6.87225151,  3.36978335,  4.3984279 ,  1.80836868]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "b[0:100]+a\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "d. For each row in  array a, calculate the sum of the power of the first column and the power of the second column."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T11:53:01.222514500Z",
     "start_time": "2024-08-20T11:53:01.215573900Z"
    },
    "id": "66e5746bca89efa9",
    "outputId": "00dc5019-a1d5-42fe-fb8b-e5a98e897c03"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([38.26, 33.01, 32.33, 30.77, 37.96, 44.37, 32.72, 36.56, 27.77,\n       33.62, 42.85, 34.6 , 32.04, 27.49, 49.64, 51.85, 44.37, 38.26,\n       46.93, 40.45, 40.72, 39.7 , 34.12, 36.9 , 34.6 , 34.  , 36.56,\n       39.29, 38.6 , 32.33, 32.65, 40.72, 43.85, 47.89, 33.62, 35.24,\n       42.5 , 36.97, 28.36, 37.57, 37.25, 25.54, 29.6 , 37.25, 40.45,\n       32.04, 40.45, 31.4 , 41.78, 35.89, 59.24, 51.2 , 57.22, 35.54,\n       50.09, 40.33, 50.58, 29.77, 51.97, 34.33, 29.  , 43.81, 40.84,\n       45.62, 39.77, 54.5 , 40.36, 40.93, 43.28, 37.61, 45.05, 45.05,\n       45.94, 45.05, 49.37, 52.56, 54.08, 53.89, 44.41, 39.25, 36.01,\n       36.01, 40.93, 43.29, 38.16, 47.56, 54.5 , 44.98, 40.36, 36.5 ,\n       37.01, 46.21, 40.4 , 30.29, 38.65, 41.49, 40.9 , 46.85, 32.26,\n       40.33])"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "a[:,0]**2 + a[:,1]**2\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "e. You are going to multiply array a with array c. Before doing, predict the shape of the resulting array and results of the first row based on __the rules of broadcasting__.\\\n",
    "f. Now, multiply array a with array c and compare the result with your prediction."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T14:20:35.382713Z",
     "start_time": "2025-01-24T14:20:35.371332Z"
    },
    "id": "dd9325c76be23450",
    "outputId": "7edf8d76-2757-4eb9-9ced-fe791f7805d6"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 5.1,  7. ,  4.2,  0.8],\n",
       "       [ 4.9,  6. ,  4.2,  0.8],\n",
       "       [ 4.7,  6.4,  3.9,  0.8],\n",
       "       [ 4.6,  6.2,  4.5,  0.8],\n",
       "       [ 5. ,  7.2,  4.2,  0.8],\n",
       "       [ 5.4,  7.8,  5.1,  1.6],\n",
       "       [ 4.6,  6.8,  4.2,  1.2],\n",
       "       [ 5. ,  6.8,  4.5,  0.8],\n",
       "       [ 4.4,  5.8,  4.2,  0.8],\n",
       "       [ 4.9,  6.2,  4.5,  0.4],\n",
       "       [ 5.4,  7.4,  4.5,  0.8],\n",
       "       [ 4.8,  6.8,  4.8,  0.8],\n",
       "       [ 4.8,  6. ,  4.2,  0.4],\n",
       "       [ 4.3,  6. ,  3.3,  0.4],\n",
       "       [ 5.8,  8. ,  3.6,  0.8],\n",
       "       [ 5.7,  8.8,  4.5,  1.6],\n",
       "       [ 5.4,  7.8,  3.9,  1.6],\n",
       "       [ 5.1,  7. ,  4.2,  1.2],\n",
       "       [ 5.7,  7.6,  5.1,  1.2],\n",
       "       [ 5.1,  7.6,  4.5,  1.2],\n",
       "       [ 5.4,  6.8,  5.1,  0.8],\n",
       "       [ 5.1,  7.4,  4.5,  1.6],\n",
       "       [ 4.6,  7.2,  3. ,  0.8],\n",
       "       [ 5.1,  6.6,  5.1,  2. ],\n",
       "       [ 4.8,  6.8,  5.7,  0.8],\n",
       "       [ 5. ,  6. ,  4.8,  0.8],\n",
       "       [ 5. ,  6.8,  4.8,  1.6],\n",
       "       [ 5.2,  7. ,  4.5,  0.8],\n",
       "       [ 5.2,  6.8,  4.2,  0.8],\n",
       "       [ 4.7,  6.4,  4.8,  0.8],\n",
       "       [ 4.8,  6.2,  4.8,  0.8],\n",
       "       [ 5.4,  6.8,  4.5,  1.6],\n",
       "       [ 5.2,  8.2,  4.5,  0.4],\n",
       "       [ 5.5,  8.4,  4.2,  0.8],\n",
       "       [ 4.9,  6.2,  4.5,  0.8],\n",
       "       [ 5. ,  6.4,  3.6,  0.8],\n",
       "       [ 5.5,  7. ,  3.9,  0.8],\n",
       "       [ 4.9,  7.2,  4.2,  0.4],\n",
       "       [ 4.4,  6. ,  3.9,  0.8],\n",
       "       [ 5.1,  6.8,  4.5,  0.8],\n",
       "       [ 5. ,  7. ,  3.9,  1.2],\n",
       "       [ 4.5,  4.6,  3.9,  1.2],\n",
       "       [ 4.4,  6.4,  3.9,  0.8],\n",
       "       [ 5. ,  7. ,  4.8,  2.4],\n",
       "       [ 5.1,  7.6,  5.7,  1.6],\n",
       "       [ 4.8,  6. ,  4.2,  1.2],\n",
       "       [ 5.1,  7.6,  4.8,  0.8],\n",
       "       [ 4.6,  6.4,  4.2,  0.8],\n",
       "       [ 5.3,  7.4,  4.5,  0.8],\n",
       "       [ 5. ,  6.6,  4.2,  0.8],\n",
       "       [ 7. ,  6.4, 14.1,  5.6],\n",
       "       [ 6.4,  6.4, 13.5,  6. ],\n",
       "       [ 6.9,  6.2, 14.7,  6. ],\n",
       "       [ 5.5,  4.6, 12. ,  5.2],\n",
       "       [ 6.5,  5.6, 13.8,  6. ],\n",
       "       [ 5.7,  5.6, 13.5,  5.2],\n",
       "       [ 6.3,  6.6, 14.1,  6.4],\n",
       "       [ 4.9,  4.8,  9.9,  4. ],\n",
       "       [ 6.6,  5.8, 13.8,  5.2],\n",
       "       [ 5.2,  5.4, 11.7,  5.6],\n",
       "       [ 5. ,  4. , 10.5,  4. ],\n",
       "       [ 5.9,  6. , 12.6,  6. ],\n",
       "       [ 6. ,  4.4, 12. ,  4. ],\n",
       "       [ 6.1,  5.8, 14.1,  5.6],\n",
       "       [ 5.6,  5.8, 10.8,  5.2],\n",
       "       [ 6.7,  6.2, 13.2,  5.6],\n",
       "       [ 5.6,  6. , 13.5,  6. ],\n",
       "       [ 5.8,  5.4, 12.3,  4. ],\n",
       "       [ 6.2,  4.4, 13.5,  6. ],\n",
       "       [ 5.6,  5. , 11.7,  4.4],\n",
       "       [ 5.9,  6.4, 14.4,  7.2],\n",
       "       [ 6.1,  5.6, 12. ,  5.2],\n",
       "       [ 6.3,  5. , 14.7,  6. ],\n",
       "       [ 6.1,  5.6, 14.1,  4.8],\n",
       "       [ 6.4,  5.8, 12.9,  5.2],\n",
       "       [ 6.6,  6. , 13.2,  5.6],\n",
       "       [ 6.8,  5.6, 14.4,  5.6],\n",
       "       [ 6.7,  6. , 15. ,  6.8],\n",
       "       [ 6. ,  5.8, 13.5,  6. ],\n",
       "       [ 5.7,  5.2, 10.5,  4. ],\n",
       "       [ 5.5,  4.8, 11.4,  4.4],\n",
       "       [ 5.5,  4.8, 11.1,  4. ],\n",
       "       [ 5.8,  5.4, 11.7,  4.8],\n",
       "       [ 6. ,  5.4, 15.3,  6.4],\n",
       "       [ 5.4,  6. , 13.5,  6. ],\n",
       "       [ 6. ,  6.8, 13.5,  6.4],\n",
       "       [ 6.7,  6.2, 14.1,  6. ],\n",
       "       [ 6.3,  4.6, 13.2,  5.2],\n",
       "       [ 5.6,  6. , 12.3,  5.2],\n",
       "       [ 5.5,  5. , 12. ,  5.2],\n",
       "       [ 5.5,  5.2, 13.2,  4.8],\n",
       "       [ 6.1,  6. , 13.8,  5.6],\n",
       "       [ 5.8,  5.2, 12. ,  4.8],\n",
       "       [ 5. ,  4.6,  9.9,  4. ],\n",
       "       [ 5.6,  5.4, 12.6,  5.2],\n",
       "       [ 5.7,  6. , 12.6,  4.8],\n",
       "       [ 5.7,  5.8, 12.6,  5.2],\n",
       "       [ 6.2,  5.8, 12.9,  5.2],\n",
       "       [ 5.1,  5. ,  9. ,  4.4],\n",
       "       [ 5.7,  5.6, 12.3,  5.2]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "\n",
    "a * c\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "First rule 1 is applied to array c. The shape of c is padded to (1,4) because it had less dimensions than a.\n",
    "`[1,2,3,4] -> [[1,2,3,4]]`\n",
    "\n",
    "Then, rule 2 is applied to c. The shape of c is stretched to (100,4) to match the shape of a.\n",
    "`[[1,2,3,4]] -> [[1,2,3,4],[1,2,3,4],...,[1,2,3,4]]`\n",
    "\n",
    "Finally, the two arrays are multiplied element-wise."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "g. Now multiply array a with array d. Before doing, predict the shape of the resulting array and results of the first row based on __the rules of broadcasting__.\n"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T12:11:42.406339400Z",
     "start_time": "2024-08-20T12:11:42.373939900Z"
    },
    "id": "7a82253889b1ad1c",
    "outputId": "6684dd1e-1831-4b7f-efaf-de4e7c4937d6"
   },
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (100,4) (4,1) ",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[24], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43ma\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43md\u001B[49m\n",
      "\u001B[1;31mValueError\u001B[0m: operands could not be broadcast together with shapes (100,4) (4,1) "
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "a * d\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Rule 1: the number of dimensions is the same for both arrays. Padding not applied.\\\n",
    "Rule 2: The shape of d is stretched from (4,1) to (4,4) to match the shape of a.\\\n",
    "Rule 3: The dimensions of the arrays differ. An error is raised.\\"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "h. Now multiply c with. d. Before doing, predict the shape of the resulting array and results of the first row based on __the rules of broadcasting__."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T14:33:53.292214Z",
     "start_time": "2025-01-24T14:33:53.273059Z"
    },
    "id": "3da1324c2b6341b3",
    "outputId": "7519e3ca-367e-41e9-8655-449a78861861"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.4, 10.8, 16.2, 21.6],\n",
       "       [ 4.8,  9.6, 14.4, 19.2],\n",
       "       [ 4.8,  9.6, 14.4, 19.2],\n",
       "       [ 4.3,  8.6, 12.9, 17.2]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 4 into shape (4,4)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m c \u001B[38;5;241m*\u001B[39m d\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m#SOLUTION_END\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m \u001B[43mc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreshape\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mValueError\u001B[0m: cannot reshape array of size 4 into shape (4,4)"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "c * d\n",
    "#SOLUTION_END\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Rule 1:shape c (4,) becomes (1,4) to match the shape of d (4,1)\\\n",
    "Rule 2: c is stretched to (4,4). d (4,1) is stretched to (4,4) to match the shape of c.\\\n",
    "Rule 3: The two arrays are multiplied element-wise."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "i. For dataset a, normalize the data by calculating the z-score for each column. This way you can compare the columns of the dataset.\\\n",
    "*In case you don't remember, the formula for the z-score is: x-mean/std.*"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T12:31:30.634795600Z",
     "start_time": "2024-08-20T12:31:30.611526400Z"
    },
    "id": "206437c3e08645d5",
    "outputId": "f25465d6-a921-4ea4-d489-39273c971c34"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([5.471, 3.099, 2.861, 0.786])"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "array([5.1, 4.9, 4.7, 4.6, 5. , 5.4, 4.6, 5. , 4.4, 4.9, 5.4, 4.8, 4.8,\n       4.3, 5.8, 5.7, 5.4, 5.1, 5.7, 5.1, 5.4, 5.1, 4.6, 5.1, 4.8, 5. ,\n       5. , 5.2, 5.2, 4.7, 4.8, 5.4, 5.2, 5.5, 4.9, 5. , 5.5, 4.9, 4.4,\n       5.1, 5. , 4.5, 4.4, 5. , 5.1, 4.8, 5.1, 4.6, 5.3, 5. , 7. , 6.4,\n       6.9, 5.5, 6.5, 5.7, 6.3, 4.9, 6.6, 5.2, 5. , 5.9, 6. , 6.1, 5.6,\n       6.7, 5.6, 5.8, 6.2, 5.6, 5.9, 6.1, 6.3, 6.1, 6.4, 6.6, 6.8, 6.7,\n       6. , 5.7, 5.5, 5.5, 5.8, 6. , 5.4, 6. , 6.7, 6.3, 5.6, 5.5, 5.5,\n       6.1, 5.8, 5. , 5.6, 5.7, 5.7, 6.2, 5.1, 5.7])"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "array([[-5.81065904e-01,  8.41837140e-01, -1.01297765e+00,\n        -1.04211089e+00],\n       [-8.94308978e-01, -2.07835104e-01, -1.01297765e+00,\n        -1.04211089e+00],\n       [-1.20755205e+00,  2.12033793e-01, -1.08231219e+00,\n        -1.04211089e+00],\n       [-1.36417359e+00,  2.09934449e-03, -9.43643106e-01,\n        -1.04211089e+00],\n       [-7.37687441e-01,  1.05177159e+00, -1.01297765e+00,\n        -1.04211089e+00],\n       [-1.11201292e-01,  1.68157493e+00, -8.04974023e-01,\n        -6.86441647e-01],\n       [-1.36417359e+00,  6.31902691e-01, -1.01297765e+00,\n        -8.64276271e-01],\n       [-7.37687441e-01,  6.31902691e-01, -9.43643106e-01,\n        -1.04211089e+00],\n       [-1.67741667e+00, -4.17769553e-01, -1.01297765e+00,\n        -1.04211089e+00],\n       [-8.94308978e-01,  2.09934449e-03, -9.43643106e-01,\n        -1.21994552e+00],\n       [-1.11201292e-01,  1.26170604e+00, -9.43643106e-01,\n        -1.04211089e+00],\n       [-1.05093052e+00,  6.31902691e-01, -8.74308565e-01,\n        -1.04211089e+00],\n       [-1.05093052e+00, -2.07835104e-01, -1.01297765e+00,\n        -1.21994552e+00],\n       [-1.83403820e+00, -2.07835104e-01, -1.22098127e+00,\n        -1.21994552e+00],\n       [ 5.15284858e-01,  1.89150938e+00, -1.15164673e+00,\n        -1.04211089e+00],\n       [ 3.58663321e-01,  2.73124718e+00, -9.43643106e-01,\n        -6.86441647e-01],\n       [-1.11201292e-01,  1.68157493e+00, -1.08231219e+00,\n        -6.86441647e-01],\n       [-5.81065904e-01,  8.41837140e-01, -1.01297765e+00,\n        -8.64276271e-01],\n       [ 3.58663321e-01,  1.47164049e+00, -8.04974023e-01,\n        -8.64276271e-01],\n       [-5.81065904e-01,  1.47164049e+00, -9.43643106e-01,\n        -8.64276271e-01],\n       [-1.11201292e-01,  6.31902691e-01, -8.04974023e-01,\n        -1.04211089e+00],\n       [-5.81065904e-01,  1.26170604e+00, -9.43643106e-01,\n        -6.86441647e-01],\n       [-1.36417359e+00,  1.05177159e+00, -1.29031581e+00,\n        -1.04211089e+00],\n       [-5.81065904e-01,  4.21968242e-01, -8.04974023e-01,\n        -5.08607024e-01],\n       [-1.05093052e+00,  6.31902691e-01, -6.66304941e-01,\n        -1.04211089e+00],\n       [-7.37687441e-01, -2.07835104e-01, -8.74308565e-01,\n        -1.04211089e+00],\n       [-7.37687441e-01,  6.31902691e-01, -8.74308565e-01,\n        -6.86441647e-01],\n       [-4.24444366e-01,  8.41837140e-01, -9.43643106e-01,\n        -1.04211089e+00],\n       [-4.24444366e-01,  6.31902691e-01, -1.01297765e+00,\n        -1.04211089e+00],\n       [-1.20755205e+00,  2.12033793e-01, -8.74308565e-01,\n        -1.04211089e+00],\n       [-1.05093052e+00,  2.09934449e-03, -8.74308565e-01,\n        -1.04211089e+00],\n       [-1.11201292e-01,  6.31902691e-01, -9.43643106e-01,\n        -6.86441647e-01],\n       [-4.24444366e-01,  2.10144383e+00, -9.43643106e-01,\n        -1.21994552e+00],\n       [ 4.54202458e-02,  2.31137828e+00, -1.01297765e+00,\n        -1.04211089e+00],\n       [-8.94308978e-01,  2.09934449e-03, -9.43643106e-01,\n        -1.04211089e+00],\n       [-7.37687441e-01,  2.12033793e-01, -1.15164673e+00,\n        -1.04211089e+00],\n       [ 4.54202458e-02,  8.41837140e-01, -1.08231219e+00,\n        -1.04211089e+00],\n       [-8.94308978e-01,  1.05177159e+00, -1.01297765e+00,\n        -1.21994552e+00],\n       [-1.67741667e+00, -2.07835104e-01, -1.08231219e+00,\n        -1.04211089e+00],\n       [-5.81065904e-01,  6.31902691e-01, -9.43643106e-01,\n        -1.04211089e+00],\n       [-7.37687441e-01,  8.41837140e-01, -1.08231219e+00,\n        -8.64276271e-01],\n       [-1.52079513e+00, -1.67737625e+00, -1.08231219e+00,\n        -8.64276271e-01],\n       [-1.67741667e+00,  2.12033793e-01, -1.08231219e+00,\n        -1.04211089e+00],\n       [-7.37687441e-01,  8.41837140e-01, -8.74308565e-01,\n        -3.30772400e-01],\n       [-5.81065904e-01,  1.47164049e+00, -6.66304941e-01,\n        -6.86441647e-01],\n       [-1.05093052e+00, -2.07835104e-01, -1.01297765e+00,\n        -8.64276271e-01],\n       [-5.81065904e-01,  1.47164049e+00, -8.74308565e-01,\n        -1.04211089e+00],\n       [-1.36417359e+00,  2.12033793e-01, -1.01297765e+00,\n        -1.04211089e+00],\n       [-2.67822829e-01,  1.26170604e+00, -9.43643106e-01,\n        -1.04211089e+00],\n       [-7.37687441e-01,  4.21968242e-01, -1.01297765e+00,\n        -1.04211089e+00],\n       [ 2.39474331e+00,  2.12033793e-01,  1.27506221e+00,\n         1.09190459e+00],\n       [ 1.45501408e+00,  2.12033793e-01,  1.13639313e+00,\n         1.26973921e+00],\n       [ 2.23812177e+00,  2.09934449e-03,  1.41373130e+00,\n         1.26973921e+00],\n       [ 4.54202458e-02, -1.67737625e+00,  7.89720424e-01,\n         9.14069966e-01],\n       [ 1.61163562e+00, -6.27704002e-01,  1.20572767e+00,\n         1.26973921e+00],\n       [ 3.58663321e-01, -6.27704002e-01,  1.13639313e+00,\n         9.14069966e-01],\n       [ 1.29839254e+00,  4.21968242e-01,  1.27506221e+00,\n         1.44757384e+00],\n       [-8.94308978e-01, -1.46744180e+00,  3.04378636e-01,\n         3.80566095e-01],\n       [ 1.76825716e+00, -4.17769553e-01,  1.20572767e+00,\n         9.14069966e-01],\n       [-4.24444366e-01, -8.37638451e-01,  7.20385883e-01,\n         1.09190459e+00],\n       [-7.37687441e-01, -2.30717959e+00,  4.43047718e-01,\n         3.80566095e-01],\n       [ 6.71906395e-01, -2.07835104e-01,  9.28389507e-01,\n         1.26973921e+00],\n       [ 8.28527933e-01, -1.88731069e+00,  7.89720424e-01,\n         3.80566095e-01],\n       [ 9.85149470e-01, -4.17769553e-01,  1.27506221e+00,\n         1.09190459e+00],\n       [ 2.02041783e-01, -4.17769553e-01,  5.12382260e-01,\n         9.14069966e-01],\n       [ 1.92487869e+00,  2.09934449e-03,  1.06705859e+00,\n         1.09190459e+00],\n       [ 2.02041783e-01, -2.07835104e-01,  1.13639313e+00,\n         1.26973921e+00],\n       [ 5.15284858e-01, -8.37638451e-01,  8.59054966e-01,\n         3.80566095e-01],\n       [ 1.14177101e+00, -1.88731069e+00,  1.13639313e+00,\n         1.26973921e+00],\n       [ 2.02041783e-01, -1.25750735e+00,  7.20385883e-01,\n         5.58400718e-01],\n       [ 6.71906395e-01,  2.12033793e-01,  1.34439675e+00,\n         1.80324308e+00],\n       [ 9.85149470e-01, -6.27704002e-01,  7.89720424e-01,\n         9.14069966e-01],\n       [ 1.29839254e+00, -1.25750735e+00,  1.41373130e+00,\n         1.26973921e+00],\n       [ 9.85149470e-01, -6.27704002e-01,  1.27506221e+00,\n         7.36235342e-01],\n       [ 1.45501408e+00, -4.17769553e-01,  9.97724048e-01,\n         9.14069966e-01],\n       [ 1.76825716e+00, -2.07835104e-01,  1.06705859e+00,\n         1.09190459e+00],\n       [ 2.08150023e+00, -6.27704002e-01,  1.34439675e+00,\n         1.09190459e+00],\n       [ 1.92487869e+00, -2.07835104e-01,  1.48306584e+00,\n         1.62540846e+00],\n       [ 8.28527933e-01, -4.17769553e-01,  1.13639313e+00,\n         1.26973921e+00],\n       [ 3.58663321e-01, -1.04757290e+00,  4.43047718e-01,\n         3.80566095e-01],\n       [ 4.54202458e-02, -1.46744180e+00,  6.51051342e-01,\n         5.58400718e-01],\n       [ 4.54202458e-02, -1.46744180e+00,  5.81716801e-01,\n         3.80566095e-01],\n       [ 5.15284858e-01, -8.37638451e-01,  7.20385883e-01,\n         7.36235342e-01],\n       [ 8.28527933e-01, -8.37638451e-01,  1.55240038e+00,\n         1.44757384e+00],\n       [-1.11201292e-01, -2.07835104e-01,  1.13639313e+00,\n         1.26973921e+00],\n       [ 8.28527933e-01,  6.31902691e-01,  1.13639313e+00,\n         1.44757384e+00],\n       [ 1.92487869e+00,  2.09934449e-03,  1.27506221e+00,\n         1.26973921e+00],\n       [ 1.29839254e+00, -1.67737625e+00,  1.06705859e+00,\n         9.14069966e-01],\n       [ 2.02041783e-01, -2.07835104e-01,  8.59054966e-01,\n         9.14069966e-01],\n       [ 4.54202458e-02, -1.25750735e+00,  7.89720424e-01,\n         9.14069966e-01],\n       [ 4.54202458e-02, -1.04757290e+00,  1.06705859e+00,\n         7.36235342e-01],\n       [ 9.85149470e-01, -2.07835104e-01,  1.20572767e+00,\n         1.09190459e+00],\n       [ 5.15284858e-01, -1.04757290e+00,  7.89720424e-01,\n         7.36235342e-01],\n       [-7.37687441e-01, -1.67737625e+00,  3.04378636e-01,\n         3.80566095e-01],\n       [ 2.02041783e-01, -8.37638451e-01,  9.28389507e-01,\n         9.14069966e-01],\n       [ 3.58663321e-01, -2.07835104e-01,  9.28389507e-01,\n         7.36235342e-01],\n       [ 3.58663321e-01, -4.17769553e-01,  9.28389507e-01,\n         9.14069966e-01],\n       [ 1.14177101e+00, -4.17769553e-01,  9.97724048e-01,\n         9.14069966e-01],\n       [-5.81065904e-01, -1.25750735e+00,  9.63750123e-02,\n         5.58400718e-01],\n       [ 3.58663321e-01, -6.27704002e-01,  8.59054966e-01,\n         9.14069966e-01]])"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "(a - a.mean(axis=0)) / a.std(axis=0)\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<!--BOOK_INFORMATION-->\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"figures/PDSH-cover-small.png\">\n",
    "\n",
    "*This notebook contains an excerpt from the [Python Data Science Handbook](http://shop.oreilly.com/product/0636920034919.do) by Jake VanderPlas; the content is available [on GitHub](https://github.com/jakevdp/PythonDataScienceHandbook).*\n",
    "\n",
    "*The text is released under the [CC-BY-NC-ND license](https://creativecommons.org/licenses/by-nc-nd/3.0/us/legalcode), and code is released under the [MIT license](https://opensource.org/licenses/MIT). If you find this content useful, please consider supporting the work by [buying the book](http://shop.oreilly.com/product/0636920034919.do)!*"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<!--NAVIGATION-->\n",
    "< [Computation on Arrays: Broadcasting](02.05-Computation-on-arrays-broadcasting.ipynb) | [Contents](Index.ipynb) | [Fancy Indexing](02.07-Fancy-Indexing.ipynb) >\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/02.06-Boolean-Arrays-and-Masks.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Comparisons, Masks, and Boolean Logic"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This section covers the use of Boolean masks to examine and manipulate values within NumPy arrays.\n",
    "Masking comes up when you want to extract, modify, count, or otherwise manipulate values in an array based on some criterion: for example, you might wish to count all values greater than a certain value, or perhaps remove all outliers that are above some threshold.\n",
    "In NumPy, Boolean masking is often the most efficient way to accomplish these types of tasks."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Example: Counting Rainy Days\n",
    "\n",
    "Imagine you have a series of data that represents the amount of precipitation each day for a year in a given city.\n",
    "For example, here we'll load the daily rainfall statistics for the city of Seattle in 2014, using Pandas (which is covered in more detail in [Chapter 3](03.00-Introduction-to-Pandas.ipynb)):"
   ]
  },
  {
   "metadata": {
    "id": "A47bonV8GzZK",
    "outputId": "89c7f2b7-9454-4fda-9d08-3a9b8ffc8b59"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(365,)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# use pandas to extract rainfall inches as a NumPy array\n",
    "rainfall = pd.read_csv('data/Seattle2014.csv')['PRCP'].values\n",
    "inches = rainfall / 254.0  # 1/10mm -> inches\n",
    "inches.shape"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The array contains 365 values, giving daily rainfall in inches from January 1 to December 31, 2014.\n",
    "\n",
    "As a first quick visualization, let's look at the histogram of rainy days, which was generated using Matplotlib (we will explore this tool more fully in [Chapter 4](DS2-4NotebooksWithSolutions.ipynb)):"
   ]
  },
  {
   "metadata": {
    "id": "GDDYmGr1GzZO"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn; seaborn.set()  # set plot styles"
   ]
  },
  {
   "metadata": {
    "id": "hdiqTq7RGzZP",
    "outputId": "80de27fe-ae4a-4c25-ec73-e6fd49b54af3"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAesAAAFVCAYAAADPM8ekAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nngAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b617a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": null,
   "source": "plt.hist(inches, 40);"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This histogram gives us a general idea of what the data looks like: despite its reputation, the vast majority of days in Seattle saw near zero measured rainfall in 2014.\n",
    "But this doesn't do a good job of conveying some information we'd like to see: for example, how many rainy days were there in the year? What is the average precipitation on those rainy days? How many days were there with more than half an inch of rain?"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Digging into the data\n",
    "\n",
    "One approach to this would be to answer these questions by hand: loop through the data, incrementing a counter each time we see values in some desired range.\n",
    "For reasons discussed throughout this chapter, such an approach is very inefficient, both from the standpoint of time writing code and time computing the result.\n",
    "We saw in [Computation on NumPy Arrays: Universal Functions](02.03-Computation-on-arrays-ufuncs.ipynb) that NumPy's ufuncs can be used in place of loops to do fast element-wise arithmetic operations on arrays; in the same way, we can use other ufuncs to do element-wise *comparisons* over arrays, and we can then manipulate the results to answer the questions we have.\n",
    "We'll leave the data aside for right now, and discuss some general tools in NumPy to use *masking* to quickly answer these types of questions."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Comparison Operators as ufuncs\n",
    "\n",
    "In [Computation on NumPy Arrays: Universal Functions](02.03-Computation-on-arrays-ufuncs.ipynb) we introduced ufuncs, and focused in particular on arithmetic operators. We saw that using ``+``, ``-``, ``*``, ``/``, and others on arrays leads to element-wise operations.\n",
    "NumPy also implements comparison operators such as ``<`` (less than) and ``>`` (greater than) as element-wise ufuncs.\n",
    "The result of these comparison operators is always an array with a Boolean data type.\n",
    "All six of the standard comparison operations are available:"
   ]
  },
  {
   "metadata": {
    "collapsed": true,
    "id": "y37Nk8nIGzZW"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "x = np.array([1, 2, 3, 4, 5])"
  },
  {
   "metadata": {
    "id": "Swl8TlFXGzZY",
    "outputId": "fc502499-a70a-478d-b100-ab3b0b0884c3"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False, False, False], dtype=bool)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "x < 3  # less than"
  },
  {
   "metadata": {
    "id": "iWb_dAHPGzZZ",
    "outputId": "24e0d43d-2ff4-4171-fa99-e6a94d8efb21"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False,  True,  True], dtype=bool)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "x > 3  # greater than"
  },
  {
   "metadata": {
    "id": "J5gxAd9EGzZa",
    "outputId": "4e3757da-ae1c-46d4-d066-41e3a5aad97c"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, False, False], dtype=bool)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "x <= 3  # less than or equal"
  },
  {
   "metadata": {
    "id": "tCKeLJlKGzZb",
    "outputId": "75c68969-84e5-4da3-85f0-c08a7cbea8cd"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False,  True,  True,  True], dtype=bool)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "x >= 3  # greater than or equal"
  },
  {
   "metadata": {
    "id": "JvWDUvvoGzZd",
    "outputId": "2979c086-2638-492c-9132-087af462626c"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False,  True,  True], dtype=bool)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "x != 3  # not equal"
  },
  {
   "metadata": {
    "id": "cnLV3XyHGzZe",
    "outputId": "8d9d72d5-ac32-42f9-e325-37700bd65b31"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False,  True, False, False], dtype=bool)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "x == 3  # equal"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "It is also possible to do an element-wise comparison of two arrays, and to include compound expressions:"
  },
  {
   "metadata": {
    "id": "Y1NgHhL-GzZh",
    "outputId": "0b1a00d5-6417-4e51-d573-487060cdd418"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False, False, False], dtype=bool)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "(2 * x) == (x ** 2)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "As in the case of arithmetic operators, the comparison operators are implemented as ufuncs in NumPy; for example, when you write ``x < 3``, internally NumPy uses ``np.less(x, 3)``.\n",
    "    A summary of the comparison operators and their equivalent ufunc is shown here:\n",
    "\n",
    "| Operator\t    | Equivalent ufunc    || Operator\t   | Equivalent ufunc    |\n",
    "|---------------|---------------------||---------------|---------------------|\n",
    "|``==``         |``np.equal``         ||``!=``         |``np.not_equal``     |\n",
    "|``<``          |``np.less``          ||``<=``         |``np.less_equal``    |\n",
    "|``>``          |``np.greater``       ||``>=``         |``np.greater_equal`` |"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Just as in the case of arithmetic ufuncs, these will work on arrays of any size and shape.\n",
    "Here is a two-dimensional example:"
   ]
  },
  {
   "metadata": {
    "id": "tWef3I6cGzZj",
    "outputId": "315bf7c7-7023-4ba7-a077-80d78398be55"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 0, 3, 3],\n",
       "       [7, 9, 3, 5],\n",
       "       [2, 4, 7, 6]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "rng = np.random.RandomState(0)\n",
    "x = rng.randint(10, size=(3, 4))\n",
    "x"
   ]
  },
  {
   "metadata": {
    "id": "lXAHAzrHGzZk",
    "outputId": "72fa173b-c133-43c4-c29c-5044cf537993"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True],\n",
       "       [False, False,  True,  True],\n",
       "       [ True,  True, False, False]], dtype=bool)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "x < 6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In each case, the result is a Boolean array, and NumPy provides a number of straightforward patterns for working with these Boolean results."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Working with Boolean Arrays\n",
    "\n",
    "Given a Boolean array, there are a host of useful operations you can do.\n",
    "We'll work with ``x``, the two-dimensional array we created earlier."
   ]
  },
  {
   "metadata": {
    "id": "tHe8UbLwGzZm",
    "outputId": "f3491a82-a7f6-4cdb-d1a9-f92222a17874"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 0 3 3]\n",
      " [7 9 3 5]\n",
      " [2 4 7 6]]\n"
     ]
    }
   ],
   "execution_count": null,
   "source": "print(x)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Counting entries\n",
    "\n",
    "To count the number of ``True`` entries in a Boolean array, ``np.count_nonzero`` is useful:"
   ]
  },
  {
   "metadata": {
    "id": "aAN7bpCVGzZo",
    "outputId": "a1193d47-65a6-48cc-827c-6a89add70eb7"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "# how many values less than 6?\n",
    "np.count_nonzero(x < 6)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We see that there are eight array entries that are less than 6.\n",
    "Another way to get at this information is to use ``np.sum``; in this case, ``False`` is interpreted as ``0``, and ``True`` is interpreted as ``1``:"
   ]
  },
  {
   "metadata": {
    "id": "2St5Q1iCGzZr",
    "outputId": "0c087f22-088d-4ec8-c364-6ac05dc235d0"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "np.sum(x < 6)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The benefit of ``sum()`` is that like with other NumPy aggregation functions, this summation can be done along rows or columns as well:"
  },
  {
   "metadata": {
    "id": "tJPXF4htGzZv",
    "outputId": "3ce57d69-ce0c-4f2f-fd1b-6b561d14b4e4"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 2, 2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "# how many values less than 6 in each row?\n",
    "np.sum(x < 6, axis=1)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This counts the number of values less than 6 in each row of the matrix.\n",
    "\n",
    "If we're interested in quickly checking whether any or all the values are true, we can use (you guessed it) ``np.any`` or ``np.all``:"
   ]
  },
  {
   "metadata": {
    "id": "2yN_Yhs6GzZw",
    "outputId": "f06f92de-e9cf-4fe1-fff8-746cc4dd81c7"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "# are there any values greater than 8?\n",
    "np.any(x > 8)"
   ]
  },
  {
   "metadata": {
    "id": "hTwqiuo4GzZx",
    "outputId": "6d3ce797-d76a-479c-ae61-d19577dc12e3"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "# are there any values less than zero?\n",
    "np.any(x < 0)"
   ]
  },
  {
   "metadata": {
    "id": "vdkhmpSFGzZy",
    "outputId": "baaf68f9-7320-4f06-faa8-432d50416c52"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "# are all values less than 10?\n",
    "np.all(x < 10)"
   ]
  },
  {
   "metadata": {
    "id": "nI73oBSlGzZz",
    "outputId": "677cd2a9-e05c-4292-e41e-e82b2a3a2ab2"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "# are all values equal to 6?\n",
    "np.all(x == 6)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "``np.all`` and ``np.any`` can be used along particular axes as well. For example:"
  },
  {
   "metadata": {
    "id": "wxQt0vfqGzZ2",
    "outputId": "712f6253-8c90-4982-aa8b-440924a3625c"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True], dtype=bool)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "# are all values in each row less than 8?\n",
    "np.all(x < 8, axis=1)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Here all the elements in the first and third rows are less than 8, while this is not the case for the second row.\n",
    "\n",
    "Finally, a quick warning: as mentioned in [Aggregations: Min, Max, and Everything In Between](02.04-Computation-on-arrays-aggregates.ipynb), Python has built-in ``sum()``, ``any()``, and ``all()`` functions. These have a different syntax than the NumPy versions, and in particular will fail or produce unintended results when used on multidimensional arrays. Be sure that you are using ``np.sum()``, ``np.any()``, and ``np.all()`` for these examples!"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Boolean operators\n",
    "\n",
    "We've already seen how we might count, say, all days with rain less than four inches, or all days with rain greater than two inches.\n",
    "But what if we want to know about all days with rain less than four inches and greater than one inch?\n",
    "This is accomplished through Python's *bitwise logic operators*, ``&``, ``|``, ``^``, and ``~``.\n",
    "Like with the standard arithmetic operators, NumPy overloads these as ufuncs which work element-wise on (usually Boolean) arrays.\n",
    "\n",
    "For example, we can address this sort of compound question as follows:"
   ]
  },
  {
   "metadata": {
    "id": "HWq1DufyGzZ4",
    "outputId": "cc43d35e-48ce-4592-bf37-1271bca82358"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "np.sum((inches > 0.5) & (inches < 1))"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "So we see that there are 29 days with rainfall between 0.5 and 1.0 inches.\n",
    "\n",
    "Note that the parentheses here are important–because of operator precedence rules, with parentheses removed this expression would be evaluated as follows, which results in an error:\n",
    "\n",
    "``` python\n",
    "inches > (0.5 & inches) < 1\n",
    "```\n",
    "\n",
    "Using the equivalence of *A AND B* and *NOT (NOT A OR NOT B)* (which you may remember if you've taken an introductory logic course), we can compute the same result in a different manner:"
   ]
  },
  {
   "metadata": {
    "id": "_h9AQQ3AGzZ6",
    "outputId": "58f1257c-c5bc-454c-a678-fbf090ce7109"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "np.sum(~( (inches <= 0.5) | (inches >= 1) ))"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Combining comparison operators and Boolean operators on arrays can lead to a wide range of efficient logical operations.\n",
    "\n",
    "The following table summarizes the bitwise Boolean operators and their equivalent ufuncs:"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "| Operator\t    | Equivalent ufunc    || Operator\t    | Equivalent ufunc    |\n",
    "|---------------|---------------------||---------------|---------------------|\n",
    "|``&``          |``np.bitwise_and``   ||&#124;         |``np.bitwise_or``    |\n",
    "|``^``          |``np.bitwise_xor``   ||``~``          |``np.bitwise_not``   |"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Using these tools, we might start to answer the types of questions we have about our weather data.\n",
    "Here are some examples of results we can compute when combining masking with aggregations:"
   ]
  },
  {
   "metadata": {
    "id": "Hx2d1crFGzZ7",
    "outputId": "bd79fcdb-ed35-4cc3-bfe4-4217ee8bac07"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number days without rain:       215\n",
      "Number days with rain:          150\n",
      "Days with more than 0.5 inches: 37\n",
      "Rainy days with < 0.2 inches  : 75\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "print(\"Number days without rain:      \", np.sum(inches == 0))\n",
    "print(\"Number days with rain:         \", np.sum(inches != 0))\n",
    "print(\"Days with more than 0.5 inches:\", np.sum(inches > 0.5))\n",
    "print(\"Rainy days with < 0.2 inches  :\", np.sum((inches > 0) &\n",
    "                                                (inches < 0.2)))"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Boolean Arrays as Masks\n",
    "\n",
    "In the preceding section we looked at aggregates computed directly on Boolean arrays.\n",
    "A more powerful pattern is to use Boolean arrays as masks, to select particular subsets of the data themselves.\n",
    "Returning to our ``x`` array from before, suppose we want an array of all values in the array that are less than, say, 5:"
   ]
  },
  {
   "metadata": {
    "id": "bEZTpNv9GzZ9",
    "outputId": "ded92e11-487b-4635-8645-887481f8d934"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 0, 3, 3],\n",
       "       [7, 9, 3, 5],\n",
       "       [2, 4, 7, 6]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "x"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can obtain a Boolean array for this condition easily, as we've already seen:"
  },
  {
   "metadata": {
    "id": "_zhBAKMmGzZ-",
    "outputId": "d127ece4-56cd-4ff1-fea9-2f64bda687e3"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False,  True,  True,  True],\n",
       "       [False, False,  True, False],\n",
       "       [ True,  True, False, False]], dtype=bool)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "x < 5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now to *select* these values from the array, we can simply index on this Boolean array; this is known as a *masking* operation:"
  },
  {
   "metadata": {
    "id": "_4ED2Z6JGzZ-",
    "outputId": "092b9b10-9d72-45ea-88e7-a228df633545"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 3, 3, 2, 4])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "x[x < 5]"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "What is returned is a one-dimensional array filled with all the values that meet this condition; in other words, all the values in positions at which the mask array is ``True``.\n",
    "\n",
    "We are then free to operate on these values as we wish.\n",
    "For example, we can compute some relevant statistics on our Seattle rain data:"
   ]
  },
  {
   "metadata": {
    "id": "6pkDO20SGzZ_",
    "outputId": "64e8f891-e6b3-4f3d-f5cd-6274908eebe7"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median precip on rainy days in 2014 (inches):    0.194881889764\n",
      "Median precip on summer days in 2014 (inches):   0.0\n",
      "Maximum precip on summer days in 2014 (inches):  0.850393700787\n",
      "Median precip on non-summer rainy days (inches): 0.200787401575\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "# construct a mask of all rainy days\n",
    "rainy = (inches > 0)\n",
    "\n",
    "# construct a mask of all summer days (June 21st is the 172nd day)\n",
    "days = np.arange(365)\n",
    "summer = (days > 172) & (days < 262)\n",
    "\n",
    "print(\"Median precip on rainy days in 2014 (inches):   \",\n",
    "      np.median(inches[rainy]))\n",
    "print(\"Median precip on summer days in 2014 (inches):  \",\n",
    "      np.median(inches[summer]))\n",
    "print(\"Maximum precip on summer days in 2014 (inches): \",\n",
    "      np.max(inches[summer]))\n",
    "print(\"Median precip on non-summer rainy days (inches):\",\n",
    "      np.median(inches[rainy & ~summer]))"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "By combining Boolean operations, masking operations, and aggregates, we can very quickly answer these sorts of questions for our dataset."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Aside: Using the Keywords and/or Versus the Operators &/|\n",
    "\n",
    "One common point of confusion is the difference between the keywords ``and`` and ``or`` on one hand, and the operators ``&`` and ``|`` on the other hand.\n",
    "When would you use one versus the other?\n",
    "\n",
    "The difference is this: ``and`` and ``or`` gauge the truth or falsehood of *entire object*, while ``&`` and ``|`` refer to *bits within each object*.\n",
    "\n",
    "When you use ``and`` or ``or``, it's equivalent to asking Python to treat the object as a single Boolean entity.\n",
    "In Python, all nonzero integers will evaluate as True. Thus:"
   ]
  },
  {
   "metadata": {
    "id": "jvHNcbakGzaA",
    "outputId": "8ea6d57d-b168-43d1-e587-20e12f881c8f"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "bool(42), bool(0)"
  },
  {
   "metadata": {
    "id": "gSUJklm-GzaB",
    "outputId": "b1af7a94-120f-4049-d4ec-f8548d4a1638"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "bool(42 and 0)"
  },
  {
   "metadata": {
    "id": "NPa3tp1HGzaB",
    "outputId": "b22e7a77-0071-48b2-d76a-475f972a6fab"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "bool(42 or 0)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "When you use ``&`` and ``|`` on integers, the expression operates on the bits of the element, applying the *and* or the *or* to the individual bits making up the number:"
  },
  {
   "metadata": {
    "id": "NtOv6v5aGzaC",
    "outputId": "94ee8f1a-9868-4b66-b6f1-41c917ee7aaf"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0b101010'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "bin(42)"
  },
  {
   "metadata": {
    "id": "WGlPfj_bGzaC",
    "outputId": "a7c82b07-5efb-4d53-dbb5-3d68bccdf255"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0b111011'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "bin(59)"
  },
  {
   "metadata": {
    "id": "2fLSJ_PDGzaC",
    "outputId": "bc307e35-5890-45c2-f77a-4ff5e2727b49"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0b101010'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "bin(42 & 59)"
  },
  {
   "metadata": {
    "id": "nHUnYzQnGzaD",
    "outputId": "2833e70e-c7ba-4dfa-ae07-8a2bcb0d0461"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0b111011'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "bin(42 | 59)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Notice that the corresponding bits of the binary representation are compared in order to yield the result.\n",
    "\n",
    "When you have an array of Boolean values in NumPy, this can be thought of as a string of bits where ``1 = True`` and ``0 = False``, and the result of ``&`` and ``|`` operates similarly to above:"
   ]
  },
  {
   "metadata": {
    "id": "UwSPSO7MGzaE",
    "outputId": "963b22a6-f20b-4c5c-e271-b141c80fb26e"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, False,  True,  True], dtype=bool)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "A = np.array([1, 0, 1, 0, 1, 0], dtype=bool)\n",
    "B = np.array([1, 1, 1, 0, 1, 1], dtype=bool)\n",
    "A | B"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Using ``or`` on these arrays will try to evaluate the truth or falsehood of the entire array object, which is not a well-defined value:"
  },
  {
   "metadata": {
    "id": "c2DqJ1XXGzaE",
    "outputId": "41e54375-7898-45f3-f1c4-665b50b6f53e"
   },
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-38-5d8e4f2e21c0>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mA\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mB\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "execution_count": null,
   "source": "A or B"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Similarly, when doing a Boolean expression on a given array, you should use ``|`` or ``&`` rather than ``or`` or ``and``:"
  },
  {
   "metadata": {
    "id": "w36hIkeoGzaF",
    "outputId": "3cd675e2-7fc6-41a5-8fa7-02bcc85823f0"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False,  True,  True,  True, False, False], dtype=bool)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "x = np.arange(10)\n",
    "(x > 4) & (x < 8)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Trying to evaluate the truth or falsehood of the entire array will give the same ``ValueError`` we saw previously:"
  },
  {
   "metadata": {
    "id": "i2FgfA-uGzaG",
    "outputId": "f653f1e7-d7dc-4c7a-eec2-e275719c915b"
   },
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-40-3d24f1ffd63d>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m4\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m \u001B[0;34m<\u001B[0m \u001B[0;36m8\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "execution_count": null,
   "source": "(x > 4) and (x < 8)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "So remember this: ``and`` and ``or`` perform a single Boolean evaluation on an entire object, while ``&`` and ``|`` perform multiple Boolean evaluations on the content (the individual bits or bytes) of an object.\n",
    "For Boolean NumPy arrays, the latter is nearly always the desired operation."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<!--NAVIGATION-->\n",
    "< [Computation on Arrays: Broadcasting](02.05-Computation-on-arrays-broadcasting.ipynb) | [Contents](Index.ipynb) | [Fancy Indexing](02.07-Fancy-Indexing.ipynb) >\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/02.06-Boolean-Arrays-and-Masks.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>\n"
   ]
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-24T12:34:32.329719Z",
     "start_time": "2025-01-24T12:34:30.881827Z"
    },
    "id": "initial_id",
    "outputId": "4a83b7be-38f3-46ba-e1a3-cb5a3e219119"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _wine_dataset:\n",
      "\n",
      "Wine recognition dataset\n",
      "------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      ":Number of Instances: 178\n",
      ":Number of Attributes: 13 numeric, predictive attributes and the class\n",
      ":Attribute Information:\n",
      "    - Alcohol\n",
      "    - Malic acid\n",
      "    - Ash\n",
      "    - Alcalinity of ash\n",
      "    - Magnesium\n",
      "    - Total phenols\n",
      "    - Flavanoids\n",
      "    - Nonflavanoid phenols\n",
      "    - Proanthocyanins\n",
      "    - Color intensity\n",
      "    - Hue\n",
      "    - OD280/OD315 of diluted wines\n",
      "    - Proline\n",
      "    - class:\n",
      "        - class_0\n",
      "        - class_1\n",
      "        - class_2\n",
      "\n",
      ":Summary Statistics:\n",
      "\n",
      "============================= ==== ===== ======= =====\n",
      "                                Min   Max   Mean     SD\n",
      "============================= ==== ===== ======= =====\n",
      "Alcohol:                      11.0  14.8    13.0   0.8\n",
      "Malic Acid:                   0.74  5.80    2.34  1.12\n",
      "Ash:                          1.36  3.23    2.36  0.27\n",
      "Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
      "Magnesium:                    70.0 162.0    99.7  14.3\n",
      "Total Phenols:                0.98  3.88    2.29  0.63\n",
      "Flavanoids:                   0.34  5.08    2.03  1.00\n",
      "Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
      "Proanthocyanins:              0.41  3.58    1.59  0.57\n",
      "Colour Intensity:              1.3  13.0     5.1   2.3\n",
      "Hue:                          0.48  1.71    0.96  0.23\n",
      "OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
      "Proline:                       278  1680     746   315\n",
      "============================= ==== ===== ======= =====\n",
      "\n",
      ":Missing Attribute Values: None\n",
      ":Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
      ":Creator: R.A. Fisher\n",
      ":Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      ":Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML Wine recognition datasets.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
      "\n",
      "The data is the results of a chemical analysis of wines grown in the same\n",
      "region in Italy by three different cultivators. There are thirteen different\n",
      "measurements taken for different constituents found in the three types of\n",
      "wine.\n",
      "\n",
      "Original Owners:\n",
      "\n",
      "Forina, M. et al, PARVUS -\n",
      "An Extendible Package for Data Exploration, Classification and Correlation.\n",
      "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
      "Via Brigata Salerno, 16147 Genoa, Italy.\n",
      "\n",
      "Citation:\n",
      "\n",
      "Lichman, M. (2013). UCI Machine Learning Repository\n",
      "[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
      "School of Information and Computer Science.\n",
      "\n",
      ".. dropdown:: References\n",
      "\n",
      "    (1) S. Aeberhard, D. Coomans and O. de Vel,\n",
      "    Comparison of Classifiers in High Dimensional Settings,\n",
      "    Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of\n",
      "    Mathematics and Statistics, James Cook University of North Queensland.\n",
      "    (Also submitted to Technometrics).\n",
      "\n",
      "    The data was used with many others for comparing various\n",
      "    classifiers. The classes are separable, though only RDA\n",
      "    has achieved 100% correct classification.\n",
      "    (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data))\n",
      "    (All results using the leave-one-out technique)\n",
      "\n",
      "    (2) S. Aeberhard, D. Coomans and O. de Vel,\n",
      "    \"THE CLASSIFICATION PERFORMANCE OF RDA\"\n",
      "    Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of\n",
      "    Mathematics and Statistics, James Cook University of North Queensland.\n",
      "    (Also submitted to Journal of Chemometrics).\n",
      "\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import sklearn.datasets as ds\n",
    "import numpy as np\n",
    "wine_x= np.array(ds.load_wine().data)\n",
    "wine_y= np.array(ds.load_wine().target)\n",
    "descr= ds.load_wine().DESCR\n",
    "print(descr)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "When running the first cell you are provided with a description of the wine dataset included in de sklearn Python module. Go through the description and complete the following tasks:\\\n",
    "The features (independent variables) are stored in the array wine_x. The target wineclass (dependent variable) is stored in the array wine_y.\\\n",
    "## 1. Boolean Arrays and Masks\n",
    "a. You want to know which of the wines are the best quality. Print a boolean array that shows whether the wineclass equals 2 in wine_y.\\\n",
    "b. Check with one statement whether column 5 (index 4) of wine_x has values above 160, also check for 170. The result has to be one boolean value.\\\n",
    "c. All values of column 5 should lie between 70 and 170. Check this with one statement. The result has to be one boolean value. If you get \"false\" check with the min and max functions which value is causing the problem.\\\n",
    "d. Now give a boolean array that shows whether the wineclass equals 0 or 2 in wine_y.\\\n",
    "e. Show all rows of wine_x where the first column of wine_x is greater than 14.\\\n",
    "f. Show all rows of wine_x where the class of the wine equals 2.\\\n",
    "g. Show all rows of wine_x where column 2 is less than 1 and the class of the wine equals 1\\\n",
    "h. Change all values in column 0 of wine_x that are higher than 13 to the nearest integer.\\"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T12:34:32.426021Z",
     "start_time": "2025-01-24T12:34:32.402161Z"
    },
    "id": "fa06ba0aea60b378",
    "outputId": "3425c840-34da-41ef-d658-d593ec203a02"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True]\n",
      "b:\n",
      "True\n",
      "c:\n",
      "False\n",
      "The minimum of column 5 is 70.0, the maximum of column 5 is 162.0\n",
      "d:\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True]\n",
      "e:\n",
      "[[1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n",
      "  2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03]\n",
      " [1.437e+01 1.950e+00 2.500e+00 1.680e+01 1.130e+02 3.850e+00 3.490e+00\n",
      "  2.400e-01 2.180e+00 7.800e+00 8.600e-01 3.450e+00 1.480e+03]\n",
      " [1.420e+01 1.760e+00 2.450e+00 1.520e+01 1.120e+02 3.270e+00 3.390e+00\n",
      "  3.400e-01 1.970e+00 6.750e+00 1.050e+00 2.850e+00 1.450e+03]\n",
      " [1.439e+01 1.870e+00 2.450e+00 1.460e+01 9.600e+01 2.500e+00 2.520e+00\n",
      "  3.000e-01 1.980e+00 5.250e+00 1.020e+00 3.580e+00 1.290e+03]\n",
      " [1.406e+01 2.150e+00 2.610e+00 1.760e+01 1.210e+02 2.600e+00 2.510e+00\n",
      "  3.100e-01 1.250e+00 5.050e+00 1.060e+00 3.580e+00 1.295e+03]\n",
      " [1.483e+01 1.640e+00 2.170e+00 1.400e+01 9.700e+01 2.800e+00 2.980e+00\n",
      "  2.900e-01 1.980e+00 5.200e+00 1.080e+00 2.850e+00 1.045e+03]\n",
      " [1.410e+01 2.160e+00 2.300e+00 1.800e+01 1.050e+02 2.950e+00 3.320e+00\n",
      "  2.200e-01 2.380e+00 5.750e+00 1.250e+00 3.170e+00 1.510e+03]\n",
      " [1.412e+01 1.480e+00 2.320e+00 1.680e+01 9.500e+01 2.200e+00 2.430e+00\n",
      "  2.600e-01 1.570e+00 5.000e+00 1.170e+00 2.820e+00 1.280e+03]\n",
      " [1.475e+01 1.730e+00 2.390e+00 1.140e+01 9.100e+01 3.100e+00 3.690e+00\n",
      "  4.300e-01 2.810e+00 5.400e+00 1.250e+00 2.730e+00 1.150e+03]\n",
      " [1.438e+01 1.870e+00 2.380e+00 1.200e+01 1.020e+02 3.300e+00 3.640e+00\n",
      "  2.900e-01 2.960e+00 7.500e+00 1.200e+00 3.000e+00 1.547e+03]\n",
      " [1.430e+01 1.920e+00 2.720e+00 2.000e+01 1.200e+02 2.800e+00 3.140e+00\n",
      "  3.300e-01 1.970e+00 6.200e+00 1.070e+00 2.650e+00 1.280e+03]\n",
      " [1.419e+01 1.590e+00 2.480e+00 1.650e+01 1.080e+02 3.300e+00 3.930e+00\n",
      "  3.200e-01 1.860e+00 8.700e+00 1.230e+00 2.820e+00 1.680e+03]\n",
      " [1.406e+01 1.630e+00 2.280e+00 1.600e+01 1.260e+02 3.000e+00 3.170e+00\n",
      "  2.400e-01 2.100e+00 5.650e+00 1.090e+00 3.710e+00 7.800e+02]\n",
      " [1.402e+01 1.680e+00 2.210e+00 1.600e+01 9.600e+01 2.650e+00 2.330e+00\n",
      "  2.600e-01 1.980e+00 4.700e+00 1.040e+00 3.590e+00 1.035e+03]\n",
      " [1.422e+01 3.990e+00 2.510e+00 1.320e+01 1.280e+02 3.000e+00 3.040e+00\n",
      "  2.000e-01 2.080e+00 5.100e+00 8.900e-01 3.530e+00 7.600e+02]\n",
      " [1.421e+01 4.040e+00 2.440e+00 1.890e+01 1.110e+02 2.850e+00 2.650e+00\n",
      "  3.000e-01 1.250e+00 5.240e+00 8.700e-01 3.330e+00 1.080e+03]\n",
      " [1.438e+01 3.590e+00 2.280e+00 1.600e+01 1.020e+02 3.250e+00 3.170e+00\n",
      "  2.700e-01 2.190e+00 4.900e+00 1.040e+00 3.440e+00 1.065e+03]\n",
      " [1.410e+01 2.020e+00 2.400e+00 1.880e+01 1.030e+02 2.750e+00 2.920e+00\n",
      "  3.200e-01 2.380e+00 6.200e+00 1.070e+00 2.750e+00 1.060e+03]\n",
      " [1.422e+01 1.700e+00 2.300e+00 1.630e+01 1.180e+02 3.200e+00 3.000e+00\n",
      "  2.600e-01 2.030e+00 6.380e+00 9.400e-01 3.310e+00 9.700e+02]\n",
      " [1.434e+01 1.680e+00 2.700e+00 2.500e+01 9.800e+01 2.800e+00 1.310e+00\n",
      "  5.300e-01 2.700e+00 1.300e+01 5.700e-01 1.960e+00 6.600e+02]\n",
      " [1.416e+01 2.510e+00 2.480e+00 2.000e+01 9.100e+01 1.680e+00 7.000e-01\n",
      "  4.400e-01 1.240e+00 9.700e+00 6.200e-01 1.710e+00 6.600e+02]\n",
      " [1.413e+01 4.100e+00 2.740e+00 2.450e+01 9.600e+01 2.050e+00 7.600e-01\n",
      "  5.600e-01 1.350e+00 9.200e+00 6.100e-01 1.600e+00 5.600e+02]]\n",
      "f:\n",
      "[[1.286000e+01 1.350000e+00 2.320000e+00 1.800000e+01 1.220000e+02\n",
      "  1.510000e+00 1.250000e+00 2.100000e-01 9.400000e-01 4.100000e+00\n",
      "  7.600000e-01 1.290000e+00 6.300000e+02]\n",
      " [1.288000e+01 2.990000e+00 2.400000e+00 2.000000e+01 1.040000e+02\n",
      "  1.300000e+00 1.220000e+00 2.400000e-01 8.300000e-01 5.400000e+00\n",
      "  7.400000e-01 1.420000e+00 5.300000e+02]\n",
      " [1.281000e+01 2.310000e+00 2.400000e+00 2.400000e+01 9.800000e+01\n",
      "  1.150000e+00 1.090000e+00 2.700000e-01 8.300000e-01 5.700000e+00\n",
      "  6.600000e-01 1.360000e+00 5.600000e+02]\n",
      " [1.270000e+01 3.550000e+00 2.360000e+00 2.150000e+01 1.060000e+02\n",
      "  1.700000e+00 1.200000e+00 1.700000e-01 8.400000e-01 5.000000e+00\n",
      "  7.800000e-01 1.290000e+00 6.000000e+02]\n",
      " [1.251000e+01 1.240000e+00 2.250000e+00 1.750000e+01 8.500000e+01\n",
      "  2.000000e+00 5.800000e-01 6.000000e-01 1.250000e+00 5.450000e+00\n",
      "  7.500000e-01 1.510000e+00 6.500000e+02]\n",
      " [1.260000e+01 2.460000e+00 2.200000e+00 1.850000e+01 9.400000e+01\n",
      "  1.620000e+00 6.600000e-01 6.300000e-01 9.400000e-01 7.100000e+00\n",
      "  7.300000e-01 1.580000e+00 6.950000e+02]\n",
      " [1.225000e+01 4.720000e+00 2.540000e+00 2.100000e+01 8.900000e+01\n",
      "  1.380000e+00 4.700000e-01 5.300000e-01 8.000000e-01 3.850000e+00\n",
      "  7.500000e-01 1.270000e+00 7.200000e+02]\n",
      " [1.253000e+01 5.510000e+00 2.640000e+00 2.500000e+01 9.600000e+01\n",
      "  1.790000e+00 6.000000e-01 6.300000e-01 1.100000e+00 5.000000e+00\n",
      "  8.200000e-01 1.690000e+00 5.150000e+02]\n",
      " [1.349000e+01 3.590000e+00 2.190000e+00 1.950000e+01 8.800000e+01\n",
      "  1.620000e+00 4.800000e-01 5.800000e-01 8.800000e-01 5.700000e+00\n",
      "  8.100000e-01 1.820000e+00 5.800000e+02]\n",
      " [1.284000e+01 2.960000e+00 2.610000e+00 2.400000e+01 1.010000e+02\n",
      "  2.320000e+00 6.000000e-01 5.300000e-01 8.100000e-01 4.920000e+00\n",
      "  8.900000e-01 2.150000e+00 5.900000e+02]\n",
      " [1.293000e+01 2.810000e+00 2.700000e+00 2.100000e+01 9.600000e+01\n",
      "  1.540000e+00 5.000000e-01 5.300000e-01 7.500000e-01 4.600000e+00\n",
      "  7.700000e-01 2.310000e+00 6.000000e+02]\n",
      " [1.336000e+01 2.560000e+00 2.350000e+00 2.000000e+01 8.900000e+01\n",
      "  1.400000e+00 5.000000e-01 3.700000e-01 6.400000e-01 5.600000e+00\n",
      "  7.000000e-01 2.470000e+00 7.800000e+02]\n",
      " [1.352000e+01 3.170000e+00 2.720000e+00 2.350000e+01 9.700000e+01\n",
      "  1.550000e+00 5.200000e-01 5.000000e-01 5.500000e-01 4.350000e+00\n",
      "  8.900000e-01 2.060000e+00 5.200000e+02]\n",
      " [1.362000e+01 4.950000e+00 2.350000e+00 2.000000e+01 9.200000e+01\n",
      "  2.000000e+00 8.000000e-01 4.700000e-01 1.020000e+00 4.400000e+00\n",
      "  9.100000e-01 2.050000e+00 5.500000e+02]\n",
      " [1.225000e+01 3.880000e+00 2.200000e+00 1.850000e+01 1.120000e+02\n",
      "  1.380000e+00 7.800000e-01 2.900000e-01 1.140000e+00 8.210000e+00\n",
      "  6.500000e-01 2.000000e+00 8.550000e+02]\n",
      " [1.316000e+01 3.570000e+00 2.150000e+00 2.100000e+01 1.020000e+02\n",
      "  1.500000e+00 5.500000e-01 4.300000e-01 1.300000e+00 4.000000e+00\n",
      "  6.000000e-01 1.680000e+00 8.300000e+02]\n",
      " [1.388000e+01 5.040000e+00 2.230000e+00 2.000000e+01 8.000000e+01\n",
      "  9.800000e-01 3.400000e-01 4.000000e-01 6.800000e-01 4.900000e+00\n",
      "  5.800000e-01 1.330000e+00 4.150000e+02]\n",
      " [1.287000e+01 4.610000e+00 2.480000e+00 2.150000e+01 8.600000e+01\n",
      "  1.700000e+00 6.500000e-01 4.700000e-01 8.600000e-01 7.650000e+00\n",
      "  5.400000e-01 1.860000e+00 6.250000e+02]\n",
      " [1.332000e+01 3.240000e+00 2.380000e+00 2.150000e+01 9.200000e+01\n",
      "  1.930000e+00 7.600000e-01 4.500000e-01 1.250000e+00 8.420000e+00\n",
      "  5.500000e-01 1.620000e+00 6.500000e+02]\n",
      " [1.308000e+01 3.900000e+00 2.360000e+00 2.150000e+01 1.130000e+02\n",
      "  1.410000e+00 1.390000e+00 3.400000e-01 1.140000e+00 9.400000e+00\n",
      "  5.700000e-01 1.330000e+00 5.500000e+02]\n",
      " [1.350000e+01 3.120000e+00 2.620000e+00 2.400000e+01 1.230000e+02\n",
      "  1.400000e+00 1.570000e+00 2.200000e-01 1.250000e+00 8.600000e+00\n",
      "  5.900000e-01 1.300000e+00 5.000000e+02]\n",
      " [1.279000e+01 2.670000e+00 2.480000e+00 2.200000e+01 1.120000e+02\n",
      "  1.480000e+00 1.360000e+00 2.400000e-01 1.260000e+00 1.080000e+01\n",
      "  4.800000e-01 1.470000e+00 4.800000e+02]\n",
      " [1.311000e+01 1.900000e+00 2.750000e+00 2.550000e+01 1.160000e+02\n",
      "  2.200000e+00 1.280000e+00 2.600000e-01 1.560000e+00 7.100000e+00\n",
      "  6.100000e-01 1.330000e+00 4.250000e+02]\n",
      " [1.323000e+01 3.300000e+00 2.280000e+00 1.850000e+01 9.800000e+01\n",
      "  1.800000e+00 8.300000e-01 6.100000e-01 1.870000e+00 1.052000e+01\n",
      "  5.600000e-01 1.510000e+00 6.750000e+02]\n",
      " [1.258000e+01 1.290000e+00 2.100000e+00 2.000000e+01 1.030000e+02\n",
      "  1.480000e+00 5.800000e-01 5.300000e-01 1.400000e+00 7.600000e+00\n",
      "  5.800000e-01 1.550000e+00 6.400000e+02]\n",
      " [1.317000e+01 5.190000e+00 2.320000e+00 2.200000e+01 9.300000e+01\n",
      "  1.740000e+00 6.300000e-01 6.100000e-01 1.550000e+00 7.900000e+00\n",
      "  6.000000e-01 1.480000e+00 7.250000e+02]\n",
      " [1.384000e+01 4.120000e+00 2.380000e+00 1.950000e+01 8.900000e+01\n",
      "  1.800000e+00 8.300000e-01 4.800000e-01 1.560000e+00 9.010000e+00\n",
      "  5.700000e-01 1.640000e+00 4.800000e+02]\n",
      " [1.245000e+01 3.030000e+00 2.640000e+00 2.700000e+01 9.700000e+01\n",
      "  1.900000e+00 5.800000e-01 6.300000e-01 1.140000e+00 7.500000e+00\n",
      "  6.700000e-01 1.730000e+00 8.800000e+02]\n",
      " [1.434000e+01 1.680000e+00 2.700000e+00 2.500000e+01 9.800000e+01\n",
      "  2.800000e+00 1.310000e+00 5.300000e-01 2.700000e+00 1.300000e+01\n",
      "  5.700000e-01 1.960000e+00 6.600000e+02]\n",
      " [1.348000e+01 1.670000e+00 2.640000e+00 2.250000e+01 8.900000e+01\n",
      "  2.600000e+00 1.100000e+00 5.200000e-01 2.290000e+00 1.175000e+01\n",
      "  5.700000e-01 1.780000e+00 6.200000e+02]\n",
      " [1.236000e+01 3.830000e+00 2.380000e+00 2.100000e+01 8.800000e+01\n",
      "  2.300000e+00 9.200000e-01 5.000000e-01 1.040000e+00 7.650000e+00\n",
      "  5.600000e-01 1.580000e+00 5.200000e+02]\n",
      " [1.369000e+01 3.260000e+00 2.540000e+00 2.000000e+01 1.070000e+02\n",
      "  1.830000e+00 5.600000e-01 5.000000e-01 8.000000e-01 5.880000e+00\n",
      "  9.600000e-01 1.820000e+00 6.800000e+02]\n",
      " [1.285000e+01 3.270000e+00 2.580000e+00 2.200000e+01 1.060000e+02\n",
      "  1.650000e+00 6.000000e-01 6.000000e-01 9.600000e-01 5.580000e+00\n",
      "  8.700000e-01 2.110000e+00 5.700000e+02]\n",
      " [1.296000e+01 3.450000e+00 2.350000e+00 1.850000e+01 1.060000e+02\n",
      "  1.390000e+00 7.000000e-01 4.000000e-01 9.400000e-01 5.280000e+00\n",
      "  6.800000e-01 1.750000e+00 6.750000e+02]\n",
      " [1.378000e+01 2.760000e+00 2.300000e+00 2.200000e+01 9.000000e+01\n",
      "  1.350000e+00 6.800000e-01 4.100000e-01 1.030000e+00 9.580000e+00\n",
      "  7.000000e-01 1.680000e+00 6.150000e+02]\n",
      " [1.373000e+01 4.360000e+00 2.260000e+00 2.250000e+01 8.800000e+01\n",
      "  1.280000e+00 4.700000e-01 5.200000e-01 1.150000e+00 6.620000e+00\n",
      "  7.800000e-01 1.750000e+00 5.200000e+02]\n",
      " [1.345000e+01 3.700000e+00 2.600000e+00 2.300000e+01 1.110000e+02\n",
      "  1.700000e+00 9.200000e-01 4.300000e-01 1.460000e+00 1.068000e+01\n",
      "  8.500000e-01 1.560000e+00 6.950000e+02]\n",
      " [1.282000e+01 3.370000e+00 2.300000e+00 1.950000e+01 8.800000e+01\n",
      "  1.480000e+00 6.600000e-01 4.000000e-01 9.700000e-01 1.026000e+01\n",
      "  7.200000e-01 1.750000e+00 6.850000e+02]\n",
      " [1.358000e+01 2.580000e+00 2.690000e+00 2.450000e+01 1.050000e+02\n",
      "  1.550000e+00 8.400000e-01 3.900000e-01 1.540000e+00 8.660000e+00\n",
      "  7.400000e-01 1.800000e+00 7.500000e+02]\n",
      " [1.340000e+01 4.600000e+00 2.860000e+00 2.500000e+01 1.120000e+02\n",
      "  1.980000e+00 9.600000e-01 2.700000e-01 1.110000e+00 8.500000e+00\n",
      "  6.700000e-01 1.920000e+00 6.300000e+02]\n",
      " [1.220000e+01 3.030000e+00 2.320000e+00 1.900000e+01 9.600000e+01\n",
      "  1.250000e+00 4.900000e-01 4.000000e-01 7.300000e-01 5.500000e+00\n",
      "  6.600000e-01 1.830000e+00 5.100000e+02]\n",
      " [1.277000e+01 2.390000e+00 2.280000e+00 1.950000e+01 8.600000e+01\n",
      "  1.390000e+00 5.100000e-01 4.800000e-01 6.400000e-01 9.899999e+00\n",
      "  5.700000e-01 1.630000e+00 4.700000e+02]\n",
      " [1.416000e+01 2.510000e+00 2.480000e+00 2.000000e+01 9.100000e+01\n",
      "  1.680000e+00 7.000000e-01 4.400000e-01 1.240000e+00 9.700000e+00\n",
      "  6.200000e-01 1.710000e+00 6.600000e+02]\n",
      " [1.371000e+01 5.650000e+00 2.450000e+00 2.050000e+01 9.500000e+01\n",
      "  1.680000e+00 6.100000e-01 5.200000e-01 1.060000e+00 7.700000e+00\n",
      "  6.400000e-01 1.740000e+00 7.400000e+02]\n",
      " [1.340000e+01 3.910000e+00 2.480000e+00 2.300000e+01 1.020000e+02\n",
      "  1.800000e+00 7.500000e-01 4.300000e-01 1.410000e+00 7.300000e+00\n",
      "  7.000000e-01 1.560000e+00 7.500000e+02]\n",
      " [1.327000e+01 4.280000e+00 2.260000e+00 2.000000e+01 1.200000e+02\n",
      "  1.590000e+00 6.900000e-01 4.300000e-01 1.350000e+00 1.020000e+01\n",
      "  5.900000e-01 1.560000e+00 8.350000e+02]\n",
      " [1.317000e+01 2.590000e+00 2.370000e+00 2.000000e+01 1.200000e+02\n",
      "  1.650000e+00 6.800000e-01 5.300000e-01 1.460000e+00 9.300000e+00\n",
      "  6.000000e-01 1.620000e+00 8.400000e+02]\n",
      " [1.413000e+01 4.100000e+00 2.740000e+00 2.450000e+01 9.600000e+01\n",
      "  2.050000e+00 7.600000e-01 5.600000e-01 1.350000e+00 9.200000e+00\n",
      "  6.100000e-01 1.600000e+00 5.600000e+02]]\n",
      "g:\n",
      "[[1.237e+01 9.400e-01 1.360e+00 1.060e+01 8.800e+01 1.980e+00 5.700e-01\n",
      "  2.800e-01 4.200e-01 1.950e+00 1.050e+00 1.820e+00 5.200e+02]\n",
      " [1.334e+01 9.400e-01 2.360e+00 1.700e+01 1.100e+02 2.530e+00 1.300e+00\n",
      "  5.500e-01 4.200e-01 3.170e+00 1.020e+00 1.930e+00 7.500e+02]\n",
      " [1.303e+01 9.000e-01 1.710e+00 1.600e+01 8.600e+01 1.950e+00 2.030e+00\n",
      "  2.400e-01 1.460e+00 4.600e+00 1.190e+00 2.480e+00 3.920e+02]\n",
      " [1.233e+01 9.900e-01 1.950e+00 1.480e+01 1.360e+02 1.900e+00 1.850e+00\n",
      "  3.500e-01 2.760e+00 3.400e+00 1.060e+00 2.310e+00 7.500e+02]\n",
      " [1.200e+01 9.200e-01 2.000e+00 1.900e+01 8.600e+01 2.420e+00 2.260e+00\n",
      "  3.000e-01 1.430e+00 2.500e+00 1.380e+00 3.120e+00 2.780e+02]\n",
      " [1.184e+01 8.900e-01 2.580e+00 1.800e+01 9.400e+01 2.200e+00 2.210e+00\n",
      "  2.200e-01 2.350e+00 3.050e+00 7.900e-01 3.080e+00 5.200e+02]\n",
      " [1.267e+01 9.800e-01 2.240e+00 1.800e+01 9.900e+01 2.200e+00 1.940e+00\n",
      "  3.000e-01 1.460e+00 2.620e+00 1.230e+00 3.160e+00 4.500e+02]\n",
      " [1.141e+01 7.400e-01 2.500e+00 2.100e+01 8.800e+01 2.480e+00 2.010e+00\n",
      "  4.200e-01 1.440e+00 3.080e+00 1.100e+00 2.310e+00 4.340e+02]]\n",
      "h:\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "print(\"a:\")\n",
    "print(wine_y==2)\n",
    "print(\"b:\")\n",
    "print(np.any(wine_x[:,4]>160))\n",
    "print(\"c:\")\n",
    "print(np.all((wine_x[:,4]>70 ) & (wine_x[:,4]<170)))\n",
    "print(f'The minimum of column 5 is {wine_x[:,4].min()}, the maximum of column 5 is {wine_x[:,4].max()}')\n",
    "print(\"d:\")\n",
    "print((wine_y==2) | (wine_y==0))\n",
    "print(\"e:\")\n",
    "print(wine_x[wine_x[:,0]>14])\n",
    "print(\"f:\")\n",
    "print(wine_x[wine_y==2])\n",
    "print(\"g:\")\n",
    "print(wine_x[(wine_x[:,1]<1) & (wine_y==1)])\n",
    "print(\"h:\")\n",
    "wine_x[:,0][wine_x[:,0]>13]=np.round(wine_x[:,0][wine_x[:,0]>13])\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<!--BOOK_INFORMATION-->\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"figures/PDSH-cover-small.png\">\n",
    "\n",
    "*This notebook contains an excerpt from the [Python Data Science Handbook](http://shop.oreilly.com/product/0636920034919.do) by Jake VanderPlas; the content is available [on GitHub](https://github.com/jakevdp/PythonDataScienceHandbook).*\n",
    "\n",
    "*The text is released under the [CC-BY-NC-ND license](https://creativecommons.org/licenses/by-nc-nd/3.0/us/legalcode), and code is released under the [MIT license](https://opensource.org/licenses/MIT). If you find this content useful, please consider supporting the work by [buying the book](http://shop.oreilly.com/product/0636920034919.do)!*"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<!--NAVIGATION-->\n",
    "< [Comparisons, Masks, and Boolean Logic](02.06-Boolean-Arrays-and-Masks.ipynb) | [Contents](Index.ipynb) | [Sorting Arrays](02.08-Sorting.ipynb) >\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/02.07-Fancy-Indexing.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Fancy Indexing"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In the previous sections, we saw how to access and modify portions of arrays using simple indices (e.g., ``arr[0]``), slices (e.g., ``arr[:5]``), and Boolean masks (e.g., ``arr[arr > 0]``).\n",
    "In this section, we'll look at another style of array indexing, known as *fancy indexing*.\n",
    "Fancy indexing is like the simple indexing we've already seen, but we pass arrays of indices in place of single scalars.\n",
    "This allows us to very quickly access and modify complicated subsets of an array's values."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Exploring Fancy Indexing\n",
    "\n",
    "Fancy indexing is conceptually simple: it means passing an array of indices to access multiple array elements at once.\n",
    "For example, consider the following array:"
   ]
  },
  {
   "metadata": {
    "id": "kum3Kn0hNzPY",
    "outputId": "0dfa548e-a374-41e9-8a7c-a9bf697b9ddb"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[51 92 14 71 60 20 82 86 74 74]\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "rand = np.random.RandomState(42)\n",
    "\n",
    "x = rand.randint(100, size=10)\n",
    "print(x)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Suppose we want to access three different elements. We could do it like this:"
  },
  {
   "metadata": {
    "id": "8K3Lop0sNzPb",
    "outputId": "e9b1afa8-f141-474f-b1c6-a917b6dad59d"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[71, 86, 14]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "[x[3], x[7], x[2]]"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Alternatively, we can pass a single list or array of indices to obtain the same result:"
  },
  {
   "metadata": {
    "id": "AQDePCh9NzPd",
    "outputId": "2740ad75-d65e-4601-942c-315c29c52b95"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([71, 86, 60])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "ind = [3, 7, 4]\n",
    "x[ind]"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "When using fancy indexing, the shape of the result reflects the shape of the *index arrays* rather than the shape of the *array being indexed*:"
  },
  {
   "metadata": {
    "id": "3XAhpIxmNzPe",
    "outputId": "f4c7f5e5-16c8-43c5-d8e7-eee7edbd6987"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[71, 86],\n",
       "       [60, 20]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "ind = np.array([[3, 7],\n",
    "                [4, 5]])\n",
    "x[ind]"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Fancy indexing also works in multiple dimensions. Consider the following array:"
  },
  {
   "metadata": {
    "id": "g1sZk0SoNzPf",
    "outputId": "5b5104bf-2bc4-4b3c-cccc-62b48802925b"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "X = np.arange(12).reshape((3, 4))\n",
    "X"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Like with standard indexing, the first index refers to the row, and the second to the column:"
  },
  {
   "metadata": {
    "id": "OxKreSy-NzPf",
    "outputId": "396b4121-1d67-4126-c86e-484cb7da2d9e"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  5, 11])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "row = np.array([0, 1, 2])\n",
    "col = np.array([2, 1, 3])\n",
    "X[row, col]"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Notice that the first value in the result is ``X[0, 2]``, the second is ``X[1, 1]``, and the third is ``X[2, 3]``.\n",
    "The pairing of indices in fancy indexing follows all the broadcasting rules that were mentioned in [Computation on Arrays: Broadcasting](02.05-Computation-on-arrays-broadcasting.ipynb).\n",
    "So, for example, if we combine a column vector and a row vector within the indices, we get a two-dimensional result:"
   ]
  },
  {
   "metadata": {
    "id": "f4S4CgGbNzPg",
    "outputId": "d8a482cb-16dd-47af-9a39-b082fb8ecbfa"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  1,  3],\n",
       "       [ 6,  5,  7],\n",
       "       [10,  9, 11]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "X[row[:, np.newaxis], col]"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Here, each row value is matched with each column vector, exactly as we saw in broadcasting of arithmetic operations.\n",
    "For example:"
   ]
  },
  {
   "metadata": {
    "id": "t9mzywlDNzPg",
    "outputId": "4c50d300-a11d-47ae-fd94-5ff328f683c9"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [2, 1, 3],\n",
       "       [4, 2, 6]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "row[:, np.newaxis] * col"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "It is always important to remember with fancy indexing that the return value reflects the *broadcasted shape of the indices*, rather than the shape of the array being indexed."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Combined Indexing\n",
    "\n",
    "For even more powerful operations, fancy indexing can be combined with the other indexing schemes we've seen:"
   ]
  },
  {
   "metadata": {
    "id": "38jJnX_uNzPh",
    "outputId": "9eb63e1f-7645-4e84-be1c-69007b8d8f2e"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]]\n"
     ]
    }
   ],
   "execution_count": null,
   "source": "print(X)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can combine fancy and simple indices:"
  },
  {
   "metadata": {
    "id": "qtf0jDV3NzPi",
    "outputId": "5100e148-e174-44ea-9301-85614af5535f"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  8,  9])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "X[2, [2, 0, 1]]"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can also combine fancy indexing with slicing:"
  },
  {
   "metadata": {
    "id": "O5z5FU2LNzPj",
    "outputId": "d126dea1-0d25-4a43-aa3b-b38203ddbe67"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6,  4,  5],\n",
       "       [10,  8,  9]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "X[1:, [2, 0, 1]]"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "And we can combine fancy indexing with masking:"
  },
  {
   "metadata": {
    "id": "yirF3T-hNzPj",
    "outputId": "a6abd676-6006-4a45-cb5e-76c25a383a44"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  2],\n",
       "       [ 4,  6],\n",
       "       [ 8, 10]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "mask = np.array([1, 0, 1, 0], dtype=bool)\n",
    "X[row[:, np.newaxis], mask]"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "All of these indexing options combined lead to a very flexible set of operations for accessing and modifying array values."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Example: Selecting Random Points\n",
    "\n",
    "One common use of fancy indexing is the selection of subsets of rows from a matrix.\n",
    "For example, we might have an $N$ by $D$ matrix representing $N$ points in $D$ dimensions, such as the following points drawn from a two-dimensional normal distribution:"
   ]
  },
  {
   "metadata": {
    "id": "dRKETVjxNzPm",
    "outputId": "08ef8f07-003a-4f62-c7d4-5f9573a8075d"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "mean = [0, 0]\n",
    "cov = [[1, 2],\n",
    "       [2, 5]]\n",
    "X = rand.multivariate_normal(mean, cov, 100)\n",
    "X.shape"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Using the plotting tools we will discuss in [Introduction to Matplotlib](DS2-4NotebooksWithSolutions.ipynb), we can visualize these points as a scatter-plot:"
  },
  {
   "metadata": {
    "id": "-SVuf3r2NzPm",
    "outputId": "8050e80b-9463-4d7b-cb29-4b017af4baf5"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFVCAYAAADVDycqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e332048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": null,
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn; seaborn.set()  # for plot styling\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1]);"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's use fancy indexing to select 20 random points. We'll do this by first choosing 20 random indices with no repeats, and use these indices to select a portion of the original array:"
  },
  {
   "metadata": {
    "id": "faww-fBGNzPn",
    "outputId": "5f99df49-efc3-45b1-d80b-5016903b4257"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([93, 45, 73, 81, 50, 10, 98, 94,  4, 64, 65, 89, 47, 84, 82, 80, 25,\n",
       "       90, 63, 20])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "indices = np.random.choice(X.shape[0], 20, replace=False)\n",
    "indices"
   ]
  },
  {
   "metadata": {
    "id": "oS-omH7vNzPp",
    "outputId": "ede95851-0436-494f-bb12-1ef7b5ace12b"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "selection = X[indices]  # fancy indexing here\n",
    "selection.shape"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now to see which points were selected, let's over-plot large circles at the locations of the selected points:"
  },
  {
   "metadata": {
    "id": "FV2zUtGjNzPp",
    "outputId": "d0d1266b-5b64-438e-ac20-f0cab160cd64"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFVCAYAAADVDycqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118687240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": null,
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], alpha=0.3)\n",
    "plt.scatter(selection[:, 0], selection[:, 1],\n",
    "            facecolor='none', s=200);"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This sort of strategy is often used to quickly partition datasets, as is often needed in train/test splitting for validation of statistical models (see [Hyperparameters and Model Validation](05.03-Hyperparameters-and-Model-Validation.ipynb)), and in sampling approaches to answering statistical questions."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Modifying Values with Fancy Indexing\n",
    "\n",
    "Just as fancy indexing can be used to access parts of an array, it can also be used to modify parts of an array.\n",
    "For example, imagine we have an array of indices and we'd like to set the corresponding items in an array to some value:"
   ]
  },
  {
   "metadata": {
    "id": "qYZlXGcrNzPx",
    "outputId": "e100d609-6223-4d08-bc4f-fe6db93ecbb2"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 99 99  3 99  5  6  7 99  9]\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "x = np.arange(10)\n",
    "i = np.array([2, 1, 8, 4])\n",
    "x[i] = 99\n",
    "print(x)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can use any assignment-type operator for this. For example:"
  },
  {
   "metadata": {
    "id": "a7n3W99ANzPy",
    "outputId": "784ca8e1-df24-49f5-ce85-f8f6c993d412"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 89 89  3 89  5  6  7 89  9]\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "x[i] -= 10\n",
    "print(x)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Notice, though, that repeated indices with these operations can cause some potentially unexpected results. Consider the following:"
  },
  {
   "metadata": {
    "id": "duR66V0_NzPy",
    "outputId": "9fbeaf4b-2b23-4564-f0c6-9311ad7cd068"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "x = np.zeros(10)\n",
    "x[[0, 0]] = [4, 6]\n",
    "print(x)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Where did the 4 go? The result of this operation is to first assign ``x[0] = 4``, followed by ``x[0] = 6``.\n",
    "The result, of course, is that ``x[0]`` contains the value 6.\n",
    "\n",
    "Fair enough, but consider this operation:"
   ]
  },
  {
   "metadata": {
    "id": "OAbXcouSNzPz",
    "outputId": "d4ea86e0-5873-4a84-9149-8ea9e5056016"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.,  0.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "i = [2, 3, 3, 4, 4, 4]\n",
    "x[i] += 1\n",
    "x"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "You might expect that ``x[3]`` would contain the value 2, and ``x[4]`` would contain the value 3, as this is how many times each index is repeated. Why is this not the case?\n",
    "Conceptually, this is because ``x[i] += 1`` is meant as a shorthand of ``x[i] = x[i] + 1``. ``x[i] + 1`` is evaluated, and then the result is assigned to the indices in x.\n",
    "With this in mind, it is not the augmentation that happens multiple times, but the assignment, which leads to the rather nonintuitive results.\n",
    "\n",
    "So what if you want the other behavior where the operation is repeated? For this, you can use the ``at()`` method of ufuncs (available since NumPy 1.8), and do the following:"
   ]
  },
  {
   "metadata": {
    "id": "sA4_oD84NzP0",
    "outputId": "0424d038-983c-49ba-f7c2-df92a3866776"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  1.  2.  3.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "x = np.zeros(10)\n",
    "np.add.at(x, i, 1)\n",
    "print(x)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The ``at()`` method does an in-place application of the given operator at the specified indices (here, ``i``) with the specified value (here, 1).\n",
    "Another method that is similar in spirit is the ``reduceat()`` method of ufuncs, which you can read about in the NumPy documentation."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Example: Binning Data\n",
    "\n",
    "You can use these ideas to efficiently bin data to create a histogram by hand.\n",
    "For example, imagine we have 1,000 values and would like to quickly find where they fall within an array of bins.\n",
    "We could compute it using ``ufunc.at`` like this:"
   ]
  },
  {
   "metadata": {
    "id": "rvyLKSoaNzP0"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "np.random.seed(42)\n",
    "x = np.random.randn(100)\n",
    "\n",
    "# compute a histogram by hand\n",
    "bins = np.linspace(-5, 5, 20)\n",
    "counts = np.zeros_like(bins)\n",
    "\n",
    "# find the appropriate bin for each x\n",
    "i = np.searchsorted(bins, x)\n",
    "\n",
    "# add 1 to each of these bins\n",
    "np.add.at(counts, i, 1)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The counts now reflect the number of points within each bin–in other words, a histogram:"
  },
  {
   "metadata": {
    "id": "3zKr-lkONzP1",
    "outputId": "9dae1c42-9b61-4e7b-de79-1a77b53e0fe9"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFVCAYAAADYEVdtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwgCQRIQBIIkIA0ASEQaAJP8P7quNPHF17C4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1186d90b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": null,
   "source": [
    "# plot the results\n",
    "plt.plot(bins, counts, linestyle='steps');"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Of course, it would be silly to have to do this each time you want to plot a histogram.\n",
    "This is why Matplotlib provides the ``plt.hist()`` routine, which does the same in a single line:\n",
    "\n",
    "```python\n",
    "plt.hist(x, bins, histtype='step');\n",
    "```\n",
    "\n",
    "This function will create a nearly identical plot to the one seen here.\n",
    "To compute the binning, ``matplotlib`` uses the ``np.histogram`` function, which does a very similar computation to what we did before. Let's compare the two here:"
   ]
  },
  {
   "metadata": {
    "id": "MK6pcvctNzP2",
    "outputId": "536ee058-1a0a-40c5-a3aa-528295a70167"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy routine:\n",
      "10000 loops, best of 3: 97.6 µs per loop\n",
      "Custom routine:\n",
      "10000 loops, best of 3: 19.5 µs per loop\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "print(\"NumPy routine:\")\n",
    "%timeit counts, edges = np.histogram(x, bins)\n",
    "\n",
    "print(\"Custom routine:\")\n",
    "%timeit np.add.at(counts, np.searchsorted(bins, x), 1)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Our own one-line algorithm is several times faster than the optimized algorithm in NumPy! How can this be?\n",
    "If you dig into the ``np.histogram`` source code (you can do this in IPython by typing ``np.histogram??``), you'll see that it's quite a bit more involved than the simple search-and-count that we've done; this is because NumPy's algorithm is more flexible, and particularly is designed for better performance when the number of data points becomes large:"
   ]
  },
  {
   "metadata": {
    "id": "KoQfuMB6NzP3",
    "outputId": "ab4cd6c3-8bc1-4b8b-9517-869bbdf3cb02"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy routine:\n",
      "10 loops, best of 3: 68.7 ms per loop\n",
      "Custom routine:\n",
      "10 loops, best of 3: 135 ms per loop\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "x = np.random.randn(1000000)\n",
    "print(\"NumPy routine:\")\n",
    "%timeit counts, edges = np.histogram(x, bins)\n",
    "\n",
    "print(\"Custom routine:\")\n",
    "%timeit np.add.at(counts, np.searchsorted(bins, x), 1)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "What this comparison shows is that algorithmic efficiency is almost never a simple question. An algorithm efficient for large datasets will not always be the best choice for small datasets, and vice versa (see [Big-O Notation](02.08-Sorting.ipynb#Aside:-Big-O-Notation)).\n",
    "But the advantage of coding this algorithm yourself is that with an understanding of these basic methods, you could use these building blocks to extend this to do some very interesting custom behaviors.\n",
    "The key to efficiently using Python in data-intensive applications is knowing about general convenience routines like ``np.histogram`` and when they're appropriate, but also knowing how to make use of lower-level functionality when you need more pointed behavior."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<!--NAVIGATION-->\n",
    "< [Comparisons, Masks, and Boolean Logic](02.06-Boolean-Arrays-and-Masks.ipynb) | [Contents](Index.ipynb) | [Sorting Arrays](02.08-Sorting.ipynb) >\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/02.07-Fancy-Indexing.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>\n"
   ]
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-24T14:59:57.168270Z",
     "start_time": "2025-01-24T14:59:57.153262Z"
    },
    "id": "initial_id",
    "outputId": "09876dd5-be2e-4617-cafa-d1170e212603"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _wine_dataset:\n",
      "\n",
      "Wine recognition dataset\n",
      "------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      ":Number of Instances: 178\n",
      ":Number of Attributes: 13 numeric, predictive attributes and the class\n",
      ":Attribute Information:\n",
      "    - Alcohol\n",
      "    - Malic acid\n",
      "    - Ash\n",
      "    - Alcalinity of ash\n",
      "    - Magnesium\n",
      "    - Total phenols\n",
      "    - Flavanoids\n",
      "    - Nonflavanoid phenols\n",
      "    - Proanthocyanins\n",
      "    - Color intensity\n",
      "    - Hue\n",
      "    - OD280/OD315 of diluted wines\n",
      "    - Proline\n",
      "    - class:\n",
      "        - class_0\n",
      "        - class_1\n",
      "        - class_2\n",
      "\n",
      ":Summary Statistics:\n",
      "\n",
      "============================= ==== ===== ======= =====\n",
      "                                Min   Max   Mean     SD\n",
      "============================= ==== ===== ======= =====\n",
      "Alcohol:                      11.0  14.8    13.0   0.8\n",
      "Malic Acid:                   0.74  5.80    2.34  1.12\n",
      "Ash:                          1.36  3.23    2.36  0.27\n",
      "Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
      "Magnesium:                    70.0 162.0    99.7  14.3\n",
      "Total Phenols:                0.98  3.88    2.29  0.63\n",
      "Flavanoids:                   0.34  5.08    2.03  1.00\n",
      "Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
      "Proanthocyanins:              0.41  3.58    1.59  0.57\n",
      "Colour Intensity:              1.3  13.0     5.1   2.3\n",
      "Hue:                          0.48  1.71    0.96  0.23\n",
      "OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
      "Proline:                       278  1680     746   315\n",
      "============================= ==== ===== ======= =====\n",
      "\n",
      ":Missing Attribute Values: None\n",
      ":Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
      ":Creator: R.A. Fisher\n",
      ":Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      ":Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML Wine recognition datasets.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
      "\n",
      "The data is the results of a chemical analysis of wines grown in the same\n",
      "region in Italy by three different cultivators. There are thirteen different\n",
      "measurements taken for different constituents found in the three types of\n",
      "wine.\n",
      "\n",
      "Original Owners:\n",
      "\n",
      "Forina, M. et al, PARVUS -\n",
      "An Extendible Package for Data Exploration, Classification and Correlation.\n",
      "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
      "Via Brigata Salerno, 16147 Genoa, Italy.\n",
      "\n",
      "Citation:\n",
      "\n",
      "Lichman, M. (2013). UCI Machine Learning Repository\n",
      "[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
      "School of Information and Computer Science.\n",
      "\n",
      ".. dropdown:: References\n",
      "\n",
      "    (1) S. Aeberhard, D. Coomans and O. de Vel,\n",
      "    Comparison of Classifiers in High Dimensional Settings,\n",
      "    Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of\n",
      "    Mathematics and Statistics, James Cook University of North Queensland.\n",
      "    (Also submitted to Technometrics).\n",
      "\n",
      "    The data was used with many others for comparing various\n",
      "    classifiers. The classes are separable, though only RDA\n",
      "    has achieved 100% correct classification.\n",
      "    (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data))\n",
      "    (All results using the leave-one-out technique)\n",
      "\n",
      "    (2) S. Aeberhard, D. Coomans and O. de Vel,\n",
      "    \"THE CLASSIFICATION PERFORMANCE OF RDA\"\n",
      "    Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of\n",
      "    Mathematics and Statistics, James Cook University of North Queensland.\n",
      "    (Also submitted to Journal of Chemometrics).\n",
      "\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import sklearn.datasets as ds\n",
    "import numpy as np\n",
    "wine_x= np.array(ds.load_wine().data)\n",
    "wine_y= np.array(ds.load_wine().target)\n",
    "descr= ds.load_wine().DESCR\n",
    "print(descr)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Fancy Indexing\n",
    "\n",
    "In this exercise we will use a wine dataset from the sklearn module. The features (independent variables) are stored in the array wine_x. The target wineclass (dependent variable) is stored in the array wine_y. See the description above for more information on the dataset.\n",
    "\n",
    "\n",
    "a. Select the 1st, 5th and 10th row of wine_x. Do it with one statement.\\\n",
    "b. We want to pick a sample of the wine_x dataset. Pick a sample of 5 rows of wine_x. Use the random module of numpy.\\\n",
    "c. Pick a sample of 20 rows of wine_x. We only want to select columns Alcohol, Malic Acid and Ash (first tree columns). Use combined indexing. Do it with one statement.\\\n",
    "d. In column 0 of wine_x change the values of row 5,20,38,45,60 to 0."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T15:10:52.662041Z",
     "start_time": "2025-01-24T15:10:52.652272Z"
    },
    "id": "6cc5ef6201a553de",
    "outputId": "c6d7ea12-4b9d-4a02-b130-5a689e498aea"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "[[1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n",
      "  2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03]\n",
      " [1.324e+01 2.590e+00 2.870e+00 2.100e+01 1.180e+02 2.800e+00 2.690e+00\n",
      "  3.900e-01 1.820e+00 4.320e+00 1.040e+00 2.930e+00 7.350e+02]\n",
      " [1.386e+01 1.350e+00 2.270e+00 1.600e+01 9.800e+01 2.980e+00 3.150e+00\n",
      "  2.200e-01 1.850e+00 7.220e+00 1.010e+00 3.550e+00 1.045e+03]]\n",
      "b\n",
      "[[1.260e+01 2.460e+00 2.200e+00 1.850e+01 9.400e+01 1.620e+00 6.600e-01\n",
      "  6.300e-01 9.400e-01 7.100e+00 7.300e-01 1.580e+00 6.950e+02]\n",
      " [1.184e+01 2.890e+00 2.230e+00 1.800e+01 1.120e+02 1.720e+00 1.320e+00\n",
      "  4.300e-01 9.500e-01 2.650e+00 9.600e-01 2.520e+00 5.000e+02]\n",
      " [1.103e+01 1.510e+00 2.200e+00 2.150e+01 8.500e+01 2.460e+00 2.170e+00\n",
      "  5.200e-01 2.010e+00 1.900e+00 1.710e+00 2.870e+00 4.070e+02]\n",
      " [1.363e+01 1.810e+00 2.700e+00 1.720e+01 1.120e+02 2.850e+00 2.910e+00\n",
      "  3.000e-01 1.460e+00 7.300e+00 1.280e+00 2.880e+00 1.310e+03]\n",
      " [1.413e+01 4.100e+00 2.740e+00 2.450e+01 9.600e+01 2.050e+00 7.600e-01\n",
      "  5.600e-01 1.350e+00 9.200e+00 6.100e-01 1.600e+00 5.600e+02]]\n",
      "c\n",
      "[[12.77  2.39  2.28]\n",
      " [14.3   1.92  2.72]\n",
      " [12.69  1.53  2.26]\n",
      " [12.6   2.46  2.2 ]\n",
      " [12.86  1.35  2.32]]\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "print(\"a\")\n",
    "print(wine_x[[0,4,9]])\n",
    "print(\"b\")\n",
    "rng = np.random.default_rng(seed=42)\n",
    "print(wine_x[rng.choice(range(0, len(wine_x)), 5, replace=False)])\n",
    "print(\"c\")\n",
    "print(wine_x[rng.choice(range(0, len(wine_x)), 5, replace=False), 0:3])\n",
    "wine_x[[5,20,38,45,60],0]=0\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {
    "id": "ff15de614486ec17"
   },
   "cell_type": "code",
   "outputs": [],
   "source": "",
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<!--BOOK_INFORMATION-->\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"figures/PDSH-cover-small.png\">\n",
    "\n",
    "*This notebook contains an excerpt from the [Python Data Science Handbook](http://shop.oreilly.com/product/0636920034919.do) by Jake VanderPlas; the content is available [on GitHub](https://github.com/jakevdp/PythonDataScienceHandbook).*\n",
    "\n",
    "*The text is released under the [CC-BY-NC-ND license](https://creativecommons.org/licenses/by-nc-nd/3.0/us/legalcode), and code is released under the [MIT license](https://opensource.org/licenses/MIT). If you find this content useful, please consider supporting the work by [buying the book](http://shop.oreilly.com/product/0636920034919.do)!*"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<!--NAVIGATION-->\n",
    "< [Structured Data: NumPy's Structured Arrays](02.09-Structured-Data-NumPy.ipynb) | [Contents](Index.ipynb) | [Introducing Pandas Objects](03.01-Introducing-Pandas-Objects.ipynb) >\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.00-Introduction-to-Pandas.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data Manipulation with Pandas"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In the previous chapter, we dove into detail on NumPy and its ``ndarray`` object, which provides efficient storage and manipulation of dense typed arrays in Python.\n",
    "Here we'll build on this knowledge by looking in detail at the data structures provided by the Pandas library.\n",
    "Pandas is a newer package built on top of NumPy, and provides an efficient implementation of a ``DataFrame``.\n",
    "``DataFrame``s are essentially multidimensional arrays with attached row and column labels, and often with heterogeneous types and/or missing data.\n",
    "As well as offering a convenient storage interface for labeled data, Pandas implements a number of powerful data operations familiar to users of both database frameworks and spreadsheet programs.\n",
    "\n",
    "As we saw, NumPy's ``ndarray`` data structure provides essential features for the type of clean, well-organized data typically seen in numerical computing tasks.\n",
    "While it serves this purpose very well, its limitations become clear when we need more flexibility (e.g., attaching labels to data, working with missing data, etc.) and when attempting operations that do not map well to element-wise broadcasting (e.g., groupings, pivots, etc.), each of which is an important piece of analyzing the less structured data available in many forms in the world around us.\n",
    "Pandas, and in particular its ``Series`` and ``DataFrame`` objects, builds on the NumPy array structure and provides efficient access to these sorts of \"data munging\" tasks that occupy much of a data scientist's time.\n",
    "\n",
    "In this chapter, we will focus on the mechanics of using ``Series``, ``DataFrame``, and related structures effectively.\n",
    "We will use examples drawn from real datasets where appropriate, but these examples are not necessarily the focus."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Installing and Using Pandas\n",
    "\n",
    "Installation of Pandas on your system requires NumPy to be installed, and if building the library from source, requires the appropriate tools to compile the C and Cython sources on which Pandas is built.\n",
    "Details on this installation can be found in the [Pandas documentation](http://pandas.pydata.org/).\n",
    "If you followed the advice outlined in the [Preface](00.00-Preface.ipynb) and used the Anaconda stack, you already have Pandas installed.\n",
    "\n",
    "Once Pandas is installed, you can import it and check the version:"
   ]
  },
  {
   "metadata": {
    "id": "Dhab3B4t5Y_y",
    "outputId": "3029fe1e-9f80-4655-8e55-eb21491f2665"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.18.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "import pandas\n",
    "pandas.__version__"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Just as we generally import NumPy under the alias ``np``, we will import Pandas under the alias ``pd``:"
  },
  {
   "metadata": {
    "collapsed": true,
    "id": "vhs2j-AM5Y_0"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "import pandas as pd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This import convention will be used throughout the remainder of this book."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Reminder about Built-In Documentation\n",
    "\n",
    "As you read through this chapter, don't forget that IPython gives you the ability to quickly explore the contents of a package (by using the tab-completion feature) as well as the documentation of various functions (using the ``?`` character). (Refer back to [Help and Documentation in IPython](01.01-Help-And-Documentation.ipynb) if you need a refresher on this.)\n",
    "\n",
    "For example, to display all the contents of the pandas namespace, you can type\n",
    "\n",
    "```ipython\n",
    "In [3]: pd.<TAB>\n",
    "```\n",
    "\n",
    "And to display Pandas's built-in documentation, you can use this:\n",
    "\n",
    "```ipython\n",
    "In [4]: pd?\n",
    "```\n",
    "\n",
    "More detailed documentation, along with tutorials and other resources, can be found at http://pandas.pydata.org/."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<!--NAVIGATION-->\n",
    "< [Structured Data: NumPy's Structured Arrays](02.09-Structured-Data-NumPy.ipynb) | [Contents](Index.ipynb) | [Introducing Pandas Objects](03.01-Introducing-Pandas-Objects.ipynb) >\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.00-Introduction-to-Pandas.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<!--BOOK_INFORMATION-->\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"figures/PDSH-cover-small.png\">\n",
    "\n",
    "*This notebook contains an excerpt from the [Python Data Science Handbook](http://shop.oreilly.com/product/0636920034919.do) by Jake VanderPlas; the content is available [on GitHub](https://github.com/jakevdp/PythonDataScienceHandbook).*\n",
    "\n",
    "*The text is released under the [CC-BY-NC-ND license](https://creativecommons.org/licenses/by-nc-nd/3.0/us/legalcode), and code is released under the [MIT license](https://opensource.org/licenses/MIT). If you find this content useful, please consider supporting the work by [buying the book](http://shop.oreilly.com/product/0636920034919.do)!*"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<!--NAVIGATION-->\n",
    "< [Data Manipulation with Pandas](03.00-Introduction-to-Pandas.ipynb) | [Contents](Index.ipynb) | [Data Indexing and Selection](03.02-Data-Indexing-and-Selection.ipynb) >\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.01-Introducing-Pandas-Objects.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Introducing Pandas Objects"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "At the very basic level, Pandas objects can be thought of as enhanced versions of NumPy structured arrays in which the rows and columns are identified with labels rather than simple integer indices.\n",
    "As we will see during the course of this chapter, Pandas provides a host of useful tools, methods, and functionality on top of the basic data structures, but nearly everything that follows will require an understanding of what these structures are.\n",
    "Thus, before we go any further, let's introduce these three fundamental Pandas data structures: the ``Series``, ``DataFrame``, and ``Index``.\n",
    "\n",
    "We will start our code sessions with the standard NumPy and Pandas imports:"
   ]
  },
  {
   "metadata": {
    "collapsed": true,
    "id": "IC-e25khpWPV"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## The Pandas Series Object\n",
    "\n",
    "A Pandas ``Series`` is a one-dimensional array of indexed data.\n",
    "It can be created from a list or array as follows:"
   ]
  },
  {
   "metadata": {
    "id": "fMdnJaQbpWPW",
    "outputId": "dff20213-cf54-479b-8208-a6cd7c8dd2ab"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.25\n",
       "1    0.50\n",
       "2    0.75\n",
       "3    1.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "data = pd.Series([0.25, 0.5, 0.75, 1.0])\n",
    "data"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "As we see in the output, the ``Series`` wraps both a sequence of values and a sequence of indices, which we can access with the ``values`` and ``index`` attributes.\n",
    "The ``values`` are simply a familiar NumPy array:"
   ]
  },
  {
   "metadata": {
    "id": "uxEb-trqpWPX",
    "outputId": "f9951742-6a20-4d98-ebe5-90f4641957c6"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.25,  0.5 ,  0.75,  1.  ])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "data.values"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The ``index`` is an array-like object of type ``pd.Index``, which we'll discuss in more detail momentarily."
  },
  {
   "metadata": {
    "id": "Oc5QAkrEpWPY",
    "outputId": "5070656e-bc8d-47d0-bcfc-c314292f5f1e"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=4, step=1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "data.index"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Like with a NumPy array, data can be accessed by the associated index via the familiar Python square-bracket notation:"
  },
  {
   "metadata": {
    "id": "WBiMjh8apWPY",
    "outputId": "441cc6b0-c46b-4f97-9d0b-251acc817879"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "data[1]"
  },
  {
   "metadata": {
    "id": "7aloBqtCpWPZ",
    "outputId": "899aa912-7339-482b-9572-3537c9dd1a99"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.50\n",
       "2    0.75\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "data[1:3]"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As we will see, though, the Pandas ``Series`` is much more general and flexible than the one-dimensional NumPy array that it emulates."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### ``Series`` as generalized NumPy array"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "From what we've seen so far, it may look like the ``Series`` object is basically interchangeable with a one-dimensional NumPy array.\n",
    "The essential difference is the presence of the index: while the Numpy Array has an *implicitly defined* integer index used to access the values, the Pandas ``Series`` has an *explicitly defined* index associated with the values.\n",
    "\n",
    "This explicit index definition gives the ``Series`` object additional capabilities. For example, the index need not be an integer, but can consist of values of any desired type.\n",
    "For example, if we wish, we can use strings as an index:"
   ]
  },
  {
   "metadata": {
    "id": "BgX_BOSPpWPZ",
    "outputId": "cbff0a69-159f-4931-c7e8-acbbfd3f0bc5"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    0.25\n",
       "b    0.50\n",
       "c    0.75\n",
       "d    1.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "data = pd.Series([0.25, 0.5, 0.75, 1.0],\n",
    "                 index=['a', 'b', 'c', 'd'])\n",
    "data"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "And the item access works as expected:"
  },
  {
   "metadata": {
    "id": "9bpnPHhzpWPa",
    "outputId": "74d2217c-4082-438e-8ff7-4c541e51f46d"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "data['b']"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can even use non-contiguous or non-sequential indices:"
  },
  {
   "metadata": {
    "id": "S1XBn-2YpWPa",
    "outputId": "3dcfcf46-290c-4428-fb05-be13400ee371"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.25\n",
       "5    0.50\n",
       "3    0.75\n",
       "7    1.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "data = pd.Series([0.25, 0.5, 0.75, 1.0],\n",
    "                 index=[2, 5, 3, 7])\n",
    "data"
   ]
  },
  {
   "metadata": {
    "id": "xaG77pJKpWPa",
    "outputId": "3815b4e0-6643-47d7-a473-27f9a94a18a1"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "data[5]"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Series as specialized dictionary\n",
    "\n",
    "In this way, you can think of a Pandas ``Series`` a bit like a specialization of a Python dictionary.\n",
    "A dictionary is a structure that maps arbitrary keys to a set of arbitrary values, and a ``Series`` is a structure which maps typed keys to a set of typed values.\n",
    "This typing is important: just as the type-specific compiled code behind a NumPy array makes it more efficient than a Python list for certain operations, the type information of a Pandas ``Series`` makes it much more efficient than Python dictionaries for certain operations.\n",
    "\n",
    "The ``Series``-as-dictionary analogy can be made even more clear by constructing a ``Series`` object directly from a Python dictionary:"
   ]
  },
  {
   "metadata": {
    "id": "Chbhba-2pWPb",
    "outputId": "8687259a-935e-4a58-e800-3b65c5ac0206"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "California    38332521\n",
       "Florida       19552860\n",
       "Illinois      12882135\n",
       "New York      19651127\n",
       "Texas         26448193\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "population_dict = {'California': 38332521,\n",
    "                   'Texas': 26448193,\n",
    "                   'New York': 19651127,\n",
    "                   'Florida': 19552860,\n",
    "                   'Illinois': 12882135}\n",
    "population = pd.Series(population_dict)\n",
    "population"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "By default, a ``Series`` will be created where the index is drawn from the sorted keys.\n",
    "From here, typical dictionary-style item access can be performed:"
   ]
  },
  {
   "metadata": {
    "id": "eB0BH8IKpWPb",
    "outputId": "0138ea21-30d0-44c0-960b-1e990dcd9e06"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38332521"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "population['California']"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Unlike a dictionary, though, the ``Series`` also supports array-style operations such as slicing:"
  },
  {
   "metadata": {
    "id": "cqFQ6McMpWPc",
    "outputId": "620298b3-2bcf-4ec3-9e63-c97259c4e67f"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "California    38332521\n",
       "Florida       19552860\n",
       "Illinois      12882135\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "population['California':'Illinois']"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We'll discuss some of the quirks of Pandas indexing and slicing in [Data Indexing and Selection](03.02-Data-Indexing-and-Selection.ipynb)."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Constructing Series objects\n",
    "\n",
    "We've already seen a few ways of constructing a Pandas ``Series`` from scratch; all of them are some version of the following:\n",
    "\n",
    "```python\n",
    ">>> pd.Series(data, index=index)\n",
    "```\n",
    "\n",
    "where ``index`` is an optional argument, and ``data`` can be one of many entities.\n",
    "\n",
    "For example, ``data`` can be a list or NumPy array, in which case ``index`` defaults to an integer sequence:"
   ]
  },
  {
   "metadata": {
    "id": "TkISLlnQpWPc",
    "outputId": "b8114609-fcca-4fe5-cea7-2fee06e99fa9"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    4\n",
       "2    6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "pd.Series([2, 4, 6])"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "``data`` can be a scalar, which is repeated to fill the specified index:"
  },
  {
   "metadata": {
    "id": "BIAiWb6LpWPc",
    "outputId": "29a74de1-4dd6-423e-b497-1b66ba8bb2f1"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100    5\n",
       "200    5\n",
       "300    5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "pd.Series(5, index=[100, 200, 300])"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "``data`` can be a dictionary, in which ``index`` defaults to the sorted dictionary keys:"
  },
  {
   "metadata": {
    "id": "EViSAayDpWPd",
    "outputId": "6b680c68-69ec-4c70-ada9-49c92f686816"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    b\n",
       "2    a\n",
       "3    c\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "pd.Series({2:'a', 1:'b', 3:'c'})"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In each case, the index can be explicitly set if a different result is preferred:"
  },
  {
   "metadata": {
    "id": "ifmsZM8mpWPd",
    "outputId": "099a1fb7-d087-4558-8b41-65a5a34cebe0"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    c\n",
       "2    a\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "pd.Series({2:'a', 1:'b', 3:'c'}, index=[3, 2])"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Notice that in this case, the ``Series`` is populated only with the explicitly identified keys."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## The Pandas DataFrame Object\n",
    "\n",
    "The next fundamental structure in Pandas is the ``DataFrame``.\n",
    "Like the ``Series`` object discussed in the previous section, the ``DataFrame`` can be thought of either as a generalization of a NumPy array, or as a specialization of a Python dictionary.\n",
    "We'll now take a look at each of these perspectives."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### DataFrame as a generalized NumPy array\n",
    "If a ``Series`` is an analog of a one-dimensional array with flexible indices, a ``DataFrame`` is an analog of a two-dimensional array with both flexible row indices and flexible column names.\n",
    "Just as you might think of a two-dimensional array as an ordered sequence of aligned one-dimensional columns, you can think of a ``DataFrame`` as a sequence of aligned ``Series`` objects.\n",
    "Here, by \"aligned\" we mean that they share the same index.\n",
    "\n",
    "To demonstrate this, let's first construct a new ``Series`` listing the area of each of the five states discussed in the previous section:"
   ]
  },
  {
   "metadata": {
    "id": "hd3mEm0PpWPi",
    "outputId": "e98bb841-fad3-462d-8865-ffd4966a2776"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "California    423967\n",
       "Florida       170312\n",
       "Illinois      149995\n",
       "New York      141297\n",
       "Texas         695662\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "area_dict = {'California': 423967, 'Texas': 695662, 'New York': 141297,\n",
    "             'Florida': 170312, 'Illinois': 149995}\n",
    "area = pd.Series(area_dict)\n",
    "area"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now that we have this along with the ``population`` Series from before, we can use a dictionary to construct a single two-dimensional object containing this information:"
  },
  {
   "metadata": {
    "id": "FPPB6ZmRpWPj",
    "outputId": "cb365b68-c095-4f7e-ef71-9aa408153704"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <td>423967</td>\n",
       "      <td>38332521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Florida</th>\n",
       "      <td>170312</td>\n",
       "      <td>19552860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Illinois</th>\n",
       "      <td>149995</td>\n",
       "      <td>12882135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York</th>\n",
       "      <td>141297</td>\n",
       "      <td>19651127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Texas</th>\n",
       "      <td>695662</td>\n",
       "      <td>26448193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              area  population\n",
       "California  423967    38332521\n",
       "Florida     170312    19552860\n",
       "Illinois    149995    12882135\n",
       "New York    141297    19651127\n",
       "Texas       695662    26448193"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "states = pd.DataFrame({'population': population,\n",
    "                       'area': area})\n",
    "states"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Like the ``Series`` object, the ``DataFrame`` has an ``index`` attribute that gives access to the index labels:"
  },
  {
   "metadata": {
    "id": "io1hyL-MpWPj",
    "outputId": "2b96b5d8-3a91-44a0-abbf-ba22b7a96269"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['California', 'Florida', 'Illinois', 'New York', 'Texas'], dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "states.index"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Additionally, the ``DataFrame`` has a ``columns`` attribute, which is an ``Index`` object holding the column labels:"
  },
  {
   "metadata": {
    "id": "w9obQe88pWPj",
    "outputId": "30cc8c4f-e3da-4182-ac8a-361ccb2d8f4f"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['area', 'population'], dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "states.columns"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Thus the ``DataFrame`` can be thought of as a generalization of a two-dimensional NumPy array, where both the rows and columns have a generalized index for accessing the data."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### DataFrame as specialized dictionary\n",
    "\n",
    "Similarly, we can also think of a ``DataFrame`` as a specialization of a dictionary.\n",
    "Where a dictionary maps a key to a value, a ``DataFrame`` maps a column name to a ``Series`` of column data.\n",
    "For example, asking for the ``'area'`` attribute returns the ``Series`` object containing the areas we saw earlier:"
   ]
  },
  {
   "metadata": {
    "id": "KUCjyw7ZpWPk",
    "outputId": "7ce331b4-b52f-4ad7-d070-29cc377599f9"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "California    423967\n",
       "Florida       170312\n",
       "Illinois      149995\n",
       "New York      141297\n",
       "Texas         695662\n",
       "Name: area, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "states['area']"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Notice the potential point of confusion here: in a two-dimesnional NumPy array, ``data[0]`` will return the first *row*. For a ``DataFrame``, ``data['col0']`` will return the first *column*.\n",
    "Because of this, it is probably better to think about ``DataFrame``s as generalized dictionaries rather than generalized arrays, though both ways of looking at the situation can be useful.\n",
    "We'll explore more flexible means of indexing ``DataFrame``s in [Data Indexing and Selection](03.02-Data-Indexing-and-Selection.ipynb)."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Constructing DataFrame objects\n",
    "\n",
    "A Pandas ``DataFrame`` can be constructed in a variety of ways.\n",
    "Here we'll give several examples."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### From a single Series object\n",
    "\n",
    "A ``DataFrame`` is a collection of ``Series`` objects, and a single-column ``DataFrame`` can be constructed from a single ``Series``:"
   ]
  },
  {
   "metadata": {
    "id": "F-IvweUlpWPl",
    "outputId": "3f4f1b2d-3f42-4a59-a1bd-1d6b3a393408"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <td>38332521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Florida</th>\n",
       "      <td>19552860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Illinois</th>\n",
       "      <td>12882135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York</th>\n",
       "      <td>19651127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Texas</th>\n",
       "      <td>26448193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            population\n",
       "California    38332521\n",
       "Florida       19552860\n",
       "Illinois      12882135\n",
       "New York      19651127\n",
       "Texas         26448193"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "pd.DataFrame(population, columns=['population'])"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### From a list of dicts\n",
    "\n",
    "Any list of dictionaries can be made into a ``DataFrame``.\n",
    "We'll use a simple list comprehension to create some data:"
   ]
  },
  {
   "metadata": {
    "id": "axiuPgUjpWPl",
    "outputId": "af590fef-2a5d-4fc3-9aba-f11c52704932"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b\n",
       "0  0  0\n",
       "1  1  2\n",
       "2  2  4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "data = [{'a': i, 'b': 2 * i}\n",
    "        for i in range(3)]\n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Even if some keys in the dictionary are missing, Pandas will fill them in with ``NaN`` (i.e., \"not a number\") values:"
  },
  {
   "metadata": {
    "id": "9WYX2h44pWPl",
    "outputId": "9804d5f1-5cc9-4630-e99c-dd99c6d2fe6a"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     a  b    c\n",
       "0  1.0  2  NaN\n",
       "1  NaN  3  4.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "pd.DataFrame([{'a': 1, 'b': 2}, {'b': 3, 'c': 4}])"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### From a dictionary of Series objects\n",
    "\n",
    "As we saw before, a ``DataFrame`` can be constructed from a dictionary of ``Series`` objects as well:"
   ]
  },
  {
   "metadata": {
    "id": "FDVdkaEBpWPl",
    "outputId": "2dd71800-52e8-4ab4-a2ff-c46622b37497"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <td>423967</td>\n",
       "      <td>38332521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Florida</th>\n",
       "      <td>170312</td>\n",
       "      <td>19552860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Illinois</th>\n",
       "      <td>149995</td>\n",
       "      <td>12882135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York</th>\n",
       "      <td>141297</td>\n",
       "      <td>19651127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Texas</th>\n",
       "      <td>695662</td>\n",
       "      <td>26448193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              area  population\n",
       "California  423967    38332521\n",
       "Florida     170312    19552860\n",
       "Illinois    149995    12882135\n",
       "New York    141297    19651127\n",
       "Texas       695662    26448193"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "pd.DataFrame({'population': population,\n",
    "              'area': area})"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### From a two-dimensional NumPy array\n",
    "\n",
    "Given a two-dimensional array of data, we can create a ``DataFrame`` with any specified column and index names.\n",
    "If omitted, an integer index will be used for each:"
   ]
  },
  {
   "metadata": {
    "id": "IzqFFOw2pWPm",
    "outputId": "96c7ec31-734c-4c97-a1e7-98fa2aec7869"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>foo</th>\n",
       "      <th>bar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>0.865257</td>\n",
       "      <td>0.213169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0.442759</td>\n",
       "      <td>0.108267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>0.047110</td>\n",
       "      <td>0.905718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        foo       bar\n",
       "a  0.865257  0.213169\n",
       "b  0.442759  0.108267\n",
       "c  0.047110  0.905718"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "pd.DataFrame(np.random.rand(3, 2),\n",
    "             columns=['foo', 'bar'],\n",
    "             index=['a', 'b', 'c'])"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### From a NumPy structured array\n",
    "\n",
    "We covered structured arrays in [Structured Data: NumPy's Structured Arrays](02.09-Structured-Data-NumPy.ipynb).\n",
    "A Pandas ``DataFrame`` operates much like a structured array, and can be created directly from one:"
   ]
  },
  {
   "metadata": {
    "id": "nQVRYInMpWPm",
    "outputId": "3c288f52-6020-4ff5-f9a5-b317c23bc0c4"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(0, 0.0), (0, 0.0), (0, 0.0)], \n",
       "      dtype=[('A', '<i8'), ('B', '<f8')])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "A = np.zeros(3, dtype=[('A', 'i8'), ('B', 'f8')])\n",
    "A"
   ]
  },
  {
   "metadata": {
    "id": "V4I0wIhfpWPm",
    "outputId": "2a523007-eef3-4690-d087-bfe22ff83dd6"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A    B\n",
       "0  0  0.0\n",
       "1  0  0.0\n",
       "2  0  0.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "pd.DataFrame(A)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## The Pandas Index Object\n",
    "\n",
    "We have seen here that both the ``Series`` and ``DataFrame`` objects contain an explicit *index* that lets you reference and modify data.\n",
    "This ``Index`` object is an interesting structure in itself, and it can be thought of either as an *immutable array* or as an *ordered set* (technically a multi-set, as ``Index`` objects may contain repeated values).\n",
    "Those views have some interesting consequences in the operations available on ``Index`` objects.\n",
    "As a simple example, let's construct an ``Index`` from a list of integers:"
   ]
  },
  {
   "metadata": {
    "id": "WsRLsp0zpWPn",
    "outputId": "14f64c6c-5ce8-4f40-81a7-e59c9b428911"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([2, 3, 5, 7, 11], dtype='int64')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "ind = pd.Index([2, 3, 5, 7, 11])\n",
    "ind"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Index as immutable array\n",
    "\n",
    "The ``Index`` in many ways operates like an array.\n",
    "For example, we can use standard Python indexing notation to retrieve values or slices:"
   ]
  },
  {
   "metadata": {
    "id": "yUjpugcLpWPn",
    "outputId": "746514d5-51c5-4a1b-82d5-5cece55b520e"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "ind[1]"
  },
  {
   "metadata": {
    "id": "qE5pwoeEpWPo",
    "outputId": "148b936c-508e-4e30-df5d-774dc8f250c6"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([2, 5, 11], dtype='int64')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "ind[::2]"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "``Index`` objects also have many of the attributes familiar from NumPy arrays:"
  },
  {
   "metadata": {
    "id": "FX-qNxr7pWPo",
    "outputId": "c1819d70-f6cc-4b5f-9d91-3ceb7cd8c3f2"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 (5,) 1 int64\n"
     ]
    }
   ],
   "execution_count": null,
   "source": "print(ind.size, ind.shape, ind.ndim, ind.dtype)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "One difference between ``Index`` objects and NumPy arrays is that indices are immutable–that is, they cannot be modified via the normal means:"
  },
  {
   "metadata": {
    "id": "6jwEzh0YpWPp",
    "outputId": "6d5dd99f-6819-4872-8db6-9f53b4c79f00"
   },
   "cell_type": "code",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Index does not support mutable operations",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-34-40e631c82e8a>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mind\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/Users/jakevdp/anaconda/lib/python3.5/site-packages/pandas/indexes/base.py\u001B[0m in \u001B[0;36m__setitem__\u001B[0;34m(self, key, value)\u001B[0m\n\u001B[1;32m   1243\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1244\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__setitem__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1245\u001B[0;31m         \u001B[0;32mraise\u001B[0m \u001B[0mTypeError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Index does not support mutable operations\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1246\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1247\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__getitem__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: Index does not support mutable operations"
     ]
    }
   ],
   "execution_count": null,
   "source": "ind[1] = 0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This immutability makes it safer to share indices between multiple ``DataFrame``s and arrays, without the potential for side effects from inadvertent index modification."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Index as ordered set\n",
    "\n",
    "Pandas objects are designed to facilitate operations such as joins across datasets, which depend on many aspects of set arithmetic.\n",
    "The ``Index`` object follows many of the conventions used by Python's built-in ``set`` data structure, so that unions, intersections, differences, and other combinations can be computed in a familiar way:"
   ]
  },
  {
   "metadata": {
    "id": "U4O0yNoIpWPp"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "indA = pd.Index([1, 3, 5, 7, 9])\n",
    "indB = pd.Index([2, 3, 5, 7, 11])"
   ]
  },
  {
   "metadata": {
    "id": "kCl80L9JpWPq",
    "outputId": "becb908b-6e20-43d9-9df1-7afc8f8f941d"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([3, 5, 7], dtype='int64')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "indA & indB  # intersection"
  },
  {
   "metadata": {
    "id": "Zz51562dpWPq",
    "outputId": "bda9dd19-aa30-486c-e53b-a42de56839d7"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([1, 2, 3, 5, 7, 9, 11], dtype='int64')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "indA | indB  # union"
  },
  {
   "metadata": {
    "id": "GxolZvmBpWPq",
    "outputId": "a298973c-51d3-4d01-f8f6-1de8500a26f1"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([1, 2, 9, 11], dtype='int64')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "indA ^ indB  # symmetric difference"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "These operations may also be accessed via object methods, for example ``indA.intersection(indB)``."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<!--NAVIGATION-->\n",
    "< [Data Manipulation with Pandas](03.00-Introduction-to-Pandas.ipynb) | [Contents](Index.ipynb) | [Data Indexing and Selection](03.02-Data-Indexing-and-Selection.ipynb) >\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.01-Introducing-Pandas-Objects.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "For this exercise we create following simple series:"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T15:14:19.140624Z",
     "start_time": "2025-02-13T15:14:18.559069Z"
    },
    "id": "initial_id"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "s_a = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])\n",
    "s_a2 = pd.Series([\"one\", \"two\", \"three\", \"four\"], index=['a', 'b', 'c', 'd'])\n",
    "s_a3 = pd.Series([\"one\", \"two\", \"three\", \"four\"], index=['d', 'c', 'b', 'a'])"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Series basics\n",
    "a. print the values of s_a\\\n",
    "b. print the index of s_a\\\n",
    "c. print the data type of s_a\\\n",
    "d. print the shape of s_a\\\n",
    "e. print the number of dimensions of s_a\\\n",
    "f. print the size of s_a\\\n",
    "g. print the memory usage of s_a\\\n"
   ]
  },
  {
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2025-02-13T15:14:19.155260Z",
     "start_time": "2025-02-13T15:14:19.148195Z"
    },
    "id": "7bd051dc74d4cbd9",
    "outputId": "beb366e0-9d92-49c9-bb95-bd32d6658e5c"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n",
      "Index(['a', 'b', 'c', 'd'], dtype='object')\n",
      "int64\n",
      "(4,)\n",
      "1\n",
      "4\n",
      "64\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "#\n",
    "#SOLUTION_START\n",
    "#a\n",
    "print(s_a.values)\n",
    "#b\n",
    "print(s_a.index)\n",
    "#c\n",
    "print(s_a.dtype)\n",
    "#d\n",
    "print(s_a.shape)\n",
    "#e\n",
    "print(s_a.ndim)\n",
    "#f\n",
    "print(s_a.size)\n",
    "#g\n",
    "print(s_a.memory_usage())\n",
    "\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Creating Series\n",
    "a. create a Series s_b with the same values as s_a but with an index of [1,2,3,4].\\\n",
    "b. create a Series s_c with the same values as s_b, but with a data type of int8 instead of int64. Check the difference in memory usage between s_b and s_c.\\\n",
    "c. create a Series s_d with the same values as s_b, but use np.arange() to define the index. The range should start at 1 and end at the number of elements in s_d.\\\n",
    "d. create a Series s_e with the same values, but use a dictionary to define the Series.\\\n",
    "e. create a Series s_f with the index the numbers written out as strings (e.g. 'one', 'two', 'three', 'four')."
   ]
  },
  {
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2025-02-13T15:14:19.850656Z",
     "start_time": "2025-02-13T15:14:19.838911Z"
    },
    "id": "868cef7de0d2f13e",
    "outputId": "6d5d4f57-9b47-4ef5-ae5a-d1bb88a3e672"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    1\n",
      "2    2\n",
      "3    3\n",
      "4    4\n",
      "dtype: int64\n",
      "Memory usage s_b: 64 - Memory usage s_c: 8\n",
      "Index([1, 2, 3, 4], dtype='int8')\n",
      "Index([1, 2, 3, 4], dtype='int8')\n",
      "1    1\n",
      "2    2\n",
      "3    3\n",
      "4    4\n",
      "dtype: int64\n",
      "one      1\n",
      "two      2\n",
      "three    3\n",
      "four     4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "# a\n",
    "s_b = pd.Series(s_a.values, index=[1, 2, 3, 4])\n",
    "print(s_b)\n",
    "# b\n",
    "s_c = pd.Series(s_b.values, index=pd.Index([1, 2, 3, 4],dtype='int8'), dtype='int8')\n",
    "print(f'Memory usage s_b: {s_b.memory_usage()} - Memory usage s_c: {s_c.memory_usage()}')\n",
    "# c\n",
    "s_d = pd.Series(s_b.values, index=np.arange(1, s_b.size+1, dtype='int8'))\n",
    "print(s_c.index)\n",
    "print(s_d.index)\n",
    "# d\n",
    "s_e = pd.Series({1:1, 2:2, 3:3, 4:4})\n",
    "print(s_e)\n",
    "#e\n",
    "s_f = pd.Series(s_a.values, index=['one', 'two', 'three', 'four'])\n",
    "print(s_f)\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3. Dataframes basics and creation\n",
    "a. create a DataFrame df_a with s_a and s_a2 as columns.\\\n",
    "b. Look at the creation of s_a2 and s_a3 in the first cell. You are going to create a DataFrame df_b with s_a2 and s_a3 as columns. Before doing that, try to predict how the dataframe will look like. Then create the DataFrame. Did you expect this result? Can you explain why the values are not aligned?\\\n",
    "c. create a Dataframe df_c based on a two-dimensional numpy array created with np.arange() and shape (3,4).\\\n",
    "d. create a Dataframe df_d like df_c. The index should be ['a', 'b', 'c'] and the columns should be ['x', 'y', 'z', 'w'].\\\n",
    "e.  Try to change te first indexvalue of df_c. What happens? Can you explain why this happens?"
   ]
  },
  {
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2025-02-13T15:14:20.446153Z",
     "start_time": "2025-02-13T15:14:19.927330Z"
    },
    "id": "7c5010a0ca9ac9db",
    "outputId": "a0894248-d802-4edd-94d6-d90f29ad2a6d"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   s_a   s_a2\n",
      "a    1    one\n",
      "b    2    two\n",
      "c    3  three\n",
      "d    4   four\n",
      "     s_a   s_a3\n",
      "a    one   four\n",
      "b    two  three\n",
      "c  three    two\n",
      "d   four    one\n",
      "   0  1   2   3\n",
      "0  0  1   2   3\n",
      "1  4  5   6   7\n",
      "2  8  9  10  11\n",
      "   x  y   z   w\n",
      "a  0  1   2   3\n",
      "b  4  5   6   7\n",
      "c  8  9  10  11\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Index does not support mutable operations",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 16\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28mprint\u001B[39m(df_d)\n\u001B[0;32m     15\u001B[0m \u001B[38;5;66;03m#e\u001B[39;00m\n\u001B[1;32m---> 16\u001B[0m \u001B[43mdf_d\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124md\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;66;03m#This gives an error because the index is immutable.This immutability makes it safer to share indices between multiple ``DataFrame``s and arrays, without the potential for side effects from inadvertent index modification.\u001B[39;00m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;66;03m#SOLUTION_END\u001B[39;00m\n",
      "File \u001B[1;32m~\\venv\\DS2\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5371\u001B[0m, in \u001B[0;36mIndex.__setitem__\u001B[1;34m(self, key, value)\u001B[0m\n\u001B[0;32m   5369\u001B[0m \u001B[38;5;129m@final\u001B[39m\n\u001B[0;32m   5370\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__setitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, key, value) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 5371\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIndex does not support mutable operations\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mTypeError\u001B[0m: Index does not support mutable operations"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "# a\n",
    "df_a = pd.DataFrame({'s_a': s_a, 's_a2': s_a2})\n",
    "print(df_a)\n",
    "# b\n",
    "df_b = pd.DataFrame({'s_a': s_a2, 's_a3': s_a3})\n",
    "print(df_b)\n",
    "#The index values of s_a2 and s_a3 are not used in the samen order. Pandas uses the index values to align the data.\n",
    "# c\n",
    "df_c = pd.DataFrame(np.arange(12).reshape(3,4))\n",
    "print(df_c)\n",
    "#d\n",
    "df_d = pd.DataFrame(np.arange(12).reshape(3,4), index=['a', 'b', 'c'], columns=['x', 'y', 'z', 'w'])\n",
    "print(df_d)\n",
    "#e\n",
    "df_d.index[0] = 'd'\n",
    "#This gives an error because the index is immutable.This immutability makes it safer to share indices between multiple ``DataFrame``s and arrays, without the potential for side effects from inadvertent index modification.\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<!--BOOK_INFORMATION-->\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"figures/PDSH-cover-small.png\">\n",
    "\n",
    "*This notebook contains an excerpt from the [Python Data Science Handbook](http://shop.oreilly.com/product/0636920034919.do) by Jake VanderPlas; the content is available [on GitHub](https://github.com/jakevdp/PythonDataScienceHandbook).*\n",
    "\n",
    "*The text is released under the [CC-BY-NC-ND license](https://creativecommons.org/licenses/by-nc-nd/3.0/us/legalcode), and code is released under the [MIT license](https://opensource.org/licenses/MIT). If you find this content useful, please consider supporting the work by [buying the book](http://shop.oreilly.com/product/0636920034919.do)!*"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<!--NAVIGATION-->\n",
    "< [Introducing Pandas Objects](03.01-Introducing-Pandas-Objects.ipynb) | [Contents](Index.ipynb) | [Operating on Data in Pandas](03.03-Operations-in-Pandas.ipynb) >\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.02-Data-Indexing-and-Selection.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data Indexing and Selection"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In [Chapter 2](02.00-Introduction-to-NumPy.ipynb), we looked in detail at methods and tools to access, set, and modify values in NumPy arrays.\n",
    "These included indexing (e.g., ``arr[2, 1]``), slicing (e.g., ``arr[:, 1:5]``), masking (e.g., ``arr[arr > 0]``), fancy indexing (e.g., ``arr[0, [1, 5]]``), and combinations thereof (e.g., ``arr[:, [1, 5]]``).\n",
    "Here we'll look at similar means of accessing and modifying values in Pandas ``Series`` and ``DataFrame`` objects.\n",
    "If you have used the NumPy patterns, the corresponding patterns in Pandas will feel very familiar, though there are a few quirks to be aware of.\n",
    "\n",
    "We'll start with the simple case of the one-dimensional ``Series`` object, and then move on to the more complicated two-dimesnional ``DataFrame`` object."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data Selection in Series\n",
    "\n",
    "As we saw in the previous section, a ``Series`` object acts in many ways like a one-dimensional NumPy array, and in many ways like a standard Python dictionary.\n",
    "If we keep these two overlapping analogies in mind, it will help us to understand the patterns of data indexing and selection in these arrays."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Series as dictionary\n",
    "\n",
    "Like a dictionary, the ``Series`` object provides a mapping from a collection of keys to a collection of values:"
   ]
  },
  {
   "metadata": {
    "id": "q9mfW_VxpXdW",
    "outputId": "aedc899f-7523-4bb4-cda5-3fa50ee3e68c"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    0.25\n",
       "b    0.50\n",
       "c    0.75\n",
       "d    1.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "data = pd.Series([0.25, 0.5, 0.75, 1.0],\n",
    "                 index=['a', 'b', 'c', 'd'])\n",
    "data"
   ]
  },
  {
   "metadata": {
    "id": "UNJPfgsdpXdX",
    "outputId": "b7ac045a-7dce-4b2b-c356-05f0671f970e"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "data['b']"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can also use dictionary-like Python expressions and methods to examine the keys/indices and values:"
  },
  {
   "metadata": {
    "id": "CGzEZA60pXdY",
    "outputId": "2e27090b-1c99-4c3b-cb15-0045a9a19027"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "'a' in data"
  },
  {
   "metadata": {
    "id": "Xf-UsWEXpXdY",
    "outputId": "1b9aed6e-9faf-404d-d1c7-a1b635a21ee5"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['a', 'b', 'c', 'd'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "data.keys()"
  },
  {
   "metadata": {
    "id": "V4LzyqQgpXdY",
    "outputId": "04d9cb34-29f1-405e-e34f-4b5e983ba533"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 0.25), ('b', 0.5), ('c', 0.75), ('d', 1.0)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "list(data.items())"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "``Series`` objects can even be modified with a dictionary-like syntax.\n",
    "Just as you can extend a dictionary by assigning to a new key, you can extend a ``Series`` by assigning to a new index value:"
   ]
  },
  {
   "metadata": {
    "id": "9E1pFnjvpXdZ",
    "outputId": "e4637629-5f2e-4c80-8e1b-277cbd333cbc"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    0.25\n",
       "b    0.50\n",
       "c    0.75\n",
       "d    1.00\n",
       "e    1.25\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "data['e'] = 1.25\n",
    "data"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This easy mutability of the objects is a convenient feature: under the hood, Pandas is making decisions about memory layout and data copying that might need to take place; the user generally does not need to worry about these issues."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Series as one-dimensional array"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "A ``Series`` builds on this dictionary-like interface and provides array-style item selection via the same basic mechanisms as NumPy arrays – that is, *slices*, *masking*, and *fancy indexing*.\n",
    "Examples of these are as follows:"
   ]
  },
  {
   "metadata": {
    "id": "M2r19f-3pXda",
    "outputId": "7097ed33-96c0-416b-ad49-1b761bd485b2"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    0.25\n",
       "b    0.50\n",
       "c    0.75\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "# slicing by explicit index\n",
    "data['a':'c']"
   ]
  },
  {
   "metadata": {
    "id": "GVPTFH0CpXda",
    "outputId": "e665fba0-1db9-4758-a41a-4719e56f5b7a"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    0.25\n",
       "b    0.50\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "# slicing by implicit integer index\n",
    "data[0:2]"
   ]
  },
  {
   "metadata": {
    "id": "mGYaLGcspXda",
    "outputId": "38476e6b-585e-44a8-87eb-2e943a6683e8"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b    0.50\n",
       "c    0.75\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "# masking\n",
    "data[(data > 0.3) & (data < 0.8)]"
   ]
  },
  {
   "metadata": {
    "id": "JEfnGCmLpXdb",
    "outputId": "8ef0b91e-fdb0-46e2-9a08-359eb17b1422"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    0.25\n",
       "e    1.25\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "# fancy indexing\n",
    "data[['a', 'e']]"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Among these, slicing may be the source of the most confusion.\n",
    "Notice that when slicing with an explicit index (i.e., ``data['a':'c']``), the final index is *included* in the slice, while when slicing with an implicit index (i.e., ``data[0:2]``), the final index is *excluded* from the slice."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Indexers: loc, iloc, and ix\n",
    "\n",
    "These slicing and indexing conventions can be a source of confusion.\n",
    "For example, if your ``Series`` has an explicit integer index, an indexing operation such as ``data[1]`` will use the explicit indices, while a slicing operation like ``data[1:3]`` will use the implicit Python-style index."
   ]
  },
  {
   "metadata": {
    "id": "00vRptUhpXdb",
    "outputId": "01161b08-c5d8-4796-e1a4-1dbc55e1fa0c"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    a\n",
       "3    b\n",
       "5    c\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "data = pd.Series(['a', 'b', 'c'], index=[1, 3, 5])\n",
    "data"
   ]
  },
  {
   "metadata": {
    "id": "c3n2MUiupXdb",
    "outputId": "e2778557-d1d1-47ad-abcc-0c089310c1a2"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "# explicit index when indexing\n",
    "data[1]"
   ]
  },
  {
   "metadata": {
    "id": "Vj_GK2FBpXdc",
    "outputId": "4c414a85-9c7a-466c-e598-00b70fad2017"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    b\n",
       "5    c\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "# implicit index when slicing\n",
    "data[1:3]"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Because of this potential confusion in the case of integer indexes, Pandas provides some special *indexer* attributes that explicitly expose certain indexing schemes.\n",
    "These are not functional methods, but attributes that expose a particular slicing interface to the data in the ``Series``.\n",
    "\n",
    "First, the ``loc`` attribute allows indexing and slicing that always references the explicit index:"
   ]
  },
  {
   "metadata": {
    "id": "Y1DCFf9LpXdc",
    "outputId": "fc64d369-cda8-4b1b-9362-9bf4cb92de5d"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "data.loc[1]"
  },
  {
   "metadata": {
    "id": "_T8Ruf3ppXdc",
    "outputId": "039a362b-5b0e-44f9-80f8-5fb4a263e06f"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    a\n",
       "3    b\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "data.loc[1:3]"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The ``iloc`` attribute allows indexing and slicing that always references the implicit Python-style index:"
  },
  {
   "metadata": {
    "id": "4ysr2FgrpXdc",
    "outputId": "cd10e8fb-fb53-48eb-a91c-974b90746893"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "data.iloc[1]"
  },
  {
   "metadata": {
    "id": "jsNsbZmcpXdc",
    "outputId": "c1c3a25f-57e3-44e0-e15f-4b8dc63de57d"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    b\n",
       "5    c\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "data.iloc[1:3]"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "A third indexing attribute, ``ix``, is a hybrid of the two, and for ``Series`` objects is equivalent to standard ``[]``-based indexing.\n",
    "The purpose of the ``ix`` indexer will become more apparent in the context of ``DataFrame`` objects, which we will discuss in a moment.\n",
    "\n",
    "One guiding principle of Python code is that \"explicit is better than implicit.\"\n",
    "The explicit nature of ``loc`` and ``iloc`` make them very useful in maintaining clean and readable code; especially in the case of integer indexes, I recommend using these both to make code easier to read and understand, and to prevent subtle bugs due to the mixed indexing/slicing convention."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data Selection in DataFrame\n",
    "\n",
    "Recall that a ``DataFrame`` acts in many ways like a two-dimensional or structured array, and in other ways like a dictionary of ``Series`` structures sharing the same index.\n",
    "These analogies can be helpful to keep in mind as we explore data selection within this structure."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### DataFrame as a dictionary\n",
    "\n",
    "The first analogy we will consider is the ``DataFrame`` as a dictionary of related ``Series`` objects.\n",
    "Let's return to our example of areas and populations of states:"
   ]
  },
  {
   "metadata": {
    "id": "H5BuQhoopXdd",
    "outputId": "99942de4-8417-40aa-ab33-95dcb8f80e5b"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <td>423967</td>\n",
       "      <td>38332521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Florida</th>\n",
       "      <td>170312</td>\n",
       "      <td>19552860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Illinois</th>\n",
       "      <td>149995</td>\n",
       "      <td>12882135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York</th>\n",
       "      <td>141297</td>\n",
       "      <td>19651127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Texas</th>\n",
       "      <td>695662</td>\n",
       "      <td>26448193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              area       pop\n",
       "California  423967  38332521\n",
       "Florida     170312  19552860\n",
       "Illinois    149995  12882135\n",
       "New York    141297  19651127\n",
       "Texas       695662  26448193"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "area = pd.Series({'California': 423967, 'Texas': 695662,\n",
    "                  'New York': 141297, 'Florida': 170312,\n",
    "                  'Illinois': 149995})\n",
    "pop = pd.Series({'California': 38332521, 'Texas': 26448193,\n",
    "                 'New York': 19651127, 'Florida': 19552860,\n",
    "                 'Illinois': 12882135})\n",
    "data = pd.DataFrame({'area':area, 'pop':pop})\n",
    "data"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The individual ``Series`` that make up the columns of the ``DataFrame`` can be accessed via dictionary-style indexing of the column name:"
  },
  {
   "metadata": {
    "id": "aZg2A7YgpXde",
    "outputId": "a6b0882c-217b-4058-a175-1bae1590c744"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "California    423967\n",
       "Florida       170312\n",
       "Illinois      149995\n",
       "New York      141297\n",
       "Texas         695662\n",
       "Name: area, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "data['area']"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Equivalently, we can use attribute-style access with column names that are strings:"
  },
  {
   "metadata": {
    "id": "kq72KsIXpXdn",
    "outputId": "67abddab-bc54-4094-f2b4-a8f8940fe2a7"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "California    423967\n",
       "Florida       170312\n",
       "Illinois      149995\n",
       "New York      141297\n",
       "Texas         695662\n",
       "Name: area, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "data.area"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This attribute-style column access actually accesses the exact same object as the dictionary-style access:"
  },
  {
   "metadata": {
    "id": "vvOWkK4opXdn",
    "outputId": "60cb2070-7801-4c10-c793-bba5ab6daabd"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "data.area is data['area']"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Though this is a useful shorthand, keep in mind that it does not work for all cases!\n",
    "For example, if the column names are not strings, or if the column names conflict with methods of the ``DataFrame``, this attribute-style access is not possible.\n",
    "For example, the ``DataFrame`` has a ``pop()`` method, so ``data.pop`` will point to this rather than the ``\"pop\"`` column:"
   ]
  },
  {
   "metadata": {
    "id": "rCkfY9TypXdn",
    "outputId": "3915afde-cd4b-4959-b2d7-b70f722026a7"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "data.pop is data['pop']"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In particular, you should avoid the temptation to try column assignment via attribute (i.e., use ``data['pop'] = z`` rather than ``data.pop = z``).\n",
    "\n",
    "Like with the ``Series`` objects discussed earlier, this dictionary-style syntax can also be used to modify the object, in this case adding a new column:"
   ]
  },
  {
   "metadata": {
    "id": "Ru_I8HMrpXdo",
    "outputId": "ea5f72fc-b153-4477-a18b-4bc1a8ce0a77"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>pop</th>\n",
       "      <th>density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <td>423967</td>\n",
       "      <td>38332521</td>\n",
       "      <td>90.413926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Florida</th>\n",
       "      <td>170312</td>\n",
       "      <td>19552860</td>\n",
       "      <td>114.806121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Illinois</th>\n",
       "      <td>149995</td>\n",
       "      <td>12882135</td>\n",
       "      <td>85.883763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York</th>\n",
       "      <td>141297</td>\n",
       "      <td>19651127</td>\n",
       "      <td>139.076746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Texas</th>\n",
       "      <td>695662</td>\n",
       "      <td>26448193</td>\n",
       "      <td>38.018740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              area       pop     density\n",
       "California  423967  38332521   90.413926\n",
       "Florida     170312  19552860  114.806121\n",
       "Illinois    149995  12882135   85.883763\n",
       "New York    141297  19651127  139.076746\n",
       "Texas       695662  26448193   38.018740"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "data['density'] = data['pop'] / data['area']\n",
    "data"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This shows a preview of the straightforward syntax of element-by-element arithmetic between ``Series`` objects; we'll dig into this further in [Operating on Data in Pandas](03.03-Operations-in-Pandas.ipynb)."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### DataFrame as two-dimensional array\n",
    "\n",
    "As mentioned previously, we can also view the ``DataFrame`` as an enhanced two-dimensional array.\n",
    "We can examine the raw underlying data array using the ``values`` attribute:"
   ]
  },
  {
   "metadata": {
    "id": "3uunWKq4pXdo",
    "outputId": "467c82c6-e259-49cb-b095-871623debbe9"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.23967000e+05,   3.83325210e+07,   9.04139261e+01],\n",
       "       [  1.70312000e+05,   1.95528600e+07,   1.14806121e+02],\n",
       "       [  1.49995000e+05,   1.28821350e+07,   8.58837628e+01],\n",
       "       [  1.41297000e+05,   1.96511270e+07,   1.39076746e+02],\n",
       "       [  6.95662000e+05,   2.64481930e+07,   3.80187404e+01]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "data.values"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "With this picture in mind, many familiar array-like observations can be done on the ``DataFrame`` itself.\n",
    "For example, we can transpose the full ``DataFrame`` to swap rows and columns:"
   ]
  },
  {
   "metadata": {
    "id": "lF9WwyvqpXdo",
    "outputId": "48823962-1a1a-4530-9696-ec6ecd5ff86e"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>California</th>\n",
       "      <th>Florida</th>\n",
       "      <th>Illinois</th>\n",
       "      <th>New York</th>\n",
       "      <th>Texas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>area</th>\n",
       "      <td>4.239670e+05</td>\n",
       "      <td>1.703120e+05</td>\n",
       "      <td>1.499950e+05</td>\n",
       "      <td>1.412970e+05</td>\n",
       "      <td>6.956620e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pop</th>\n",
       "      <td>3.833252e+07</td>\n",
       "      <td>1.955286e+07</td>\n",
       "      <td>1.288214e+07</td>\n",
       "      <td>1.965113e+07</td>\n",
       "      <td>2.644819e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>density</th>\n",
       "      <td>9.041393e+01</td>\n",
       "      <td>1.148061e+02</td>\n",
       "      <td>8.588376e+01</td>\n",
       "      <td>1.390767e+02</td>\n",
       "      <td>3.801874e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           California       Florida      Illinois      New York         Texas\n",
       "area     4.239670e+05  1.703120e+05  1.499950e+05  1.412970e+05  6.956620e+05\n",
       "pop      3.833252e+07  1.955286e+07  1.288214e+07  1.965113e+07  2.644819e+07\n",
       "density  9.041393e+01  1.148061e+02  8.588376e+01  1.390767e+02  3.801874e+01"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "data.T"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "When it comes to indexing of ``DataFrame`` objects, however, it is clear that the dictionary-style indexing of columns precludes our ability to simply treat it as a NumPy array.\n",
    "In particular, passing a single index to an array accesses a row:"
   ]
  },
  {
   "metadata": {
    "id": "CA9j0Lb4pXdp",
    "outputId": "333320b9-83d3-4a9c-d902-34a4a5efcc4e"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4.23967000e+05,   3.83325210e+07,   9.04139261e+01])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "data.values[0]"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "and passing a single \"index\" to a ``DataFrame`` accesses a column:"
  },
  {
   "metadata": {
    "id": "rBcT2Oi8pXdp",
    "outputId": "c913c2e1-0ff9-4cb9-d8a4-456fea0bed7b"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "California    423967\n",
       "Florida       170312\n",
       "Illinois      149995\n",
       "New York      141297\n",
       "Texas         695662\n",
       "Name: area, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "data['area']"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Thus for array-style indexing, we need another convention.\n",
    "Here Pandas again uses the ``loc``, ``iloc``, and ``ix`` indexers mentioned earlier.\n",
    "Using the ``iloc`` indexer, we can index the underlying array as if it is a simple NumPy array (using the implicit Python-style index), but the ``DataFrame`` index and column labels are maintained in the result:"
   ]
  },
  {
   "metadata": {
    "id": "vHTYGxT_pXdq",
    "outputId": "b7894ced-8a37-4b8d-aac6-2dde21854ae0"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <td>423967</td>\n",
       "      <td>38332521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Florida</th>\n",
       "      <td>170312</td>\n",
       "      <td>19552860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Illinois</th>\n",
       "      <td>149995</td>\n",
       "      <td>12882135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              area       pop\n",
       "California  423967  38332521\n",
       "Florida     170312  19552860\n",
       "Illinois    149995  12882135"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "data.iloc[:3, :2]"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Similarly, using the ``loc`` indexer we can index the underlying data in an array-like style but using the explicit index and column names:"
  },
  {
   "metadata": {
    "id": "3q3DQx9epXdq",
    "outputId": "ca456d95-d61a-4160-d597-401b3f859be3"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <td>423967</td>\n",
       "      <td>38332521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Florida</th>\n",
       "      <td>170312</td>\n",
       "      <td>19552860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Illinois</th>\n",
       "      <td>149995</td>\n",
       "      <td>12882135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              area       pop\n",
       "California  423967  38332521\n",
       "Florida     170312  19552860\n",
       "Illinois    149995  12882135"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "data.loc[:'Illinois', :'pop']"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The ``ix`` indexer allows a hybrid of these two approaches:"
  },
  {
   "metadata": {
    "id": "2UMnOxk1pXdq",
    "outputId": "2fae673c-27c3-4f01-8844-de91c3f6567c"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <td>423967</td>\n",
       "      <td>38332521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Florida</th>\n",
       "      <td>170312</td>\n",
       "      <td>19552860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Illinois</th>\n",
       "      <td>149995</td>\n",
       "      <td>12882135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              area       pop\n",
       "California  423967  38332521\n",
       "Florida     170312  19552860\n",
       "Illinois    149995  12882135"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "data.ix[:3, :'pop']"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Keep in mind that for integer indices, the ``ix`` indexer is subject to the same potential sources of confusion as discussed for integer-indexed ``Series`` objects.\n",
    "\n",
    "Any of the familiar NumPy-style data access patterns can be used within these indexers.\n",
    "For example, in the ``loc`` indexer we can combine masking and fancy indexing as in the following:"
   ]
  },
  {
   "metadata": {
    "id": "ig973JF9pXdq",
    "outputId": "f3464898-7fe4-4ccd-b820-9da53c019298"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pop</th>\n",
       "      <th>density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Florida</th>\n",
       "      <td>19552860</td>\n",
       "      <td>114.806121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York</th>\n",
       "      <td>19651127</td>\n",
       "      <td>139.076746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               pop     density\n",
       "Florida   19552860  114.806121\n",
       "New York  19651127  139.076746"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "data.loc[data.density > 100, ['pop', 'density']]"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Any of these indexing conventions may also be used to set or modify values; this is done in the standard way that you might be accustomed to from working with NumPy:"
  },
  {
   "metadata": {
    "id": "c4baBTeUpXdr",
    "outputId": "7331cf37-b390-48e3-f5f0-670e4f1dd073"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>pop</th>\n",
       "      <th>density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <td>423967</td>\n",
       "      <td>38332521</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Florida</th>\n",
       "      <td>170312</td>\n",
       "      <td>19552860</td>\n",
       "      <td>114.806121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Illinois</th>\n",
       "      <td>149995</td>\n",
       "      <td>12882135</td>\n",
       "      <td>85.883763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York</th>\n",
       "      <td>141297</td>\n",
       "      <td>19651127</td>\n",
       "      <td>139.076746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Texas</th>\n",
       "      <td>695662</td>\n",
       "      <td>26448193</td>\n",
       "      <td>38.018740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              area       pop     density\n",
       "California  423967  38332521   90.000000\n",
       "Florida     170312  19552860  114.806121\n",
       "Illinois    149995  12882135   85.883763\n",
       "New York    141297  19651127  139.076746\n",
       "Texas       695662  26448193   38.018740"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "data.iloc[0, 2] = 90\n",
    "data"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "To build up your fluency in Pandas data manipulation, I suggest spending some time with a simple ``DataFrame`` and exploring the types of indexing, slicing, masking, and fancy indexing that are allowed by these various indexing approaches."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Additional indexing conventions\n",
    "\n",
    "There are a couple extra indexing conventions that might seem at odds with the preceding discussion, but nevertheless can be very useful in practice.\n",
    "First, while *indexing* refers to columns, *slicing* refers to rows:"
   ]
  },
  {
   "metadata": {
    "id": "t88v3qFtpXds",
    "outputId": "4656a502-38f7-4799-8c3e-e9a18c9ded1a"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>pop</th>\n",
       "      <th>density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Florida</th>\n",
       "      <td>170312</td>\n",
       "      <td>19552860</td>\n",
       "      <td>114.806121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Illinois</th>\n",
       "      <td>149995</td>\n",
       "      <td>12882135</td>\n",
       "      <td>85.883763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            area       pop     density\n",
       "Florida   170312  19552860  114.806121\n",
       "Illinois  149995  12882135   85.883763"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "data['Florida':'Illinois']"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Such slices can also refer to rows by number rather than by index:"
  },
  {
   "metadata": {
    "id": "l_dEo7p9pXdt",
    "outputId": "d3e087cb-d915-44f3-a8da-4c202c034c8a"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>pop</th>\n",
       "      <th>density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Florida</th>\n",
       "      <td>170312</td>\n",
       "      <td>19552860</td>\n",
       "      <td>114.806121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Illinois</th>\n",
       "      <td>149995</td>\n",
       "      <td>12882135</td>\n",
       "      <td>85.883763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            area       pop     density\n",
       "Florida   170312  19552860  114.806121\n",
       "Illinois  149995  12882135   85.883763"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "data[1:3]"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Similarly, direct masking operations are also interpreted row-wise rather than column-wise:"
  },
  {
   "metadata": {
    "id": "w3_9NsAJpXdt",
    "outputId": "7bcc6883-1429-46d8-dde4-2b548ed345db"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>pop</th>\n",
       "      <th>density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Florida</th>\n",
       "      <td>170312</td>\n",
       "      <td>19552860</td>\n",
       "      <td>114.806121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York</th>\n",
       "      <td>141297</td>\n",
       "      <td>19651127</td>\n",
       "      <td>139.076746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            area       pop     density\n",
       "Florida   170312  19552860  114.806121\n",
       "New York  141297  19651127  139.076746"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "data[data.density > 100]"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "These two conventions are syntactically similar to those on a NumPy array, and while these may not precisely fit the mold of the Pandas conventions, they are nevertheless quite useful in practice."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<!--NAVIGATION-->\n",
    "< [Introducing Pandas Objects](03.01-Introducing-Pandas-Objects.ipynb) | [Contents](Index.ipynb) | [Operating on Data in Pandas](03.03-Operations-in-Pandas.ipynb) >\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.02-Data-Indexing-and-Selection.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>\n"
   ]
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-11T14:30:47.032245Z",
     "start_time": "2025-02-11T14:30:47.016981Z"
    },
    "id": "initial_id"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.datasets as ds\n",
    "\n",
    "#Data preperation\n",
    "iris_bunch = ds.load_iris(as_frame=True)\n",
    "iris = pd.DataFrame(iris_bunch.data.to_numpy(), index=np.arange(1, 151), columns=iris_bunch.data.columns)\n",
    "iris_sepal_length = iris['sepal length (cm)']\n",
    "iris_sepal_length_b = pd.Series(iris['sepal length (cm)'], index=np.arange(1, 151))\n",
    "# create a dataframe with the countries of europe as the index, with a column population and gbp\n",
    "countries = ['France', 'Germany', 'Italy', 'Spain', 'Portugal', 'Greece', 'Belgium', 'Netherlands', 'Luxembourg', 'Austria', 'Switzerland', 'Denmark', 'Sweden', 'Norway', 'Finland', 'Iceland', 'Ireland', 'United Kingdom']\n",
    "population = [67, 83, 60, 47, 10, 11, 11, 17, 0.6, 9, 8, 6, 10, 5, 5, 0.3, 5, 67]\n",
    "GDP = [2.78, 4.42, 2.08, 1.39, 0.23, 0.18, 0.53, 0.91, 0.06, 0.45, 0.70, 0.35, 0.53, 0.40, 0.27, 0.02, 0.33, 2.83]\n",
    "europe = pd.DataFrame({'population': population, 'GDP': GDP}, index=countries)\n",
    "europe.sort_index(inplace=True)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Selection slicing and dicing\n",
    "### Series objects\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "The iris dataframe is a 150x4 dataframe with properties of iris flowers (To find out more of the dataset visit the dedicated [wikipedia](https://en.wikipedia.org/wiki/Iris_flower_data_set]) page. In the cel above, we also extracted one column of the dataframe.\n",
    "\n",
    "```\n",
    "iris = pd.DataFrame(iris, index=np.arange(1, 151)) #creates a dataframe with an explicit index from 1 to 150\n",
    "iris_sepal_length = iris['sepal length (cm)'] #creates a series with the sepal length of the flowers\n",
    "```\n",
    "a. Excecute iris_sepal_length[0]. What do you get? Why?\\\n",
    "b. Execute iris_sepal_length[1]. What do you get? Why?\\\n",
    "c. Execute iris_sepal_length[1:3]. What do you get? Why?"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:54:52.033402Z",
     "start_time": "2025-02-04T10:54:52.015982Z"
    },
    "id": "59d10586741af830",
    "outputId": "1085e56c-76c8-42aa-ca02-8870a0eefa64"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2    4.9\n",
       "3    4.7\n",
       "Name: sepal length (cm), dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "#iris_sepal_length[0] # This will raise an error. Pandas uses the explicit index (the index we explicitly created when creating the dataFrame (when the explicit index is of the integer type). The one we created is from 1 to 150. The implicit index is from 0 to 149. This tends to be confusing.\n",
    "iris_sepal_length[1] # This will return the sepal length of the first flower. The explicit index is 1.\n",
    "iris_sepal_length[1:3] #When slicing , Pandas uses the implicit index. This will return the sepal length of the second and third flowers.\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Because of the confusion the explicit index can cause with the bracket notation, it is better to use the loc and iloc attributes. You are always sure of what you are getting.\n",
    "\n",
    "d. Use the explicit index to get the first row\\\n",
    "e. Use the implicit index to get the first row\\\n",
    "f. Use the explicit index to get the first 10 rows\\\n",
    "g. Use the implicit index to get the first 10 rows"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:56:07.831250Z",
     "start_time": "2025-02-04T10:56:07.823243Z"
    },
    "id": "2b09001a55b1f4d6",
    "outputId": "d516996c-4d18-4c0f-ee9b-a012504bc150"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a. The first row with the explicit index: 5.1\n",
      "b. The first row with the implicit index: 5.1\n",
      "c. The first 10 rows with the explicit index: 1     5.1\n",
      "2     4.9\n",
      "3     4.7\n",
      "4     4.6\n",
      "5     5.0\n",
      "6     5.4\n",
      "7     4.6\n",
      "8     5.0\n",
      "9     4.4\n",
      "10    4.9\n",
      "Name: sepal length (cm), dtype: float64\n",
      "d. The first 10 rows with the implicit index: 1     5.1\n",
      "2     4.9\n",
      "3     4.7\n",
      "4     4.6\n",
      "5     5.0\n",
      "6     5.4\n",
      "7     4.6\n",
      "8     5.0\n",
      "9     4.4\n",
      "10    4.9\n",
      "Name: sepal length (cm), dtype: float64\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "print(f\"a. The first row with the explicit index: {iris_sepal_length.loc[1]}\")\n",
    "print(f\"b. The first row with the implicit index: {iris_sepal_length.iloc[0]}\")\n",
    "print(f\"c. The first 10 rows with the explicit index: {iris_sepal_length.loc[1:10]}\")\n",
    "#with loc the last value is included in the selection\n",
    "print(f\"d. The first 10 rows with the implicit index: {iris_sepal_length.iloc[0:10]}\")\n",
    "#with iloc the last value is not included in the selection\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### DataFrame objects\n",
    "In the first dataset we created a dataframe with the countries of Europe as the index, with a column population and gbp.\n",
    "\n",
    "a. Print the europe dataframe. What is the index of the dataframe? Wich columns does it have?\\\n",
    "b. From the europe dataframe, get the data for France using the loc attribute\\\n",
    "c. From the europe dataframe, get the population for all countries. Try do to this using 4 different ways to select data."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T14:31:59.774335Z",
     "start_time": "2025-02-11T14:31:59.735829Z"
    },
    "id": "f9960b55c6dc2cec",
    "outputId": "4d363b19-8164-4b4b-8e15-d7daea4c1fa7"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                population   GDP\n",
      "Austria                9.0  0.45\n",
      "Belgium               11.0  0.53\n",
      "Denmark                6.0  0.35\n",
      "Finland                5.0  0.27\n",
      "France                67.0  2.78\n",
      "Germany               83.0  4.42\n",
      "Greece                11.0  0.18\n",
      "Iceland                0.3  0.02\n",
      "Ireland                5.0  0.33\n",
      "Italy                 60.0  2.08\n",
      "Luxembourg             0.6  0.06\n",
      "Netherlands           17.0  0.91\n",
      "Norway                 5.0  0.40\n",
      "Portugal              10.0  0.23\n",
      "Spain                 47.0  1.39\n",
      "Sweden                10.0  0.53\n",
      "Switzerland            8.0  0.70\n",
      "United Kingdom        67.0  2.83\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "population    67.00\n",
       "GDP            2.78\n",
       "Name: France, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "population    67.00\n",
       "GDP            2.78\n",
       "Name: France, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Austria            9.0\n",
       "Belgium           11.0\n",
       "Denmark            6.0\n",
       "Finland            5.0\n",
       "France            67.0\n",
       "Germany           83.0\n",
       "Greece            11.0\n",
       "Iceland            0.3\n",
       "Ireland            5.0\n",
       "Italy             60.0\n",
       "Luxembourg         0.6\n",
       "Netherlands       17.0\n",
       "Norway             5.0\n",
       "Portugal          10.0\n",
       "Spain             47.0\n",
       "Sweden            10.0\n",
       "Switzerland        8.0\n",
       "United Kingdom    67.0\n",
       "Name: population, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Austria            9.0\n",
       "Belgium           11.0\n",
       "Denmark            6.0\n",
       "Finland            5.0\n",
       "France            67.0\n",
       "Germany           83.0\n",
       "Greece            11.0\n",
       "Iceland            0.3\n",
       "Ireland            5.0\n",
       "Italy             60.0\n",
       "Luxembourg         0.6\n",
       "Netherlands       17.0\n",
       "Norway             5.0\n",
       "Portugal          10.0\n",
       "Spain             47.0\n",
       "Sweden            10.0\n",
       "Switzerland        8.0\n",
       "United Kingdom    67.0\n",
       "Name: population, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Austria            9.0\n",
       "Belgium           11.0\n",
       "Denmark            6.0\n",
       "Finland            5.0\n",
       "France            67.0\n",
       "Germany           83.0\n",
       "Greece            11.0\n",
       "Iceland            0.3\n",
       "Ireland            5.0\n",
       "Italy             60.0\n",
       "Luxembourg         0.6\n",
       "Netherlands       17.0\n",
       "Norway             5.0\n",
       "Portugal          10.0\n",
       "Spain             47.0\n",
       "Sweden            10.0\n",
       "Switzerland        8.0\n",
       "United Kingdom    67.0\n",
       "Name: population, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Austria            9.0\n",
       "Belgium           11.0\n",
       "Denmark            6.0\n",
       "Finland            5.0\n",
       "France            67.0\n",
       "Germany           83.0\n",
       "Greece            11.0\n",
       "Iceland            0.3\n",
       "Ireland            5.0\n",
       "Italy             60.0\n",
       "Luxembourg         0.6\n",
       "Netherlands       17.0\n",
       "Norway             5.0\n",
       "Portugal          10.0\n",
       "Spain             47.0\n",
       "Sweden            10.0\n",
       "Switzerland        8.0\n",
       "United Kingdom    67.0\n",
       "Name: population, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "#a\n",
    "print(europe)\n",
    "#b\n",
    "europe.loc['France'] #This is the shortest notation\n",
    "europe.loc[\"France\",:] #This notation gives the same result as the previous one.\n",
    "\n",
    "#c\n",
    "\n",
    "europe['population'] #This notation is commonly used to select a column\n",
    "europe.population #This notation works good with autocomplete but can cause problems with column names that are also attributes of the dataframe, or when the column name has spaces.\n",
    "europe.loc[:,'population'] #Using the loc attribute is prefered because it is explicit\n",
    "europe.iloc[:,0] #With iloc you have to know the position of the column\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "d. Try to get an insight in the data. Print the iris dataframe. Use the functions describe() and info() to get a summary of the data.\\\n",
    " __From now on, you are always supposed to use these functions to get an insight in the data. Investigate every dataframe you use and is unfamiliar with these three steps.__\\\n",
    "e. Get the last 10 rows of the iris dataframe. Choose correctly between using the explicit and implicit index.\\\n",
    "f. Get the rows with the dataframe indexvalues from 100 to and including 110."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T11:00:51.106813Z",
     "start_time": "2025-02-04T11:00:51.011153Z"
    },
    "id": "afa8e7de58b2f7f1",
    "outputId": "f9822d8c-82f8-4401-9a31-4af650deacd2"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "1                  5.1               3.5                1.4               0.2\n",
      "2                  4.9               3.0                1.4               0.2\n",
      "3                  4.7               3.2                1.3               0.2\n",
      "4                  4.6               3.1                1.5               0.2\n",
      "5                  5.0               3.6                1.4               0.2\n",
      "..                 ...               ...                ...               ...\n",
      "146                6.7               3.0                5.2               2.3\n",
      "147                6.3               2.5                5.0               1.9\n",
      "148                6.5               3.0                5.2               2.0\n",
      "149                6.2               3.4                5.4               2.3\n",
      "150                5.9               3.0                5.1               1.8\n",
      "\n",
      "[150 rows x 4 columns]\n",
      "Describe:\n",
      "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
      "count         150.000000        150.000000         150.000000   \n",
      "mean            5.843333          3.057333           3.758000   \n",
      "std             0.828066          0.435866           1.765298   \n",
      "min             4.300000          2.000000           1.000000   \n",
      "25%             5.100000          2.800000           1.600000   \n",
      "50%             5.800000          3.000000           4.350000   \n",
      "75%             6.400000          3.300000           5.100000   \n",
      "max             7.900000          4.400000           6.900000   \n",
      "\n",
      "       petal width (cm)  \n",
      "count        150.000000  \n",
      "mean           1.199333  \n",
      "std            0.762238  \n",
      "min            0.100000  \n",
      "25%            0.300000  \n",
      "50%            1.300000  \n",
      "75%            1.800000  \n",
      "max            2.500000  \n",
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 150 entries, 1 to 150\n",
      "Data columns (total 4 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   sepal length (cm)  150 non-null    float64\n",
      " 1   sepal width (cm)   150 non-null    float64\n",
      " 2   petal length (cm)  150 non-null    float64\n",
      " 3   petal width (cm)   150 non-null    float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 8.3 KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "141                6.7               3.1                5.6               2.4\n",
       "142                6.9               3.1                5.1               2.3\n",
       "143                5.8               2.7                5.1               1.9\n",
       "144                6.8               3.2                5.9               2.3\n",
       "145                6.7               3.3                5.7               2.5\n",
       "146                6.7               3.0                5.2               2.3\n",
       "147                6.3               2.5                5.0               1.9\n",
       "148                6.5               3.0                5.2               2.0\n",
       "149                6.2               3.4                5.4               2.3\n",
       "150                5.9               3.0                5.1               1.8"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "100                5.7               2.8                4.1               1.3\n",
       "101                6.3               3.3                6.0               2.5\n",
       "102                5.8               2.7                5.1               1.9\n",
       "103                7.1               3.0                5.9               2.1\n",
       "104                6.3               2.9                5.6               1.8\n",
       "105                6.5               3.0                5.8               2.2\n",
       "106                7.6               3.0                6.6               2.1\n",
       "107                4.9               2.5                4.5               1.7\n",
       "108                7.3               2.9                6.3               1.8\n",
       "109                6.7               2.5                5.8               1.8\n",
       "110                7.2               3.6                6.1               2.5"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>7.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>7.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>7.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>6.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "#d\n",
    "print(iris)\n",
    "print(\"Describe:\")\n",
    "print(iris.describe())\n",
    "print(\"Info:\")\n",
    "print(iris.info())\n",
    "#e\n",
    "iris.iloc[-10:,:]\n",
    "#f\n",
    "iris.loc[100:110,:] #In case of using the loc attribute, the last value is included in the selection. This is different from the implicit index slicing and tends to be confusing.\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {
    "id": "fe6971b336ee5569"
   },
   "cell_type": "code",
   "outputs": [],
   "source": "",
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2025-02-14T09:13:33.142639Z",
     "start_time": "2025-02-14T09:13:32.043967Z"
    },
    "id": "30b4e3417867625a"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "import pandas as pd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Reading Data\n",
    "\n",
    "Very often you will need to read data from a file. In most cases, this will be a CSV file. A CSV file can be read and placed into a Pandas `DataFrame`. The first row of the file is usually used as a header. Pandas will automatically create column names based on the header, but you can also provide your own column names. You can also read data from other sources such as an SQL database, an Excel file, a JSON file, etc. For more information on reading data, see the [Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html).\n",
    "\n",
    "## Reading CSV files and working with a dataframe\n",
    "### CSV File format\n",
    "Data in Data Science is often stored in files with the extension *.csv*. CSV stands for **Comma Separated Value**. This means that the values are separated by commas, and it is a standard that was established in the 1970s. That abbreviation has remained, but nowadays values can also be separated by other characters, such as a Tab or a semicolon (;). That character is also called the delimiter or the separator. In CSV files, strings are usually also placed between quotation marks, especially when they contain spaces (or the separator, for example), so it is clear where the string begins and ends within a CSV.\n",
    "\n",
    "Decimal numbers can be stored in two ways: with a decimal point or with a decimal comma. If you save a file in a Dutch-language Excel, you will see that a decimal comma is automatically used. In an English-language Excel, it will be a decimal point. Therefore, we recommend, only for this course, not to work with Excel.\n",
    "\n",
    "Before reading a *.csv* file, you should always first check in a text editor how it is stored. By which character are the values separated? What is the decimal notation? In PyCharm, this can also be done, and moreover, PyCharm offers the possibility to immediately view a CSV file as a real table.\n",
    "\n",
    "Go to the `data` folder and open a CSV file in PyCharm. You will notice that there are tabs at the bottom that allow you to choose how you\n",
    "In PyCharm, you can view a CSV file as a table.\n",
    "\n",
    "### Reading a CSV file"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "```data = pd.read_csv('datasets/persons1.csv', )```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "__READING A CSV FILE IS ONE OF THE MOST COMMON TASKS IN DATA SCIENCE. YOU ARE EXPECTED TO BE ABLE TO DO THIS FLUENTLY DURING EVALUATIONS. MANY STUDENTS LOSE UNNECESSARY TIME OR ARE NOT ABLE TO SOLVE THE QUESTIONS BECAUSE THEY ARE NOT FAMILIAR WITH THIS TASK.__\n",
    "\n",
    "Go to the data directory and open BicycleWeather.csv in PyCharm.\n",
    "a. What is the seperator in this file?\n",
    "b. Read the dataset into a DataFrame using the read_csv function. Use the sep parameter to specify the separator.\n"
   ]
  },
  {
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2025-02-14T09:13:33.301926Z",
     "start_time": "2025-02-14T09:13:33.153665Z"
    },
    "id": "3d71bcc66ae52ccd"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "data = pd.read_csv('../../datasets/BicycleWeather.csv', sep=',')\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In PyCharm you can view the dataframe in a table format. Go to the data variable in the jupyter tab and click on \"View as DataFrame\".\n",
    "You can of course also print the data in a cell."
   ]
  },
  {
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2025-02-14T09:13:33.522790Z",
     "start_time": "2025-02-14T09:13:33.492825Z"
    },
    "id": "5d1016e40069dc5b",
    "outputId": "c769982a-1c58-4484-c129-af4ea4ce89d6"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                STATION                                STATION_NAME      DATE  \\\n",
      "0     GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120101   \n",
      "1     GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120102   \n",
      "2     GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120103   \n",
      "3     GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120104   \n",
      "4     GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120105   \n",
      "...                 ...                                         ...       ...   \n",
      "1335  GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20150828   \n",
      "1336  GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20150829   \n",
      "1337  GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20150830   \n",
      "1338  GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20150831   \n",
      "1339  GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20150901   \n",
      "\n",
      "      PRCP  SNWD  SNOW  TMAX  TMIN  AWND  WDF2  ...  WT17  WT05  WT02  WT22  \\\n",
      "0        0     0     0   128    50    47   100  ... -9999 -9999 -9999 -9999   \n",
      "1      109     0     0   106    28    45   180  ... -9999 -9999 -9999 -9999   \n",
      "2        8     0     0   117    72    23   180  ... -9999 -9999 -9999 -9999   \n",
      "3      203     0     0   122    56    47   180  ... -9999 -9999 -9999 -9999   \n",
      "4       13     0     0    89    28    61   200  ... -9999 -9999 -9999 -9999   \n",
      "...    ...   ...   ...   ...   ...   ...   ...  ...   ...   ...   ...   ...   \n",
      "1335     5     0     0   233   156    26   230  ... -9999 -9999 -9999 -9999   \n",
      "1336   325     0     0   222   133    58   210  ... -9999 -9999 -9999 -9999   \n",
      "1337   102     0     0   200   128    47   200  ... -9999 -9999 -9999 -9999   \n",
      "1338     0     0     0   189   161    58   210  ... -9999 -9999 -9999 -9999   \n",
      "1339    58     0     0   194   139 -9999 -9999  ... -9999 -9999 -9999 -9999   \n",
      "\n",
      "      WT04  WT13  WT16  WT08  WT18  WT03  \n",
      "0    -9999 -9999 -9999 -9999 -9999 -9999  \n",
      "1    -9999     1     1 -9999 -9999 -9999  \n",
      "2    -9999 -9999     1 -9999 -9999 -9999  \n",
      "3    -9999     1     1 -9999 -9999 -9999  \n",
      "4    -9999 -9999     1 -9999 -9999 -9999  \n",
      "...    ...   ...   ...   ...   ...   ...  \n",
      "1335 -9999 -9999 -9999 -9999 -9999 -9999  \n",
      "1336 -9999 -9999 -9999 -9999 -9999 -9999  \n",
      "1337 -9999 -9999 -9999 -9999 -9999 -9999  \n",
      "1338 -9999 -9999 -9999 -9999 -9999 -9999  \n",
      "1339 -9999 -9999 -9999 -9999 -9999 -9999  \n",
      "\n",
      "[1340 rows x 26 columns]\n"
     ]
    }
   ],
   "execution_count": null,
   "source": "print(data)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now, investigate the data with describe(), info() and head() functions."
  },
  {
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2025-02-14T09:13:33.766716Z",
     "start_time": "2025-02-14T09:13:33.562048Z"
    },
    "id": "8d647cb9ee817792",
    "outputId": "4bdbad69-7494-434f-b1e9-da7877af7bd7"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               DATE         PRCP         SNWD         SNOW         TMAX  \\\n",
       "count  1.340000e+03  1340.000000  1340.000000  1340.000000  1340.000000   \n",
       "mean   2.013427e+07    28.292537     0.324627   -29.545522   166.672388   \n",
       "std    1.063978e+04    62.763097     4.479127   545.736003    74.331651   \n",
       "min    2.012010e+07     0.000000     0.000000 -9999.000000   -16.000000   \n",
       "25%    2.012118e+07     0.000000     0.000000     0.000000   111.000000   \n",
       "50%    2.013107e+07     0.000000     0.000000     0.000000   156.000000   \n",
       "75%    2.014100e+07    25.000000     0.000000     0.000000   222.000000   \n",
       "max    2.015090e+07   559.000000    80.000000   173.000000   356.000000   \n",
       "\n",
       "              TMIN         AWND         WDF2         WDF5         WSF2  ...  \\\n",
       "count  1340.000000  1340.000000  1340.000000  1340.000000  1340.000000  ...   \n",
       "mean     83.249254    24.692537   170.840299    22.154478    64.513433  ...   \n",
       "std      50.563330   274.396498   296.343588  1298.860605   276.304370  ...   \n",
       "min     -71.000000 -9999.000000 -9999.000000 -9999.000000 -9999.000000  ...   \n",
       "25%      44.000000    22.000000   107.500000   120.000000    54.000000  ...   \n",
       "50%      83.000000    30.000000   200.000000   205.000000    67.000000  ...   \n",
       "75%     122.000000    40.000000   230.000000   240.000000    89.000000  ...   \n",
       "max     183.000000    95.000000   360.000000   360.000000   192.000000  ...   \n",
       "\n",
       "              WT17         WT05         WT02         WT22         WT04  \\\n",
       "count  1340.000000  1340.000000  1340.000000  1340.000000  1340.000000   \n",
       "mean  -9991.537313 -9984.074627 -9491.537313 -9931.835821 -9961.686567   \n",
       "std     273.179182   386.189416  2195.610628   817.085672   609.934146   \n",
       "min   -9999.000000 -9999.000000 -9999.000000 -9999.000000 -9999.000000   \n",
       "25%   -9999.000000 -9999.000000 -9999.000000 -9999.000000 -9999.000000   \n",
       "50%   -9999.000000 -9999.000000 -9999.000000 -9999.000000 -9999.000000   \n",
       "75%   -9999.000000 -9999.000000 -9999.000000 -9999.000000 -9999.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "              WT13         WT16         WT08         WT18         WT03  \n",
       "count  1340.000000  1340.000000  1340.000000  1340.000000  1340.000000  \n",
       "mean  -8543.776119 -7999.000000 -9767.656716 -9849.746269 -9887.059701  \n",
       "std    3527.583977  4001.493373  1503.861989  1212.995740  1052.472800  \n",
       "min   -9999.000000 -9999.000000 -9999.000000 -9999.000000 -9999.000000  \n",
       "25%   -9999.000000 -9999.000000 -9999.000000 -9999.000000 -9999.000000  \n",
       "50%   -9999.000000 -9999.000000 -9999.000000 -9999.000000 -9999.000000  \n",
       "75%   -9999.000000 -9999.000000 -9999.000000 -9999.000000 -9999.000000  \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000  \n",
       "\n",
       "[8 rows x 24 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNWD</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>AWND</th>\n",
       "      <th>WDF2</th>\n",
       "      <th>WDF5</th>\n",
       "      <th>WSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>WT17</th>\n",
       "      <th>WT05</th>\n",
       "      <th>WT02</th>\n",
       "      <th>WT22</th>\n",
       "      <th>WT04</th>\n",
       "      <th>WT13</th>\n",
       "      <th>WT16</th>\n",
       "      <th>WT08</th>\n",
       "      <th>WT18</th>\n",
       "      <th>WT03</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.340000e+03</td>\n",
       "      <td>1340.000000</td>\n",
       "      <td>1340.000000</td>\n",
       "      <td>1340.000000</td>\n",
       "      <td>1340.000000</td>\n",
       "      <td>1340.000000</td>\n",
       "      <td>1340.000000</td>\n",
       "      <td>1340.000000</td>\n",
       "      <td>1340.000000</td>\n",
       "      <td>1340.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1340.000000</td>\n",
       "      <td>1340.000000</td>\n",
       "      <td>1340.000000</td>\n",
       "      <td>1340.000000</td>\n",
       "      <td>1340.000000</td>\n",
       "      <td>1340.000000</td>\n",
       "      <td>1340.000000</td>\n",
       "      <td>1340.000000</td>\n",
       "      <td>1340.000000</td>\n",
       "      <td>1340.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.013427e+07</td>\n",
       "      <td>28.292537</td>\n",
       "      <td>0.324627</td>\n",
       "      <td>-29.545522</td>\n",
       "      <td>166.672388</td>\n",
       "      <td>83.249254</td>\n",
       "      <td>24.692537</td>\n",
       "      <td>170.840299</td>\n",
       "      <td>22.154478</td>\n",
       "      <td>64.513433</td>\n",
       "      <td>...</td>\n",
       "      <td>-9991.537313</td>\n",
       "      <td>-9984.074627</td>\n",
       "      <td>-9491.537313</td>\n",
       "      <td>-9931.835821</td>\n",
       "      <td>-9961.686567</td>\n",
       "      <td>-8543.776119</td>\n",
       "      <td>-7999.000000</td>\n",
       "      <td>-9767.656716</td>\n",
       "      <td>-9849.746269</td>\n",
       "      <td>-9887.059701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.063978e+04</td>\n",
       "      <td>62.763097</td>\n",
       "      <td>4.479127</td>\n",
       "      <td>545.736003</td>\n",
       "      <td>74.331651</td>\n",
       "      <td>50.563330</td>\n",
       "      <td>274.396498</td>\n",
       "      <td>296.343588</td>\n",
       "      <td>1298.860605</td>\n",
       "      <td>276.304370</td>\n",
       "      <td>...</td>\n",
       "      <td>273.179182</td>\n",
       "      <td>386.189416</td>\n",
       "      <td>2195.610628</td>\n",
       "      <td>817.085672</td>\n",
       "      <td>609.934146</td>\n",
       "      <td>3527.583977</td>\n",
       "      <td>4001.493373</td>\n",
       "      <td>1503.861989</td>\n",
       "      <td>1212.995740</td>\n",
       "      <td>1052.472800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.012010e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-16.000000</td>\n",
       "      <td>-71.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.012118e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>107.500000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.013107e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.014100e+07</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.015090e+07</td>\n",
       "      <td>559.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>356.000000</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1340 entries, 0 to 1339\n",
      "Data columns (total 26 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   STATION       1340 non-null   object\n",
      " 1   STATION_NAME  1340 non-null   object\n",
      " 2   DATE          1340 non-null   int64 \n",
      " 3   PRCP          1340 non-null   int64 \n",
      " 4   SNWD          1340 non-null   int64 \n",
      " 5   SNOW          1340 non-null   int64 \n",
      " 6   TMAX          1340 non-null   int64 \n",
      " 7   TMIN          1340 non-null   int64 \n",
      " 8   AWND          1340 non-null   int64 \n",
      " 9   WDF2          1340 non-null   int64 \n",
      " 10  WDF5          1340 non-null   int64 \n",
      " 11  WSF2          1340 non-null   int64 \n",
      " 12  WSF5          1340 non-null   int64 \n",
      " 13  FMTM          1340 non-null   int64 \n",
      " 14  WT14          1340 non-null   int64 \n",
      " 15  WT01          1340 non-null   int64 \n",
      " 16  WT17          1340 non-null   int64 \n",
      " 17  WT05          1340 non-null   int64 \n",
      " 18  WT02          1340 non-null   int64 \n",
      " 19  WT22          1340 non-null   int64 \n",
      " 20  WT04          1340 non-null   int64 \n",
      " 21  WT13          1340 non-null   int64 \n",
      " 22  WT16          1340 non-null   int64 \n",
      " 23  WT08          1340 non-null   int64 \n",
      " 24  WT18          1340 non-null   int64 \n",
      " 25  WT03          1340 non-null   int64 \n",
      "dtypes: int64(24), object(2)\n",
      "memory usage: 272.3+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "              STATION                                STATION_NAME      DATE  \\\n",
       "0   GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120101   \n",
       "1   GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120102   \n",
       "2   GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120103   \n",
       "3   GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120104   \n",
       "4   GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120105   \n",
       "5   GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120106   \n",
       "6   GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120107   \n",
       "7   GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120108   \n",
       "8   GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120109   \n",
       "9   GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120110   \n",
       "10  GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120111   \n",
       "11  GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120112   \n",
       "12  GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120113   \n",
       "13  GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120114   \n",
       "14  GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120115   \n",
       "15  GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120116   \n",
       "16  GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120117   \n",
       "17  GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120118   \n",
       "18  GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120119   \n",
       "19  GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120120   \n",
       "20  GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120121   \n",
       "21  GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120122   \n",
       "22  GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120123   \n",
       "23  GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120124   \n",
       "24  GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120125   \n",
       "25  GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120126   \n",
       "26  GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120127   \n",
       "27  GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120128   \n",
       "28  GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120129   \n",
       "29  GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120130   \n",
       "\n",
       "    PRCP  SNWD  SNOW  TMAX  TMIN  AWND  WDF2  ...  WT17  WT05  WT02  WT22  \\\n",
       "0      0     0     0   128    50    47   100  ... -9999 -9999 -9999 -9999   \n",
       "1    109     0     0   106    28    45   180  ... -9999 -9999 -9999 -9999   \n",
       "2      8     0     0   117    72    23   180  ... -9999 -9999 -9999 -9999   \n",
       "3    203     0     0   122    56    47   180  ... -9999 -9999 -9999 -9999   \n",
       "4     13     0     0    89    28    61   200  ... -9999 -9999 -9999 -9999   \n",
       "5     25     0     0    44    22    22   180  ... -9999 -9999 -9999 -9999   \n",
       "6      0     0     0    72    28    23   170  ... -9999 -9999 -9999 -9999   \n",
       "7      0     0     0   100    28    20   160  ... -9999 -9999 -9999 -9999   \n",
       "8     43     0     0    94    50    34   200  ... -9999 -9999 -9999 -9999   \n",
       "9     10     0     0    61     6    34    20  ... -9999 -9999 -9999 -9999   \n",
       "10     0     0     0    61   -11    51    20  ... -9999 -9999 -9999 -9999   \n",
       "11     0     0     0    61   -17    19    30  ... -9999 -9999 -9999 -9999   \n",
       "12     0     0     0    50   -28    13    40  ... -9999 -9999 -9999 -9999   \n",
       "13    41     0     0    44     6    53   220  ... -9999 -9999 -9999 -9999   \n",
       "14    53    51    61    11   -33    32   200  ... -9999 -9999 -9999 -9999   \n",
       "15    25    51     3    17   -28    50   190  ... -9999 -9999 -9999 -9999   \n",
       "16    81     0     0    33     0    56   220  ... -9999 -9999 -9999 -9999   \n",
       "17   198    25   173     0   -28    50   360  ...     1 -9999 -9999 -9999   \n",
       "18   152    76     8   -11   -28    16   300  ... -9999 -9999 -9999 -9999   \n",
       "19   135    76     0    72   -11    23   130  ... -9999 -9999 -9999 -9999   \n",
       "20    30    51     0    83    33    82   200  ... -9999 -9999 -9999 -9999   \n",
       "21    61     0     0    67    22    48   160  ... -9999 -9999 -9999 -9999   \n",
       "22     0     0     0    83    11    36   200  ... -9999 -9999 -9999 -9999   \n",
       "23    86     0     0   100    22    51   240  ... -9999 -9999 -9999 -9999   \n",
       "24    81     0     0    89    44    54   250  ... -9999 -9999 -9999 -9999   \n",
       "25    48     0     0    89    11    48   220  ... -9999 -9999 -9999 -9999   \n",
       "26     0     0     0    67   -22    14   110  ... -9999 -9999 -9999 -9999   \n",
       "27     0     0     0    67     6    22   200  ... -9999 -9999 -9999 -9999   \n",
       "28   277     0     0    94    39    45   190  ... -9999 -9999 -9999 -9999   \n",
       "29    36     0     0    83    61    51   220  ... -9999 -9999 -9999 -9999   \n",
       "\n",
       "    WT04  WT13  WT16  WT08  WT18  WT03  \n",
       "0  -9999 -9999 -9999 -9999 -9999 -9999  \n",
       "1  -9999     1     1 -9999 -9999 -9999  \n",
       "2  -9999 -9999     1 -9999 -9999 -9999  \n",
       "3  -9999     1     1 -9999 -9999 -9999  \n",
       "4  -9999 -9999     1 -9999 -9999 -9999  \n",
       "5  -9999 -9999     1 -9999 -9999 -9999  \n",
       "6  -9999     1     1 -9999 -9999 -9999  \n",
       "7  -9999 -9999 -9999 -9999 -9999 -9999  \n",
       "8  -9999     1     1 -9999 -9999 -9999  \n",
       "9  -9999 -9999     1 -9999 -9999 -9999  \n",
       "10 -9999 -9999 -9999 -9999 -9999 -9999  \n",
       "11 -9999 -9999 -9999 -9999 -9999 -9999  \n",
       "12 -9999 -9999 -9999 -9999 -9999 -9999  \n",
       "13 -9999     1     1 -9999     1 -9999  \n",
       "14 -9999     1 -9999 -9999     1 -9999  \n",
       "15 -9999     1     1 -9999     1 -9999  \n",
       "16 -9999     1 -9999 -9999     1 -9999  \n",
       "17 -9999 -9999     1 -9999     1 -9999  \n",
       "18     1 -9999     1 -9999     1 -9999  \n",
       "19 -9999 -9999     1 -9999     1 -9999  \n",
       "20 -9999 -9999     1 -9999 -9999 -9999  \n",
       "21 -9999     1     1 -9999 -9999 -9999  \n",
       "22 -9999 -9999     1 -9999 -9999 -9999  \n",
       "23 -9999     1     1 -9999 -9999 -9999  \n",
       "24 -9999     1     1 -9999 -9999 -9999  \n",
       "25 -9999     1     1 -9999 -9999 -9999  \n",
       "26 -9999     1 -9999 -9999 -9999 -9999  \n",
       "27 -9999 -9999     1 -9999 -9999 -9999  \n",
       "28 -9999     1     1 -9999 -9999 -9999  \n",
       "29 -9999 -9999     1 -9999 -9999 -9999  \n",
       "\n",
       "[30 rows x 26 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>STATION_NAME</th>\n",
       "      <th>DATE</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNWD</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>AWND</th>\n",
       "      <th>WDF2</th>\n",
       "      <th>...</th>\n",
       "      <th>WT17</th>\n",
       "      <th>WT05</th>\n",
       "      <th>WT02</th>\n",
       "      <th>WT22</th>\n",
       "      <th>WT04</th>\n",
       "      <th>WT13</th>\n",
       "      <th>WT16</th>\n",
       "      <th>WT08</th>\n",
       "      <th>WT18</th>\n",
       "      <th>WT03</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GHCND:USW00024233</td>\n",
       "      <td>SEATTLE TACOMA INTERNATIONAL AIRPORT WA US</td>\n",
       "      <td>20120101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>50</td>\n",
       "      <td>47</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GHCND:USW00024233</td>\n",
       "      <td>SEATTLE TACOMA INTERNATIONAL AIRPORT WA US</td>\n",
       "      <td>20120102</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "      <td>28</td>\n",
       "      <td>45</td>\n",
       "      <td>180</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GHCND:USW00024233</td>\n",
       "      <td>SEATTLE TACOMA INTERNATIONAL AIRPORT WA US</td>\n",
       "      <td>20120103</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>180</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>1</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GHCND:USW00024233</td>\n",
       "      <td>SEATTLE TACOMA INTERNATIONAL AIRPORT WA US</td>\n",
       "      <td>20120104</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>56</td>\n",
       "      <td>47</td>\n",
       "      <td>180</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GHCND:USW00024233</td>\n",
       "      <td>SEATTLE TACOMA INTERNATIONAL AIRPORT WA US</td>\n",
       "      <td>20120105</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>28</td>\n",
       "      <td>61</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>1</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GHCND:USW00024233</td>\n",
       "      <td>SEATTLE TACOMA INTERNATIONAL AIRPORT WA US</td>\n",
       "      <td>20120106</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>180</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>1</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GHCND:USW00024233</td>\n",
       "      <td>SEATTLE TACOMA INTERNATIONAL AIRPORT WA US</td>\n",
       "      <td>20120107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "      <td>170</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GHCND:USW00024233</td>\n",
       "      <td>SEATTLE TACOMA INTERNATIONAL AIRPORT WA US</td>\n",
       "      <td>20120108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>28</td>\n",
       "      <td>20</td>\n",
       "      <td>160</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GHCND:USW00024233</td>\n",
       "      <td>SEATTLE TACOMA INTERNATIONAL AIRPORT WA US</td>\n",
       "      <td>20120109</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>50</td>\n",
       "      <td>34</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GHCND:USW00024233</td>\n",
       "      <td>SEATTLE TACOMA INTERNATIONAL AIRPORT WA US</td>\n",
       "      <td>20120110</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>6</td>\n",
       "      <td>34</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>1</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GHCND:USW00024233</td>\n",
       "      <td>SEATTLE TACOMA INTERNATIONAL AIRPORT WA US</td>\n",
       "      <td>20120111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>-11</td>\n",
       "      <td>51</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GHCND:USW00024233</td>\n",
       "      <td>SEATTLE TACOMA INTERNATIONAL AIRPORT WA US</td>\n",
       "      <td>20120112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>-17</td>\n",
       "      <td>19</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GHCND:USW00024233</td>\n",
       "      <td>SEATTLE TACOMA INTERNATIONAL AIRPORT WA US</td>\n",
       "      <td>20120113</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>-28</td>\n",
       "      <td>13</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GHCND:USW00024233</td>\n",
       "      <td>SEATTLE TACOMA INTERNATIONAL AIRPORT WA US</td>\n",
       "      <td>20120114</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>6</td>\n",
       "      <td>53</td>\n",
       "      <td>220</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-9999</td>\n",
       "      <td>1</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GHCND:USW00024233</td>\n",
       "      <td>SEATTLE TACOMA INTERNATIONAL AIRPORT WA US</td>\n",
       "      <td>20120115</td>\n",
       "      <td>53</td>\n",
       "      <td>51</td>\n",
       "      <td>61</td>\n",
       "      <td>11</td>\n",
       "      <td>-33</td>\n",
       "      <td>32</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>1</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>1</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GHCND:USW00024233</td>\n",
       "      <td>SEATTLE TACOMA INTERNATIONAL AIRPORT WA US</td>\n",
       "      <td>20120116</td>\n",
       "      <td>25</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>-28</td>\n",
       "      <td>50</td>\n",
       "      <td>190</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-9999</td>\n",
       "      <td>1</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GHCND:USW00024233</td>\n",
       "      <td>SEATTLE TACOMA INTERNATIONAL AIRPORT WA US</td>\n",
       "      <td>20120117</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>220</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>1</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>1</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GHCND:USW00024233</td>\n",
       "      <td>SEATTLE TACOMA INTERNATIONAL AIRPORT WA US</td>\n",
       "      <td>20120118</td>\n",
       "      <td>198</td>\n",
       "      <td>25</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>-28</td>\n",
       "      <td>50</td>\n",
       "      <td>360</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>1</td>\n",
       "      <td>-9999</td>\n",
       "      <td>1</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>GHCND:USW00024233</td>\n",
       "      <td>SEATTLE TACOMA INTERNATIONAL AIRPORT WA US</td>\n",
       "      <td>20120119</td>\n",
       "      <td>152</td>\n",
       "      <td>76</td>\n",
       "      <td>8</td>\n",
       "      <td>-11</td>\n",
       "      <td>-28</td>\n",
       "      <td>16</td>\n",
       "      <td>300</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>1</td>\n",
       "      <td>-9999</td>\n",
       "      <td>1</td>\n",
       "      <td>-9999</td>\n",
       "      <td>1</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>GHCND:USW00024233</td>\n",
       "      <td>SEATTLE TACOMA INTERNATIONAL AIRPORT WA US</td>\n",
       "      <td>20120120</td>\n",
       "      <td>135</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>-11</td>\n",
       "      <td>23</td>\n",
       "      <td>130</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>1</td>\n",
       "      <td>-9999</td>\n",
       "      <td>1</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>GHCND:USW00024233</td>\n",
       "      <td>SEATTLE TACOMA INTERNATIONAL AIRPORT WA US</td>\n",
       "      <td>20120121</td>\n",
       "      <td>30</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>33</td>\n",
       "      <td>82</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>1</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>GHCND:USW00024233</td>\n",
       "      <td>SEATTLE TACOMA INTERNATIONAL AIRPORT WA US</td>\n",
       "      <td>20120122</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>22</td>\n",
       "      <td>48</td>\n",
       "      <td>160</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>GHCND:USW00024233</td>\n",
       "      <td>SEATTLE TACOMA INTERNATIONAL AIRPORT WA US</td>\n",
       "      <td>20120123</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>11</td>\n",
       "      <td>36</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>1</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>GHCND:USW00024233</td>\n",
       "      <td>SEATTLE TACOMA INTERNATIONAL AIRPORT WA US</td>\n",
       "      <td>20120124</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>22</td>\n",
       "      <td>51</td>\n",
       "      <td>240</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>GHCND:USW00024233</td>\n",
       "      <td>SEATTLE TACOMA INTERNATIONAL AIRPORT WA US</td>\n",
       "      <td>20120125</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>44</td>\n",
       "      <td>54</td>\n",
       "      <td>250</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>GHCND:USW00024233</td>\n",
       "      <td>SEATTLE TACOMA INTERNATIONAL AIRPORT WA US</td>\n",
       "      <td>20120126</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>11</td>\n",
       "      <td>48</td>\n",
       "      <td>220</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>GHCND:USW00024233</td>\n",
       "      <td>SEATTLE TACOMA INTERNATIONAL AIRPORT WA US</td>\n",
       "      <td>20120127</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>-22</td>\n",
       "      <td>14</td>\n",
       "      <td>110</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>1</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>GHCND:USW00024233</td>\n",
       "      <td>SEATTLE TACOMA INTERNATIONAL AIRPORT WA US</td>\n",
       "      <td>20120128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>1</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>GHCND:USW00024233</td>\n",
       "      <td>SEATTLE TACOMA INTERNATIONAL AIRPORT WA US</td>\n",
       "      <td>20120129</td>\n",
       "      <td>277</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>39</td>\n",
       "      <td>45</td>\n",
       "      <td>190</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>GHCND:USW00024233</td>\n",
       "      <td>SEATTLE TACOMA INTERNATIONAL AIRPORT WA US</td>\n",
       "      <td>20120130</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>61</td>\n",
       "      <td>51</td>\n",
       "      <td>220</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>1</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 26 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "data.describe()\n",
    "data.info()\n",
    "data.head(30)\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Select columns Station_name, date and TMAX from rows with index 10 to 20."
  },
  {
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2025-02-14T09:13:34.049899Z",
     "start_time": "2025-02-14T09:13:34.023344Z"
    },
    "id": "648e06484e43a472",
    "outputId": "5c936e65-4656-45f6-e403-6d5fa19a6da0"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                  STATION_NAME      DATE  TMAX\n",
       "10  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120111    61\n",
       "11  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120112    61\n",
       "12  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120113    50\n",
       "13  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120114    44\n",
       "14  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120115    11\n",
       "15  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120116    17\n",
       "16  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120117    33\n",
       "17  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120118     0\n",
       "18  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120119   -11\n",
       "19  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120120    72\n",
       "20  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120121    83"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION_NAME</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TMAX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SEATTLE TACOMA INTERNATIONAL AIRPORT WA US</td>\n",
       "      <td>20120111</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SEATTLE TACOMA INTERNATIONAL AIRPORT WA US</td>\n",
       "      <td>20120112</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SEATTLE TACOMA INTERNATIONAL AIRPORT WA US</td>\n",
       "      <td>20120113</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SEATTLE TACOMA INTERNATIONAL AIRPORT WA US</td>\n",
       "      <td>20120114</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SEATTLE TACOMA INTERNATIONAL AIRPORT WA US</td>\n",
       "      <td>20120115</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SEATTLE TACOMA INTERNATIONAL AIRPORT WA US</td>\n",
       "      <td>20120116</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SEATTLE TACOMA INTERNATIONAL AIRPORT WA US</td>\n",
       "      <td>20120117</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SEATTLE TACOMA INTERNATIONAL AIRPORT WA US</td>\n",
       "      <td>20120118</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SEATTLE TACOMA INTERNATIONAL AIRPORT WA US</td>\n",
       "      <td>20120119</td>\n",
       "      <td>-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SEATTLE TACOMA INTERNATIONAL AIRPORT WA US</td>\n",
       "      <td>20120120</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SEATTLE TACOMA INTERNATIONAL AIRPORT WA US</td>\n",
       "      <td>20120121</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "data.loc[10:20, ['STATION_NAME', 'DATE', 'TMAX']]\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now, read the file again, but this time use the extra parameter names to specify your own column names. Use range(0, 26) as column names."
  },
  {
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2025-02-14T09:13:34.815492Z",
     "start_time": "2025-02-14T09:13:34.759080Z"
    },
    "id": "b1ba6f2d0410467c"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "data = pd.read_csv('../../datasets/BicycleWeather.csv', sep=',', names=range(0, 26))\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Look at the first three rows of the data. What problem do you see?"
  },
  {
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2025-02-14T09:13:35.739124Z",
     "start_time": "2025-02-14T09:13:35.714415Z"
    },
    "id": "4ba1e4c54de13475",
    "outputId": "8b310b5a-b94d-46b8-9516-341ecbe0e467"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                  0                                           1         2   \\\n",
       "0            STATION                                STATION_NAME      DATE   \n",
       "1  GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120101   \n",
       "2  GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120102   \n",
       "3  GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120103   \n",
       "4  GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120104   \n",
       "\n",
       "     3     4     5     6     7     8     9   ...     16     17     18     19  \\\n",
       "0  PRCP  SNWD  SNOW  TMAX  TMIN  AWND  WDF2  ...   WT17   WT05   WT02   WT22   \n",
       "1     0     0     0   128    50    47   100  ...  -9999  -9999  -9999  -9999   \n",
       "2   109     0     0   106    28    45   180  ...  -9999  -9999  -9999  -9999   \n",
       "3     8     0     0   117    72    23   180  ...  -9999  -9999  -9999  -9999   \n",
       "4   203     0     0   122    56    47   180  ...  -9999  -9999  -9999  -9999   \n",
       "\n",
       "      20     21     22     23     24     25  \n",
       "0   WT04   WT13   WT16   WT08   WT18   WT03  \n",
       "1  -9999  -9999  -9999  -9999  -9999  -9999  \n",
       "2  -9999      1      1  -9999  -9999  -9999  \n",
       "3  -9999  -9999      1  -9999  -9999  -9999  \n",
       "4  -9999      1      1  -9999  -9999  -9999  \n",
       "\n",
       "[5 rows x 26 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>STATION</td>\n",
       "      <td>STATION_NAME</td>\n",
       "      <td>DATE</td>\n",
       "      <td>PRCP</td>\n",
       "      <td>SNWD</td>\n",
       "      <td>SNOW</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>TMIN</td>\n",
       "      <td>AWND</td>\n",
       "      <td>WDF2</td>\n",
       "      <td>...</td>\n",
       "      <td>WT17</td>\n",
       "      <td>WT05</td>\n",
       "      <td>WT02</td>\n",
       "      <td>WT22</td>\n",
       "      <td>WT04</td>\n",
       "      <td>WT13</td>\n",
       "      <td>WT16</td>\n",
       "      <td>WT08</td>\n",
       "      <td>WT18</td>\n",
       "      <td>WT03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GHCND:USW00024233</td>\n",
       "      <td>SEATTLE TACOMA INTERNATIONAL AIRPORT WA US</td>\n",
       "      <td>20120101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>50</td>\n",
       "      <td>47</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GHCND:USW00024233</td>\n",
       "      <td>SEATTLE TACOMA INTERNATIONAL AIRPORT WA US</td>\n",
       "      <td>20120102</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "      <td>28</td>\n",
       "      <td>45</td>\n",
       "      <td>180</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GHCND:USW00024233</td>\n",
       "      <td>SEATTLE TACOMA INTERNATIONAL AIRPORT WA US</td>\n",
       "      <td>20120103</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>180</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>1</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GHCND:USW00024233</td>\n",
       "      <td>SEATTLE TACOMA INTERNATIONAL AIRPORT WA US</td>\n",
       "      <td>20120104</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>56</td>\n",
       "      <td>47</td>\n",
       "      <td>180</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "data.head()\n",
    "#The header names are now the first row of the data\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Try to solve the problem by using the header parameter."
  },
  {
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2025-02-14T09:13:36.534210Z",
     "start_time": "2025-02-14T09:13:36.491372Z"
    },
    "id": "c5bc01194d9495d6",
    "outputId": "fc7702c8-9cbb-47ee-d7ef-989e9493bc26"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                  0                                           1         2   \\\n",
       "0  GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120101   \n",
       "1  GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120102   \n",
       "2  GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120103   \n",
       "3  GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120104   \n",
       "4  GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US  20120105   \n",
       "\n",
       "    3   4   5    6   7   8    9   ...    16    17    18    19    20    21  \\\n",
       "0    0   0   0  128  50  47  100  ... -9999 -9999 -9999 -9999 -9999 -9999   \n",
       "1  109   0   0  106  28  45  180  ... -9999 -9999 -9999 -9999 -9999     1   \n",
       "2    8   0   0  117  72  23  180  ... -9999 -9999 -9999 -9999 -9999 -9999   \n",
       "3  203   0   0  122  56  47  180  ... -9999 -9999 -9999 -9999 -9999     1   \n",
       "4   13   0   0   89  28  61  200  ... -9999 -9999 -9999 -9999 -9999 -9999   \n",
       "\n",
       "     22    23    24    25  \n",
       "0 -9999 -9999 -9999 -9999  \n",
       "1     1 -9999 -9999 -9999  \n",
       "2     1 -9999 -9999 -9999  \n",
       "3     1 -9999 -9999 -9999  \n",
       "4     1 -9999 -9999 -9999  \n",
       "\n",
       "[5 rows x 26 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GHCND:USW00024233</td>\n",
       "      <td>SEATTLE TACOMA INTERNATIONAL AIRPORT WA US</td>\n",
       "      <td>20120101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>50</td>\n",
       "      <td>47</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GHCND:USW00024233</td>\n",
       "      <td>SEATTLE TACOMA INTERNATIONAL AIRPORT WA US</td>\n",
       "      <td>20120102</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "      <td>28</td>\n",
       "      <td>45</td>\n",
       "      <td>180</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GHCND:USW00024233</td>\n",
       "      <td>SEATTLE TACOMA INTERNATIONAL AIRPORT WA US</td>\n",
       "      <td>20120103</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>180</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>1</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GHCND:USW00024233</td>\n",
       "      <td>SEATTLE TACOMA INTERNATIONAL AIRPORT WA US</td>\n",
       "      <td>20120104</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>56</td>\n",
       "      <td>47</td>\n",
       "      <td>180</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GHCND:USW00024233</td>\n",
       "      <td>SEATTLE TACOMA INTERNATIONAL AIRPORT WA US</td>\n",
       "      <td>20120105</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>28</td>\n",
       "      <td>61</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>1</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "data = pd.read_csv('../../datasets/BicycleWeather.csv', sep=',', names=range(0, 26), header=0) # In this case you give the names yourself and you indicate that the header is the first row and that the file header has te be skipped\n",
    "data.head()\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "If you look at the data, you will notice -9999 values. These are probably missing values. Try to solve this by using the na_values parameter."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-14T09:13:37.530480Z",
     "start_time": "2025-02-14T09:13:37.432269Z"
    },
    "id": "af426ff4b5bd63b1"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "data = pd.read_csv('../../datasets/BicycleWeather.csv', sep=',', names=range(0, 26), header=0, na_values= -9999) # In this case you give the names yourself and you indicate that the header is the first row and that the file header has te be skipped\n"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Categorical Variables\n",
    "In many cases, when importing data, you will encounter categorical variables. These are variables that can take on a limited number of values. These values are often represented by strings. In Pandas, you can work with these variables in a very efficient way.\n",
    "\n",
    "We start by creating a Pandas Categorical Series. A Categorical Series is a list of values that all come from a certain category. A categorical variable can take on a fixed number of values, which are usually expressed in strings. A categorical variable represents a nominal or ordinal variable, depending on whether the values in the list have a certain order or not.\n",
    "\n",
    "\n",
    "Take your **blood type** as an example. Possible values are:\n",
    "\n",
    "``> O-, O+, B-, B+, A-, A+, AB-, AB+``\n",
    "\n",
    "We know that blood type is a **nominal variable**.\n",
    "You cannot perform calculations with these values. There are also examples where there is an order, for example:\n",
    "\n",
    "Take the degree of agreement as an example. Possible values could be:\\\n",
    "``> none, little, more, most``\\\n",
    "This is clearly an example of an **ordinal variable**.\n",
    "Sometimes the values of a categorical variable are represented by numbers, but they are still categorical variables. Do not be misled by this.\n",
    "\n",
    "From the theory of measurement scales, we know that nominal variables can only be compared (using the = operator) and ordinal variables can at most be sorted (using <, >, = operators).  To work efficiently with these values, an index or category is assigned to them. Because this index is a number, it is much faster to find values of the correct category in a large dataset. Run the following code to create a nominal variable blood types.\n",
    "\n",
    "Run the following code to create a nominal variable blood types.\n",
    "```python\n",
    "values = ['AB-', 'O-', 'B-', 'B-', 'A+', 'AB+', 'O+', 'B-', 'B+', 'A-', 'A+', 'AB-']\n",
    "bloodtype = pd.Categorical(values, categories=['O-','O+','B-','B+','A-','A+','AB-','AB+'])\n",
    "bloodtype\n",
    "```"
   ]
  },
  {
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2025-02-14T09:13:38.462151Z",
     "start_time": "2025-02-14T09:13:38.434358Z"
    },
    "id": "ffd3e8baab2e5f64",
    "outputId": "16c2f195-3c11-4f5a-f826-71551a3fc7e0"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AB-', 'O-', 'B-', 'B-', 'A+', ..., 'B-', 'B+', 'A-', 'A+', 'AB-']\n",
       "Length: 12\n",
       "Categories (8, object): ['O-', 'O+', 'B-', 'B+', 'A-', 'A+', 'AB-', 'AB+']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "import pandas as pd\n",
    "values = ['AB-', 'O-', 'B-', 'B-', 'A+', 'AB+', 'O+', 'B-', 'B+', 'A-', 'A+', 'AB-']\n",
    "bloodtype = pd.Categorical(values, categories=['O-','O+','B-','B+','A-','A+','AB-','AB+'])\n",
    "bloodtype\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now run the following code to create an ordinal variable akkoord.\n",
    "```python\n",
    "values = ['little', 'more', 'none', 'more', 'little', 'most', 'none']\n",
    "agreement = pd.Categorical(values, categories=['none', 'little', 'more', 'most'], ordered=True)\n",
    "agreement\n",
    "```"
   ]
  },
  {
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2025-02-14T09:13:39.422800Z",
     "start_time": "2025-02-14T09:13:39.409582Z"
    },
    "id": "fa5a8015b34ad547",
    "outputId": "3ec9aae6-1bf2-4808-8b4c-6116e57fed8e"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['little', 'more', 'none', 'more', 'little', 'most', 'none']\n",
       "Categories (4, object): ['none' < 'little' < 'more' < 'most']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "values = ['little', 'more', 'none', 'more', 'little', 'most', 'none']\n",
    "agreement = pd.Categorical(values, categories=['none', 'little', 'more', 'most'], ordered=True)\n",
    "agreement\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "When reading a csv you can also specify which columns are categorical. This can be done with the dtype parameter. Create a new DataFrame laptops from the file laptops.csv. Specify that the columns cpuGeneration and brand are categorical.\n",
    "_Tip dtype={'col_name':'category', 'col_name2':'category'}_\n",
    " As always, first look at the file to see what the separator is. In this case it will also be important to set the decimal argument correctly."
   ]
  },
  {
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2025-02-14T09:13:41.723634Z",
     "start_time": "2025-02-14T09:13:40.288331Z"
    },
    "id": "e7760887ed11853a"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "laptops = pd.read_csv('../../datasets/laptops.csv', sep=';', dtype={'cpuGeneration': 'category', 'brand': 'category'}, decimal=',')\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Check the result. cpuGeneration and brand should be of type category and diskspace should be of type float."
  },
  {
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2025-02-14T09:13:41.817343Z",
     "start_time": "2025-02-14T09:13:41.791209Z"
    },
    "id": "229095425966ae17",
    "outputId": "7381780d-be55-413f-bbfc-b4f2185947d4"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 857 entries, 0 to 856\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype   \n",
      "---  ------         --------------  -----   \n",
      " 0   cpuGeneration  852 non-null    category\n",
      " 1   cpuType        853 non-null    object  \n",
      " 2   RAM            855 non-null    float64 \n",
      " 3   diskspace      851 non-null    float64 \n",
      " 4   brand          856 non-null    category\n",
      "dtypes: category(2), float64(2), object(1)\n",
      "memory usage: 22.5+ KB\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "laptops.info()\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In many cases you will want to convert a column to a categorical variable after reading the file into a dataframe. In case of the dataframe laptops, convert cpuType to a categorical. The cpuType has to be 'oridinal' and the categories should be 'i3', 'i5', 'i7'."
  },
  {
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2025-02-14T09:13:42.150834Z",
     "start_time": "2025-02-14T09:13:42.140497Z"
    },
    "id": "9d1ddbba698b0c41"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "laptops['cpuType'] = pd.Categorical(laptops['cpuType'], categories=['i3', 'i5', 'i7'], ordered=True)\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Check whether the column has been converted correctly. Make sure you see < between the categories."
  },
  {
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2025-02-14T09:13:42.354482Z",
     "start_time": "2025-02-14T09:13:42.340360Z"
    },
    "id": "2244a3f9c1d5bb5d",
    "outputId": "2a496eaf-c8fd-4e70-b19a-eb69843a07f3"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      i7\n",
      "1      i5\n",
      "2      i7\n",
      "3      i7\n",
      "4      i5\n",
      "       ..\n",
      "852    i3\n",
      "853    i5\n",
      "854    i5\n",
      "855    i7\n",
      "856    i3\n",
      "Name: cpuType, Length: 857, dtype: category\n",
      "Categories (3, object): ['i3' < 'i5' < 'i7']\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "print(laptops['cpuType'])\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<!--BOOK_INFORMATION-->\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"figures/PDSH-cover-small.png\">\n",
    "\n",
    "*This notebook contains an excerpt from the [Python Data Science Handbook](http://shop.oreilly.com/product/0636920034919.do) by Jake VanderPlas; the content is available [on GitHub](https://github.com/jakevdp/PythonDataScienceHandbook).*\n",
    "\n",
    "*The text is released under the [CC-BY-NC-ND license](https://creativecommons.org/licenses/by-nc-nd/3.0/us/legalcode), and code is released under the [MIT license](https://opensource.org/licenses/MIT). If you find this content useful, please consider supporting the work by [buying the book](http://shop.oreilly.com/product/0636920034919.do)!*"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<!--NAVIGATION-->\n",
    "< [Data Indexing and Selection](03.02-Data-Indexing-and-Selection.ipynb) | [Contents](Index.ipynb) | [Handling Missing Data](03.04-Missing-Values.ipynb) >\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.03-Operations-in-Pandas.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Operating on Data in Pandas"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "One of the essential pieces of NumPy is the ability to perform quick element-wise operations, both with basic arithmetic (addition, subtraction, multiplication, etc.) and with more sophisticated operations (trigonometric functions, exponential and logarithmic functions, etc.).\n",
    "Pandas inherits much of this functionality from NumPy, and the ufuncs that we introduced in [Computation on NumPy Arrays: Universal Functions](02.03-Computation-on-arrays-ufuncs.ipynb) are key to this.\n",
    "\n",
    "Pandas includes a couple useful twists, however: for unary operations like negation and trigonometric functions, these ufuncs will *preserve index and column labels* in the output, and for binary operations such as addition and multiplication, Pandas will automatically *align indices* when passing the objects to the ufunc.\n",
    "This means that keeping the context of data and combining data from different sources–both potentially error-prone tasks with raw NumPy arrays–become essentially foolproof ones with Pandas.\n",
    "We will additionally see that there are well-defined operations between one-dimensional ``Series`` structures and two-dimensional ``DataFrame`` structures."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Ufuncs: Index Preservation\n",
    "\n",
    "Because Pandas is designed to work with NumPy, any NumPy ufunc will work on Pandas ``Series`` and ``DataFrame`` objects.\n",
    "Let's start by defining a simple ``Series`` and ``DataFrame`` on which to demonstrate this:"
   ]
  },
  {
   "metadata": {
    "collapsed": true,
    "id": "kC1MY2Smp1du"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "metadata": {
    "id": "7ms4R2Mqp1du",
    "outputId": "5325132a-8610-4fc8-aab3-8fc92ac9c0a3"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6\n",
       "1    3\n",
       "2    7\n",
       "3    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "rng = np.random.RandomState(42)\n",
    "ser = pd.Series(rng.randint(0, 10, 4))\n",
    "ser"
   ]
  },
  {
   "metadata": {
    "id": "HEzShRfzp1dv",
    "outputId": "4388e7a0-b300-4827-b0bc-40d7b0388943"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B  C  D\n",
       "0  6  9  2  6\n",
       "1  7  4  3  7\n",
       "2  7  2  5  4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "df = pd.DataFrame(rng.randint(0, 10, (3, 4)),\n",
    "                  columns=['A', 'B', 'C', 'D'])\n",
    "df"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "If we apply a NumPy ufunc on either of these objects, the result will be another Pandas object *with the indices preserved:*"
  },
  {
   "metadata": {
    "id": "_qDMxKjCp1dw",
    "outputId": "2ff25928-c65f-4e91-8080-3b886603f8e0"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     403.428793\n",
       "1      20.085537\n",
       "2    1096.633158\n",
       "3      54.598150\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "np.exp(ser)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Or, for a slightly more complex calculation:"
  },
  {
   "metadata": {
    "id": "Z7vLLD3Up1dx",
    "outputId": "788bc679-4005-4283-e8d6-e2b6e40d312c"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>7.071068e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.707107</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-7.071068e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.707107</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>1.224647e-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A             B         C             D\n",
       "0 -1.000000  7.071068e-01  1.000000 -1.000000e+00\n",
       "1 -0.707107  1.224647e-16  0.707107 -7.071068e-01\n",
       "2 -0.707107  1.000000e+00 -0.707107  1.224647e-16"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "np.sin(df * np.pi / 4)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Any of the ufuncs discussed in [Computation on NumPy Arrays: Universal Functions](02.03-Computation-on-arrays-ufuncs.ipynb) can be used in a similar manner."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## UFuncs: Index Alignment\n",
    "\n",
    "For binary operations on two ``Series`` or ``DataFrame`` objects, Pandas will align indices in the process of performing the operation.\n",
    "This is very convenient when working with incomplete data, as we'll see in some of the examples that follow."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Index alignment in Series\n",
    "\n",
    "As an example, suppose we are combining two different data sources, and find only the top three US states by *area* and the top three US states by *population*:"
   ]
  },
  {
   "metadata": {
    "id": "tJ_PpVsRp1dx"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "area = pd.Series({'Alaska': 1723337, 'Texas': 695662,\n",
    "                  'California': 423967}, name='area')\n",
    "population = pd.Series({'California': 38332521, 'Texas': 26448193,\n",
    "                        'New York': 19651127}, name='population')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's see what happens when we divide these to compute the population density:"
  },
  {
   "metadata": {
    "id": "Ic2Qdqrzp1dy",
    "outputId": "6db4e213-c4d7-4f94-d749-538b313f40d7"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alaska              NaN\n",
       "California    90.413926\n",
       "New York            NaN\n",
       "Texas         38.018740\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "population / area"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The resulting array contains the *union* of indices of the two input arrays, which could be determined using standard Python set arithmetic on these indices:"
  },
  {
   "metadata": {
    "id": "kIzGkFHpp1dy",
    "outputId": "8cc3015a-40a0-47dd-cd0e-23c0e0dfd999"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Alaska', 'California', 'New York', 'Texas'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "area.index | population.index"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Any item for which one or the other does not have an entry is marked with ``NaN``, or \"Not a Number,\" which is how Pandas marks missing data (see further discussion of missing data in [Handling Missing Data](03.04-Missing-Values.ipynb)).\n",
    "This index matching is implemented this way for any of Python's built-in arithmetic expressions; any missing values are filled in with NaN by default:"
   ]
  },
  {
   "metadata": {
    "id": "dY5bUc2Wp1dz",
    "outputId": "2944128d-1053-4d98-b3aa-69be8a43bc93"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    NaN\n",
       "1    5.0\n",
       "2    9.0\n",
       "3    NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "A = pd.Series([2, 4, 6], index=[0, 1, 2])\n",
    "B = pd.Series([1, 3, 5], index=[1, 2, 3])\n",
    "A + B"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "If using NaN values is not the desired behavior, the fill value can be modified using appropriate object methods in place of the operators.\n",
    "For example, calling ``A.add(B)`` is equivalent to calling ``A + B``, but allows optional explicit specification of the fill value for any elements in ``A`` or ``B`` that might be missing:"
   ]
  },
  {
   "metadata": {
    "id": "jYGXlpLEp1dz",
    "outputId": "f7ed4bca-0b49-4441-8189-9871f4043669"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2.0\n",
       "1    5.0\n",
       "2    9.0\n",
       "3    5.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "A.add(B, fill_value=0)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Index alignment in DataFrame\n",
    "\n",
    "A similar type of alignment takes place for *both* columns and indices when performing operations on ``DataFrame``s:"
   ]
  },
  {
   "metadata": {
    "id": "FNZzbV2op1dz",
    "outputId": "bc86a653-678c-46af-871d-9aefa79e4d96"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A   B\n",
       "0  1  11\n",
       "1  5   1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "A = pd.DataFrame(rng.randint(0, 20, (2, 2)),\n",
    "                 columns=list('AB'))\n",
    "A"
   ]
  },
  {
   "metadata": {
    "id": "Zj6a93Qcp1dz",
    "outputId": "5634bb23-cc89-4f3a-f99f-0c44931ad369"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B</th>\n",
       "      <th>A</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   B  A  C\n",
       "0  4  0  9\n",
       "1  5  8  0\n",
       "2  9  2  6"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "B = pd.DataFrame(rng.randint(0, 10, (3, 3)),\n",
    "                 columns=list('BAC'))\n",
    "B"
   ]
  },
  {
   "metadata": {
    "id": "VIUCN5pap1d0",
    "outputId": "67141421-fb79-44eb-c46f-e71d9a728f5a"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      A     B   C\n",
       "0   1.0  15.0 NaN\n",
       "1  13.0   6.0 NaN\n",
       "2   NaN   NaN NaN"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "A + B"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Notice that indices are aligned correctly irrespective of their order in the two objects, and indices in the result are sorted.\n",
    "As was the case with ``Series``, we can use the associated object's arithmetic method and pass any desired ``fill_value`` to be used in place of missing entries.\n",
    "Here we'll fill with the mean of all values in ``A`` (computed by first stacking the rows of ``A``):"
   ]
  },
  {
   "metadata": {
    "id": "NB0pTRNpp1d0",
    "outputId": "34ff502a-ae3f-4977-d7f2-7f8b4733b7fd"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.5</td>\n",
       "      <td>13.5</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      A     B     C\n",
       "0   1.0  15.0  13.5\n",
       "1  13.0   6.0   4.5\n",
       "2   6.5  13.5  10.5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "fill = A.stack().mean()\n",
    "A.add(B, fill_value=fill)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The following table lists Python operators and their equivalent Pandas object methods:\n",
    "\n",
    "| Python Operator | Pandas Method(s)                      |\n",
    "|-----------------|---------------------------------------|\n",
    "| ``+``           | ``add()``                             |\n",
    "| ``-``           | ``sub()``, ``subtract()``             |\n",
    "| ``*``           | ``mul()``, ``multiply()``             |\n",
    "| ``/``           | ``truediv()``, ``div()``, ``divide()``|\n",
    "| ``//``          | ``floordiv()``                        |\n",
    "| ``%``           | ``mod()``                             |\n",
    "| ``**``          | ``pow()``                             |\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Ufuncs: Operations Between DataFrame and Series\n",
    "\n",
    "When performing operations between a ``DataFrame`` and a ``Series``, the index and column alignment is similarly maintained.\n",
    "Operations between a ``DataFrame`` and a ``Series`` are similar to operations between a two-dimensional and one-dimensional NumPy array.\n",
    "Consider one common operation, where we find the difference of a two-dimensional array and one of its rows:"
   ]
  },
  {
   "metadata": {
    "id": "oGXuB5eLp1d0",
    "outputId": "4710583d-b300-476a-8a58-4163c9509854"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 8, 2, 4],\n",
       "       [2, 6, 4, 8],\n",
       "       [6, 1, 3, 8]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "A = rng.randint(10, size=(3, 4))\n",
    "A"
   ]
  },
  {
   "metadata": {
    "id": "6RNHxXRap1d1",
    "outputId": "7e7f5bb5-d7e1-4ad0-ad9e-eb4f93755096"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0],\n",
       "       [-1, -2,  2,  4],\n",
       "       [ 3, -7,  1,  4]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "A - A[0]"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "According to NumPy's broadcasting rules (see [Computation on Arrays: Broadcasting](02.05-Computation-on-arrays-broadcasting.ipynb)), subtraction between a two-dimensional array and one of its rows is applied row-wise.\n",
    "\n",
    "In Pandas, the convention similarly operates row-wise by default:"
   ]
  },
  {
   "metadata": {
    "id": "Cw0CbNVRp1d1",
    "outputId": "48678e1c-8a35-4853-85c7-663d309cde58"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>R</th>\n",
       "      <th>S</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q  R  S  T\n",
       "0  0  0  0  0\n",
       "1 -1 -2  2  4\n",
       "2  3 -7  1  4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "df = pd.DataFrame(A, columns=list('QRST'))\n",
    "df - df.iloc[0]"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "If you would instead like to operate column-wise, you can use the object methods mentioned earlier, while specifying the ``axis`` keyword:"
  },
  {
   "metadata": {
    "id": "haOh-ALRp1d1",
    "outputId": "39cbcc64-b4c4-4a16-e926-c238151bff57"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>R</th>\n",
       "      <th>S</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-5</td>\n",
       "      <td>0</td>\n",
       "      <td>-6</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q  R  S  T\n",
       "0 -5  0 -6 -4\n",
       "1 -4  0 -2  2\n",
       "2  5  0  2  7"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "df.subtract(df['R'], axis=0)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Note that these ``DataFrame``/``Series`` operations, like the operations discussed above, will automatically align  indices between the two elements:"
  },
  {
   "metadata": {
    "id": "ivfQXvNkp1d6",
    "outputId": "85d8ee4f-17d9-45fa-bae1-90e2400e1523"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q    3\n",
       "S    2\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "halfrow = df.iloc[0, ::2]\n",
    "halfrow"
   ]
  },
  {
   "metadata": {
    "id": "E-Z_PtCep1d6",
    "outputId": "22a04c5a-9b7e-47f4-fd0b-203abeb4fc06"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>R</th>\n",
       "      <th>S</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Q   R    S   T\n",
       "0  0.0 NaN  0.0 NaN\n",
       "1 -1.0 NaN  2.0 NaN\n",
       "2  3.0 NaN  1.0 NaN"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "df - halfrow"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This preservation and alignment of indices and columns means that operations on data in Pandas will always maintain the data context, which prevents the types of silly errors that might come up when working with heterogeneous and/or misaligned data in raw NumPy arrays."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<!--NAVIGATION-->\n",
    "< [Data Indexing and Selection](03.02-Data-Indexing-and-Selection.ipynb) | [Contents](Index.ipynb) | [Handling Missing Data](03.04-Missing-Values.ipynb) >\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.03-Operations-in-Pandas.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Dataframe 'europe' is a dataframe with the countries of Europe as the index. It contains the columns population and GDP.\\\n",
    "National_dept is stored in a series-object and is only available for a few countries.\\\n",
    "The source-data apperently contained some errors. europe_correction is a series with the same index as 'europe' and contains the correction factors for the data.\\\n",
    " *We asked Copilot to generate the data, so it is probably no accurate data*"
   ]
  },
  {
   "metadata": {
    "collapsed": true,
    "id": "initial_id",
    "ExecuteTime": {
     "end_time": "2025-02-04T11:08:42.825560Z",
     "start_time": "2025-02-04T11:08:40.318204Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.datasets as ds\n",
    "\n",
    "#Data preperation\n",
    "rng = np.random.default_rng(42)\n",
    "#@copilot: create a dataframe with the countries of europe as the index, with a column population and gbp\n",
    "countries = ['France', 'Germany', 'Italy', 'Spain', 'Portugal', 'Greece', 'Belgium', 'Netherlands', 'Luxembourg', 'Austria', 'Switzerland', 'Denmark', 'Sweden', 'Norway', 'Finland', 'Iceland', 'Ireland', 'United Kingdom']\n",
    "population = [67, 83, 60, 47, 10, 11, 11, 17, 0.6, 9, 8, 6, 10, 5, 5, 0.3, 5, 67]\n",
    "GDP = [2.78, 4.42, 2.08, 1.39, 0.23, 0.18, 0.53, 0.91, 0.06, 0.45, 0.70, 0.35, 0.53, 0.40, 0.27, 0.02, 0.33, 2.83]\n",
    "\n",
    "national_dept = pd.Series([2.36, 2.09, 2.34, 1.18, 2.32], index=['France', 'Belgium', 'Italy', 'Austria', 'Monaco'])\n",
    "europe = pd.DataFrame({'population': population, 'GDP': GDP}, index=countries)\n",
    "europe.sort_index(inplace=True)\n",
    "\n",
    "europe_correction= rng.choice([0.99, 0.98,1.01,1], size=18)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Before you start, familiarize yourself with the dataframe.\n",
    "\n",
    "a. Add a column to the dataframe GDP_per_capita which is the GDP divided by the population. Check the result.\n",
    "\n",
    "b. Create a series national_dept_per_capita with the same index as the dataframe europe. It contains the national_dept divided by the population. Check the result.\n",
    "\n",
    "c. Create a series national_dept_per_capita_b with the same index as the dataframe europe.It contains the national_dept divided by the population. When indexes don't align, the result should be set to 0. Check the result.\n",
    "\n",
    "d. Add national_dept and national_dept_per_capita_b to the dataframe europe\n",
    "\n",
    "e. All numbers in the dataframe have to be corrected, by multiplying every row with the corresponding value in europe_correction.\n",
    "\n",
    "f. population, GDP and national_dept are in billions.Create a new dataframe europe_c with these columns adjusted. Check the result."
   ]
  },
  {
   "metadata": {
    "id": "c0f3b85fc092a89c"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "print(europe)\n",
    "print(europe.describe())\n",
    "print(europe.info())\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {
    "id": "b1934291f4c0a242",
    "outputId": "7b6a3178-1de1-4683-f747-5a20b25b3045",
    "ExecuteTime": {
     "end_time": "2025-02-04T11:16:52.754546Z",
     "start_time": "2025-02-04T11:16:52.733292Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      "Austria           0.050000\n",
      "Belgium           0.048182\n",
      "Denmark           0.058333\n",
      "Finland           0.054000\n",
      "France            0.041493\n",
      "Germany           0.053253\n",
      "Greece            0.016364\n",
      "Iceland           0.066667\n",
      "Ireland           0.066000\n",
      "Italy             0.034667\n",
      "Luxembourg        0.100000\n",
      "Netherlands       0.053529\n",
      "Norway            0.080000\n",
      "Portugal          0.023000\n",
      "Spain             0.029574\n",
      "Sweden            0.053000\n",
      "Switzerland       0.087500\n",
      "United Kingdom    0.042239\n",
      "Name: GDP_per_capita, dtype: float64\n",
      "b:\n",
      "Austria           1.351244e-28\n",
      "Belgium           1.900000e-28\n",
      "Denmark                    NaN\n",
      "Finland                    NaN\n",
      "France            3.742476e-29\n",
      "Germany                    NaN\n",
      "Greece                     NaN\n",
      "Iceland                    NaN\n",
      "Ireland                    NaN\n",
      "Italy             4.019380e-29\n",
      "Luxembourg                 NaN\n",
      "Monaco                     NaN\n",
      "Netherlands                NaN\n",
      "Norway                     NaN\n",
      "Portugal                   NaN\n",
      "Spain                      NaN\n",
      "Sweden                     NaN\n",
      "Switzerland                NaN\n",
      "United Kingdom             NaN\n",
      "dtype: float64\n",
      "c:\n",
      "Austria           1.351244e-28\n",
      "Belgium           1.900000e-28\n",
      "Denmark           0.000000e+00\n",
      "Finland           0.000000e+00\n",
      "France            3.742476e-29\n",
      "Germany           0.000000e+00\n",
      "Greece            0.000000e+00\n",
      "Iceland           0.000000e+00\n",
      "Ireland           0.000000e+00\n",
      "Italy             4.019380e-29\n",
      "Luxembourg        0.000000e+00\n",
      "Monaco                     inf\n",
      "Netherlands       0.000000e+00\n",
      "Norway            0.000000e+00\n",
      "Portugal          0.000000e+00\n",
      "Spain             0.000000e+00\n",
      "Sweden            0.000000e+00\n",
      "Switzerland       0.000000e+00\n",
      "United Kingdom    0.000000e+00\n",
      "dtype: float64\n",
      "d:\n",
      "e:\n",
      "f:\n",
      "                  population           GDP  GDP_per_capita  national_dept  \\\n",
      "Austria         8.645364e+36  4.322682e+35        0.049500   1.168200e+09   \n",
      "Belgium         1.100000e+37  5.300000e+35        0.048182   2.090000e+09   \n",
      "Denmark         6.243624e+36  3.642114e+35        0.058917            NaN   \n",
      "Finland         4.611841e+36  2.490394e+35        0.052920            NaN   \n",
      "France          6.179867e+37  2.564183e+36        0.040663   2.312800e+09   \n",
      "Germany         8.300000e+37  4.420000e+36        0.053253            NaN   \n",
      "Greece          1.056656e+37  1.729073e+35        0.016200            NaN   \n",
      "Iceland         3.121812e+35  2.081208e+34        0.067333            NaN   \n",
      "Ireland         4.802980e+36  3.169967e+35        0.065340            NaN   \n",
      "Italy           5.763576e+37  1.998040e+36        0.034320   2.316600e+09   \n",
      "Luxembourg      6.243624e+35  6.243624e+34        0.101000            NaN   \n",
      "Netherlands     1.700000e+37  9.100000e+35        0.053529            NaN   \n",
      "Norway          5.203020e+36  4.162416e+35        0.080800            NaN   \n",
      "Portugal        1.000000e+37  2.300000e+35        0.023000            NaN   \n",
      "Spain           4.890839e+37  1.446440e+36        0.029870            NaN   \n",
      "Sweden          1.000000e+37  5.300000e+35        0.053000            NaN   \n",
      "Switzerland     8.324832e+36  7.284228e+35        0.088375            NaN   \n",
      "United Kingdom  6.435993e+37  2.718487e+36        0.041816            NaN   \n",
      "\n",
      "                national_dept_per_capita  \n",
      "Austria                     1.337732e-28  \n",
      "Belgium                     1.900000e-28  \n",
      "Denmark                     0.000000e+00  \n",
      "Finland                     0.000000e+00  \n",
      "France                      3.667626e-29  \n",
      "Germany                     0.000000e+00  \n",
      "Greece                      0.000000e+00  \n",
      "Iceland                     0.000000e+00  \n",
      "Ireland                     0.000000e+00  \n",
      "Italy                       3.979186e-29  \n",
      "Luxembourg                  0.000000e+00  \n",
      "Netherlands                 0.000000e+00  \n",
      "Norway                      0.000000e+00  \n",
      "Portugal                    0.000000e+00  \n",
      "Spain                       0.000000e+00  \n",
      "Sweden                      0.000000e+00  \n",
      "Switzerland                 0.000000e+00  \n",
      "United Kingdom              0.000000e+00  \n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "#a\n",
    "print(\"a:\")\n",
    "europe['GDP_per_capita'] = europe['GDP'] / europe['population']\n",
    "print(europe['GDP_per_capita'])\n",
    "#b\n",
    "print(\"b:\")\n",
    "national_dept_per_capita = national_dept / europe['population']\n",
    "print(national_dept_per_capita)\n",
    "#c\n",
    "print(\"c:\")\n",
    "national_dept_per_capita_b = national_dept.div(europe['population'], fill_value=0)\n",
    "# we use the 'div' method to divide the series. The 'fill_value' argument is used to fill missing values with 0. div is the equivalent of the / operator in Pandas.\n",
    "print(national_dept_per_capita_b)\n",
    "#d\n",
    "print(\"d:\")\n",
    "europe['national_dept'] = national_dept\n",
    "europe['national_dept_per_capita'] = national_dept_per_capita_b\n",
    "# e\n",
    "print(\"e:\")\n",
    "europe = europe.multiply(europe_correction, axis=0)\n",
    "#Perhaps you tried 'europe2= europe * europe_correction'. This does not work because broadcasting works row-wise in Pandas by default. If you want to multiply column-wise, you need to use the 'multiply' method.\n",
    "# f\n",
    "print(\"f:\")\n",
    "europe[['population', 'GDP', 'national_dept']] *= 1e9\n",
    "print(europe)\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T11:08:43.188634Z",
     "start_time": "2025-02-04T11:08:43.175750Z"
    },
    "id": "3c17c8168c5f828b"
   },
   "cell_type": "code",
   "outputs": [],
   "source": "",
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<!--BOOK_INFORMATION-->\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"figures/PDSH-cover-small.png\">\n",
    "\n",
    "*This notebook contains an excerpt from the [Python Data Science Handbook](http://shop.oreilly.com/product/0636920034919.do) by Jake VanderPlas; the content is available [on GitHub](https://github.com/jakevdp/PythonDataScienceHandbook).*\n",
    "\n",
    "*The text is released under the [CC-BY-NC-ND license](https://creativecommons.org/licenses/by-nc-nd/3.0/us/legalcode), and code is released under the [MIT license](https://opensource.org/licenses/MIT). If you find this content useful, please consider supporting the work by [buying the book](http://shop.oreilly.com/product/0636920034919.do)!*"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<!--NAVIGATION-->\n",
    "< [Operating on Data in Pandas](03.03-Operations-in-Pandas.ipynb) | [Contents](Index.ipynb) | [Hierarchical Indexing](03.05-Hierarchical-Indexing.ipynb) >\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.04-Missing-Values.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Handling Missing Data"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The difference between data found in many tutorials and data in the real world is that real-world data is rarely clean and homogeneous.\n",
    "In particular, many interesting datasets will have some amount of data missing.\n",
    "To make matters even more complicated, different data sources may indicate missing data in different ways.\n",
    "\n",
    "In this section, we will discuss some general considerations for missing data, discuss how Pandas chooses to represent it, and demonstrate some built-in Pandas tools for handling missing data in Python.\n",
    "Here and throughout the book, we'll refer to missing data in general as *null*, *NaN*, or *NA* values."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Trade-Offs in Missing Data Conventions\n",
    "<div style=\"border: 2px solid orange; padding: 10px; border-radius: 5px; background-color: #ebcf34; color: #664f2c;\">\n",
    "<strong>! </strong>It's sufficient to read this section for understanding.\n",
    "</div>\n",
    "There are a number of schemes that have been developed to indicate the presence of missing data in a table or DataFrame.\n",
    "Generally, they revolve around one of two strategies: using a *mask* that globally indicates missing values, or choosing a *sentinel value* that indicates a missing entry.\n",
    "\n",
    "In the masking approach, the mask might be an entirely separate Boolean array, or it may involve appropriation of one bit in the data representation to locally indicate the null status of a value.\n",
    "\n",
    "In the sentinel approach, the sentinel value could be some data-specific convention, such as indicating a missing integer value with -9999 or some rare bit pattern, or it could be a more global convention, such as indicating a missing floating-point value with NaN (Not a Number), a special value which is part of the IEEE floating-point specification.\n",
    "\n",
    "None of these approaches is without trade-offs: use of a separate mask array requires allocation of an additional Boolean array, which adds overhead in both storage and computation. A sentinel value reduces the range of valid values that can be represented, and may require extra (often non-optimized) logic in CPU and GPU arithmetic. Common special values like NaN are not available for all data types.\n",
    "\n",
    "As in most cases where no universally optimal choice exists, different languages and systems use different conventions.\n",
    "For example, the R language uses reserved bit patterns within each data type as sentinel values indicating missing data, while the SciDB system uses an extra byte attached to every cell which indicates a NA state."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Missing Data in Pandas\n",
    "<div style=\"border: 2px solid orange; padding: 10px; border-radius: 5px; background-color: #ebcf34; color: #664f2c;\">\n",
    "<strong>! </strong>It's sufficient to read this section for understanding.\n",
    "</div>\n",
    "\n",
    "The way in which Pandas handles missing values is constrained by its reliance on the NumPy package, which does not have a built-in notion of NA values for non-floating-point data types.\n",
    "\n",
    "Pandas could have followed R's lead in specifying bit patterns for each individual data type to indicate nullness, but this approach turns out to be rather unwieldy.\n",
    "While R contains four basic data types, NumPy supports *far* more than this: for example, while R has a single integer type, NumPy supports *fourteen* basic integer types once you account for available precisions, signedness, and endianness of the encoding.\n",
    "Reserving a specific bit pattern in all available NumPy types would lead to an unwieldy amount of overhead in special-casing various operations for various types, likely even requiring a new fork of the NumPy package. Further, for the smaller data types (such as 8-bit integers), sacrificing a bit to use as a mask will significantly reduce the range of values it can represent.\n",
    "\n",
    "NumPy does have support for masked arrays – that is, arrays that have a separate Boolean mask array attached for marking data as \"good\" or \"bad.\"\n",
    "Pandas could have derived from this, but the overhead in both storage, computation, and code maintenance makes that an unattractive choice.\n",
    "\n",
    "With these constraints in mind, Pandas chose to use sentinels for missing data, and further chose to use two already-existing Python null values: the special floating-point ``NaN`` value, and the Python ``None`` object.\n",
    "This choice has some side effects, as we will see, but in practice ends up being a good compromise in most cases of interest."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### ``None``: Pythonic missing data\n",
    "\n",
    "The first sentinel value used by Pandas is ``None``, a Python singleton object that is often used for missing data in Python code.\n",
    "Because it is a Python object, ``None`` cannot be used in any arbitrary NumPy/Pandas array, but only in arrays with data type ``'object'`` (i.e., arrays of Python objects):"
   ]
  },
  {
   "metadata": {
    "collapsed": true,
    "id": "1HDCAVA-5uMY"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "metadata": {
    "id": "0T8k13VC5uMZ",
    "outputId": "2193a607-499f-4db7-bb14-267c956e6b08"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, None, 3, 4], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "vals1 = np.array([1, None, 3, 4])\n",
    "vals1"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This ``dtype=object`` means that the best common type representation NumPy could infer for the contents of the array is that they are Python objects.\n",
    "While this kind of object array is useful for some purposes, any operations on the data will be done at the Python level, with much more overhead than the typically fast operations seen for arrays with native types:"
   ]
  },
  {
   "metadata": {
    "id": "1Hn4tRdr5uMa",
    "outputId": "e5624fc5-f0a8-462a-fc1b-070ef5031cf3"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype = object\n",
      "10 loops, best of 3: 78.2 ms per loop\n",
      "\n",
      "dtype = int\n",
      "100 loops, best of 3: 3.06 ms per loop\n",
      "\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "for dtype in ['object', 'int']:\n",
    "    print(\"dtype =\", dtype)\n",
    "    %timeit np.arange(1E6, dtype=dtype).sum()\n",
    "    print()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The use of Python objects in an array also means that if you perform aggregations like ``sum()`` or ``min()`` across an array with a ``None`` value, you will generally get an error:"
  },
  {
   "metadata": {
    "id": "lfqRWgZT5uMb",
    "outputId": "3797c8a3-79c9-4dba-8705-1f4f23c913cb"
   },
   "cell_type": "code",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-4-749fd8ae6030>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mvals1\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/Users/jakevdp/anaconda/lib/python3.5/site-packages/numpy/core/_methods.py\u001B[0m in \u001B[0;36m_sum\u001B[0;34m(a, axis, dtype, out, keepdims)\u001B[0m\n\u001B[1;32m     30\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0m_sum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkeepdims\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 32\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mumr_sum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mout\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkeepdims\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     33\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     34\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0m_prod\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkeepdims\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: unsupported operand type(s) for +: 'int' and 'NoneType'"
     ]
    }
   ],
   "execution_count": null,
   "source": "vals1.sum()"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This reflects the fact that addition between an integer and ``None`` is undefined."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### ``NaN``: Missing numerical data\n",
    "\n",
    "The other missing data representation, ``NaN`` (acronym for *Not a Number*), is different; it is a special floating-point value recognized by all systems that use the standard IEEE floating-point representation:"
   ]
  },
  {
   "metadata": {
    "id": "PQormpiw5uMc",
    "outputId": "a8d5faee-20c9-46e0-e98a-16f1987a24f5"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "vals2 = np.array([1, np.nan, 3, 4])\n",
    "vals2.dtype"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Notice that NumPy chose a native floating-point type for this array: this means that unlike the object array from before, this array supports fast operations pushed into compiled code.\n",
    "You should be aware that ``NaN`` is a bit like a data virus–it infects any other object it touches.\n",
    "Regardless of the operation, the result of arithmetic with ``NaN`` will be another ``NaN``:"
   ]
  },
  {
   "metadata": {
    "id": "wPlCwh6A5uMc",
    "outputId": "49c1192e-2873-4468-87aa-452245e4fd09"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "1 + np.nan"
  },
  {
   "metadata": {
    "id": "hUnc70NR5uMc",
    "outputId": "36c0ff83-7e25-47fc-bd63-41fa32b071b5"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "0 *  np.nan"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Note that this means that aggregates over the values are well defined (i.e., they don't result in an error) but not always useful:"
  },
  {
   "metadata": {
    "id": "jUXX4HgR5uMd",
    "outputId": "ff38761c-2d83-49b3-f426-876cc8f270f7"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(nan, nan, nan)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "vals2.sum(), vals2.min(), vals2.max()"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "NumPy does provide some special aggregations that will ignore these missing values:"
  },
  {
   "metadata": {
    "id": "zQz8tD7J5uMd",
    "outputId": "65501a08-f6de-4d88-8d83-282032eb1ae0"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8.0, 1.0, 4.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "np.nansum(vals2), np.nanmin(vals2), np.nanmax(vals2)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Keep in mind that ``NaN`` is specifically a floating-point value; there is no equivalent NaN value for integers, strings, or other types."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### NaN and None in Pandas\n",
    "\n",
    "``NaN`` and ``None`` both have their place, and Pandas is built to handle the two of them nearly interchangeably, converting between them where appropriate:"
   ]
  },
  {
   "metadata": {
    "id": "chJGjhcS5uMe",
    "outputId": "0f174451-b7e9-4054-e092-f7ccef78ac56"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    NaN\n",
       "2    2.0\n",
       "3    NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "pd.Series([1, np.nan, 2, None])"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "For types that don't have an available sentinel value, Pandas automatically type-casts when NA values are present.\n",
    "For example, if we set a value in an integer array to ``np.nan``, it will automatically be upcast to a floating-point type to accommodate the NA:"
   ]
  },
  {
   "metadata": {
    "id": "fR_rTH0b5uMe",
    "outputId": "f7cf2676-29eb-4afa-fcbc-9a15a6f6b234"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "x = pd.Series(range(2), dtype=int)\n",
    "x"
   ]
  },
  {
   "metadata": {
    "id": "mogLHGZe5uMe",
    "outputId": "990c861b-4701-46aa-e9a8-7db525e0d869"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    NaN\n",
       "1    1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "x[0] = None\n",
    "x"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Notice that in addition to casting the integer array to floating point, Pandas automatically converts the ``None`` to a ``NaN`` value.\n",
    "(Be aware that there is a proposal to add a native integer NA to Pandas in the future; as of this writing, it has not been included).\n",
    "\n",
    "While this type of magic may feel a bit hackish compared to the more unified approach to NA values in domain-specific languages like R, the Pandas sentinel/casting approach works quite well in practice and in my experience only rarely causes issues.\n",
    "\n",
    "The following table lists the upcasting conventions in Pandas when NA values are introduced:\n",
    "\n",
    "|Typeclass     | Conversion When Storing NAs | NA Sentinel Value      |\n",
    "|--------------|-----------------------------|------------------------|\n",
    "| ``floating`` | No change                   | ``np.nan``             |\n",
    "| ``object``   | No change                   | ``None`` or ``np.nan`` |\n",
    "| ``integer``  | Cast to ``float64``         | ``np.nan``             |\n",
    "| ``boolean``  | Cast to ``object``          | ``None`` or ``np.nan`` |\n",
    "\n",
    "Keep in mind that in Pandas, string data is always stored with an ``object`` dtype."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div style=\"border: 2px solid orange; padding: 10px; border-radius: 5px; background-color: #ebcf34; color: #664f2c;\">\n",
    "<strong>! </strong>The read only parts ends here. The following sections are an integral part of the course material\n",
    "</div>\n",
    "\n",
    "## Operating on Null Values\n",
    "\n",
    "As we have seen, Pandas treats ``None`` and ``NaN`` as essentially interchangeable for indicating missing or null values.\n",
    "To facilitate this convention, there are several useful methods for detecting, removing, and replacing null values in Pandas data structures.\n",
    "They are:\n",
    "\n",
    "- ``isnull()``: Generate a boolean mask indicating missing values\n",
    "- ``notnull()``: Opposite of ``isnull()``\n",
    "- ``dropna()``: Return a filtered version of the data\n",
    "- ``fillna()``: Return a copy of the data with missing values filled or imputed\n",
    "\n",
    "We will conclude this section with a brief exploration and demonstration of these routines."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Detecting null values\n",
    "Pandas data structures have two useful methods for detecting null data: ``isnull()`` and ``notnull()``.\n",
    "Either one will return a Boolean mask over the data. For example:"
   ]
  },
  {
   "metadata": {
    "collapsed": true,
    "id": "gcvZePG-5uMf"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "data = pd.Series([1, np.nan, 'hello', None])"
  },
  {
   "metadata": {
    "id": "ozCSv6_O5uMf",
    "outputId": "ce244ba4-5814-4363-e371-1ccdf78dbe65"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1     True\n",
       "2    False\n",
       "3     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "data.isnull()"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As mentioned in [Data Indexing and Selection](03.02-Data-Indexing-and-Selection.ipynb), Boolean masks can be used directly as a ``Series`` or ``DataFrame`` index:"
  },
  {
   "metadata": {
    "id": "XdZWORqv5uMh",
    "outputId": "8f26475a-1d47-45f8-b343-258cfb824f10"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "2    hello\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "data[data.notnull()]"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The ``isnull()`` and ``notnull()`` methods produce similar Boolean results for ``DataFrame``s."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Dropping null values\n",
    "\n",
    "In addition to the masking used before, there are the convenience methods, ``dropna()``\n",
    "(which removes NA values) and ``fillna()`` (which fills in NA values). For a ``Series``,\n",
    "the result is straightforward:"
   ]
  },
  {
   "metadata": {
    "id": "d5zsxK8R5uMi",
    "outputId": "0162c400-e284-4c3e-d6a9-8a02c1a8f0de"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "2    hello\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "data.dropna()"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "For a ``DataFrame``, there are more options.\n",
    "Consider the following ``DataFrame``:"
   ]
  },
  {
   "metadata": {
    "id": "e2mgMhxo5uMn",
    "outputId": "ae9e346b-29f4-44c4-bae4-350502d2d9c7"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1  2\n",
       "0  1.0  NaN  2\n",
       "1  2.0  3.0  5\n",
       "2  NaN  4.0  6"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "df = pd.DataFrame([[1,      np.nan, 2],\n",
    "                   [2,      3,      5],\n",
    "                   [np.nan, 4,      6]])\n",
    "df"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We cannot drop single values from a ``DataFrame``; we can only drop full rows or full columns.\n",
    "Depending on the application, you might want one or the other, so ``dropna()`` gives a number of options for a ``DataFrame``.\n",
    "\n",
    "By default, ``dropna()`` will drop all rows in which *any* null value is present:"
   ]
  },
  {
   "metadata": {
    "id": "lh2sDr_i5uMo",
    "outputId": "076f0439-ae19-474e-c1e2-508f33feb4de"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1  2\n",
       "1  2.0  3.0  5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "df.dropna()"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Alternatively, you can drop NA values along a different axis; ``axis=1`` drops all columns containing a null value:"
  },
  {
   "metadata": {
    "id": "MEpovNfd5uMo",
    "outputId": "4bec6503-2dbb-4e9d-9d0d-9cfae1bde993"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   2\n",
       "0  2\n",
       "1  5\n",
       "2  6"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "df.dropna(axis='columns')"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "But this drops some good data as well; you might rather be interested in dropping rows or columns with *all* NA values, or a majority of NA values.\n",
    "This can be specified through the ``how`` or ``thresh`` parameters, which allow fine control of the number of nulls to allow through.\n",
    "\n",
    "The default is ``how='any'``, such that any row or column (depending on the ``axis`` keyword) containing a null value will be dropped.\n",
    "You can also specify ``how='all'``, which will only drop rows/columns that are *all* null values:"
   ]
  },
  {
   "metadata": {
    "id": "q54SdX6b5uMp",
    "outputId": "0dbbba0c-0d96-49ba-99cc-a931dc1a00a3"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1  2   3\n",
       "0  1.0  NaN  2 NaN\n",
       "1  2.0  3.0  5 NaN\n",
       "2  NaN  4.0  6 NaN"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "df[3] = np.nan\n",
    "df"
   ]
  },
  {
   "metadata": {
    "id": "gf_iaImf5uMp",
    "outputId": "b9c15644-06e4-43db-8dfd-eb662a8f6917"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1  2\n",
       "0  1.0  NaN  2\n",
       "1  2.0  3.0  5\n",
       "2  NaN  4.0  6"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "df.dropna(axis='columns', how='all')"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "For finer-grained control, the ``thresh`` parameter lets you specify a minimum number of non-null values for the row/column to be kept:"
  },
  {
   "metadata": {
    "id": "56N2ji9O5uMp",
    "outputId": "a018e187-b4c7-43ac-db6a-d314eb2bd522"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1  2   3\n",
       "1  2.0  3.0  5 NaN"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "df.dropna(axis='rows', thresh=3)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Here the first and last row have been dropped, because they contain only two non-null values."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Filling null values\n",
    "\n",
    "Sometimes rather than dropping NA values, you'd rather replace them with a valid value.\n",
    "This value might be a single number like zero, or it might be some sort of imputation or interpolation from the good values.\n",
    "You could do this in-place using the ``isnull()`` method as a mask, but because it is such a common operation Pandas provides the ``fillna()`` method, which returns a copy of the array with the null values replaced.\n",
    "\n",
    "Consider the following ``Series``:"
   ]
  },
  {
   "metadata": {
    "id": "169VF2xL5uMq",
    "outputId": "a12b160b-8ae8-4fdc-e5e9-85ac2fb06075"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    1.0\n",
       "b    NaN\n",
       "c    2.0\n",
       "d    NaN\n",
       "e    3.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "data = pd.Series([1, np.nan, 2, None, 3], index=list('abcde'))\n",
    "data"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can fill NA entries with a single value, such as zero:"
  },
  {
   "metadata": {
    "id": "uglouhbx5uMq",
    "outputId": "36f61afb-6efb-40f0-b2f3-1506c0612a4d"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    1.0\n",
       "b    0.0\n",
       "c    2.0\n",
       "d    0.0\n",
       "e    3.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "data.fillna(0)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can specify a forward-fill to propagate the previous value forward:"
  },
  {
   "metadata": {
    "id": "aQVdn3vu5uMr",
    "outputId": "3f7b4653-03f4-4234-ec24-679009d078f8"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    1.0\n",
       "b    1.0\n",
       "c    2.0\n",
       "d    2.0\n",
       "e    3.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "# forward-fill\n",
    "data.fillna(method='ffill')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Or we can specify a back-fill to propagate the next values backward:"
  },
  {
   "metadata": {
    "id": "XdESXswn5uMs",
    "outputId": "9e7a81d0-0525-4fb1-e2ff-3121ba03d3b1"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    1.0\n",
       "b    2.0\n",
       "c    2.0\n",
       "d    3.0\n",
       "e    3.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "# back-fill\n",
    "data.fillna(method='bfill')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "For ``DataFrame``s, the options are similar, but we can also specify an ``axis`` along which the fills take place:"
  },
  {
   "metadata": {
    "id": "H6phUJh05uMs",
    "outputId": "af1eea0d-c86c-4812-fbe6-4a65fa056387"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1  2   3\n",
       "0  1.0  NaN  2 NaN\n",
       "1  2.0  3.0  5 NaN\n",
       "2  NaN  4.0  6 NaN"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "df"
  },
  {
   "metadata": {
    "id": "7_HuiM0b5uMs",
    "outputId": "2207e324-aa8f-45f2-c7bf-2b8461e73fed"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3\n",
       "0  1.0  1.0  2.0  2.0\n",
       "1  2.0  3.0  5.0  5.0\n",
       "2  NaN  4.0  6.0  6.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "df.fillna(method='ffill', axis=1)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Notice that if a previous value is not available during a forward fill, the NA value remains."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<!--NAVIGATION-->\n",
    "< [Operating on Data in Pandas](03.03-Operations-in-Pandas.ipynb) | [Contents](Index.ipynb) | [Hierarchical Indexing](03.05-Hierarchical-Indexing.ipynb) >\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.04-Missing-Values.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dataframe 'europe' is a dataframe with the countries of Europe as the index. It's a variant on the dataframe from the previous exercise."
  },
  {
   "metadata": {
    "collapsed": true,
    "id": "initial_id",
    "ExecuteTime": {
     "end_time": "2024-10-04T07:55:10.758762900Z",
     "start_time": "2024-10-04T07:55:08.080795Z"
    },
    "outputId": "33654a67-b1e7-4c8e-dc64-bb354b77573b"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 18 entries, France to United Kingdom\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   population     18 non-null     Float32\n",
      " 1   GDP            17 non-null     Float32\n",
      " 2   national_dept  4 non-null      Float32\n",
      "dtypes: Float32(3)\n",
      "memory usage: 970.0+ bytes\n"
     ]
    },
    {
     "data": {
      "text/plain": "                population   GDP  national_dept\nFrance                67.0  2.78           2.36\nGermany               83.0  4.42           <NA>\nItaly                 60.0  2.08           2.34\nSpain                 47.0  1.39           <NA>\nPortugal              10.0  0.23           <NA>\nGreece                11.0  0.18           <NA>\nBelgium               11.0  0.53           2.09\nNetherlands           17.0  0.91           <NA>\nLuxembourg             0.6  0.06           <NA>\nAustria                9.0  0.45           1.18\nSwitzerland            8.0  <NA>           <NA>\nDenmark                6.0  0.35           <NA>\nSweden                10.0  0.53           <NA>\nNorway                 5.0   0.4           <NA>\nFinland                5.0  0.27           <NA>\nIceland                0.3  0.02           <NA>\nIreland                5.0  0.33           <NA>\nUnited Kingdom        67.0  2.83           <NA>",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>population</th>\n      <th>GDP</th>\n      <th>national_dept</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>France</th>\n      <td>67.0</td>\n      <td>2.78</td>\n      <td>2.36</td>\n    </tr>\n    <tr>\n      <th>Germany</th>\n      <td>83.0</td>\n      <td>4.42</td>\n      <td>&lt;NA&gt;</td>\n    </tr>\n    <tr>\n      <th>Italy</th>\n      <td>60.0</td>\n      <td>2.08</td>\n      <td>2.34</td>\n    </tr>\n    <tr>\n      <th>Spain</th>\n      <td>47.0</td>\n      <td>1.39</td>\n      <td>&lt;NA&gt;</td>\n    </tr>\n    <tr>\n      <th>Portugal</th>\n      <td>10.0</td>\n      <td>0.23</td>\n      <td>&lt;NA&gt;</td>\n    </tr>\n    <tr>\n      <th>Greece</th>\n      <td>11.0</td>\n      <td>0.18</td>\n      <td>&lt;NA&gt;</td>\n    </tr>\n    <tr>\n      <th>Belgium</th>\n      <td>11.0</td>\n      <td>0.53</td>\n      <td>2.09</td>\n    </tr>\n    <tr>\n      <th>Netherlands</th>\n      <td>17.0</td>\n      <td>0.91</td>\n      <td>&lt;NA&gt;</td>\n    </tr>\n    <tr>\n      <th>Luxembourg</th>\n      <td>0.6</td>\n      <td>0.06</td>\n      <td>&lt;NA&gt;</td>\n    </tr>\n    <tr>\n      <th>Austria</th>\n      <td>9.0</td>\n      <td>0.45</td>\n      <td>1.18</td>\n    </tr>\n    <tr>\n      <th>Switzerland</th>\n      <td>8.0</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n    </tr>\n    <tr>\n      <th>Denmark</th>\n      <td>6.0</td>\n      <td>0.35</td>\n      <td>&lt;NA&gt;</td>\n    </tr>\n    <tr>\n      <th>Sweden</th>\n      <td>10.0</td>\n      <td>0.53</td>\n      <td>&lt;NA&gt;</td>\n    </tr>\n    <tr>\n      <th>Norway</th>\n      <td>5.0</td>\n      <td>0.4</td>\n      <td>&lt;NA&gt;</td>\n    </tr>\n    <tr>\n      <th>Finland</th>\n      <td>5.0</td>\n      <td>0.27</td>\n      <td>&lt;NA&gt;</td>\n    </tr>\n    <tr>\n      <th>Iceland</th>\n      <td>0.3</td>\n      <td>0.02</td>\n      <td>&lt;NA&gt;</td>\n    </tr>\n    <tr>\n      <th>Ireland</th>\n      <td>5.0</td>\n      <td>0.33</td>\n      <td>&lt;NA&gt;</td>\n    </tr>\n    <tr>\n      <th>United Kingdom</th>\n      <td>67.0</td>\n      <td>2.83</td>\n      <td>&lt;NA&gt;</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#Data preparation\n",
    "countries = ['France', 'Germany', 'Italy', 'Spain', 'Portugal', 'Greece', 'Belgium', 'Netherlands', 'Luxembourg', 'Austria', 'Switzerland', 'Denmark', 'Sweden', 'Norway', 'Finland', 'Iceland', 'Ireland', 'United Kingdom']\n",
    "population = [67, 83, 60, 47, 10, 11, 11, 17, 0.6, 9, 8, 6, 10, 5, 5, 0.3, 5, 67]\n",
    "GDP = [2.78, 4.42, 2.08, 1.39, 0.23, 0.18, 0.53, 0.91, 0.06, 0.45, 0.70, 0.35, 0.53, 0.40, 0.27, 0.02, 0.33, 2.83]\n",
    "national_dept = pd.Series([2.36, 2.09, 2.34, 1.18, 2.32], index=['France', 'Belgium', 'Italy', 'Austria', 'Monaco'])\n",
    "europe = pd.DataFrame({'population': population, 'GDP': GDP}, index=countries)\n",
    "europe['national_dept'] = national_dept\n",
    "europe = europe.astype('Float32')\n",
    "europe.loc['Switzerland','GDP'] = pd.NA\n",
    "europe.info()\n",
    "europe"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Missing values in Pandas\n",
    "Investigate the dataframe europe.\n",
    "\n",
    "a. Create a ndarray with boolean values that are True when a specific value of the europe dataset is Null.\n",
    "\n",
    "b. Create a copy europe_b of the europe dataset. Drop all rows where at least one element is missing.\n",
    "\n",
    "c. With only a few countries left in the dataset it is clear that we will have to use another strategy:\n",
    "- Create a copy europe_c of the europe dataset.\n",
    "- For GDP replace the missing values by the mean of the GDP values. (This is of course not a good strategy in practice, but it is a good exercise).\n",
    "- After that delete the columns that still have missing values.\n",
    "- Check the results"
   ]
  },
  {
   "metadata": {
    "id": "40f53bd07066082c",
    "ExecuteTime": {
     "end_time": "2024-10-04T07:55:10.965357300Z",
     "start_time": "2024-10-04T07:55:10.735830600Z"
    },
    "outputId": "46ea6d0b-1267-4133-8a00-5b59fad438ab"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                population    GDP  national_dept\nFrance               False  False          False\nGermany              False  False           True\nItaly                False  False          False\nSpain                False  False           True\nPortugal             False  False           True\nGreece               False  False           True\nBelgium              False  False          False\nNetherlands          False  False           True\nLuxembourg           False  False           True\nAustria              False  False          False\nSwitzerland          False   True           True\nDenmark              False  False           True\nSweden               False  False           True\nNorway               False  False           True\nFinland              False  False           True\nIceland              False  False           True\nIreland              False  False           True\nUnited Kingdom       False  False           True",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>population</th>\n      <th>GDP</th>\n      <th>national_dept</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>France</th>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>Germany</th>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>Italy</th>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>Spain</th>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>Portugal</th>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>Greece</th>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>Belgium</th>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>Netherlands</th>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>Luxembourg</th>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>Austria</th>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>Switzerland</th>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>Denmark</th>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>Sweden</th>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>Norway</th>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>Finland</th>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>Iceland</th>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>Ireland</th>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>United Kingdom</th>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         population   GDP  national_dept\n",
      "France         67.0  2.78           2.36\n",
      "Italy          60.0  2.08           2.34\n",
      "Belgium        11.0  0.53           2.09\n",
      "Austria         9.0  0.45           1.18\n"
     ]
    },
    {
     "data": {
      "text/plain": "                population       GDP\nFrance                67.0      2.78\nGermany               83.0      4.42\nItaly                 60.0      2.08\nSpain                 47.0      1.39\nPortugal              10.0      0.23\nGreece                11.0      0.18\nBelgium               11.0      0.53\nNetherlands           17.0      0.91\nLuxembourg             0.6      0.06\nAustria                9.0      0.45\nSwitzerland            8.0  1.044706\nDenmark                6.0      0.35\nSweden                10.0      0.53\nNorway                 5.0       0.4\nFinland                5.0      0.27\nIceland                0.3      0.02\nIreland                5.0      0.33\nUnited Kingdom        67.0      2.83",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>population</th>\n      <th>GDP</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>France</th>\n      <td>67.0</td>\n      <td>2.78</td>\n    </tr>\n    <tr>\n      <th>Germany</th>\n      <td>83.0</td>\n      <td>4.42</td>\n    </tr>\n    <tr>\n      <th>Italy</th>\n      <td>60.0</td>\n      <td>2.08</td>\n    </tr>\n    <tr>\n      <th>Spain</th>\n      <td>47.0</td>\n      <td>1.39</td>\n    </tr>\n    <tr>\n      <th>Portugal</th>\n      <td>10.0</td>\n      <td>0.23</td>\n    </tr>\n    <tr>\n      <th>Greece</th>\n      <td>11.0</td>\n      <td>0.18</td>\n    </tr>\n    <tr>\n      <th>Belgium</th>\n      <td>11.0</td>\n      <td>0.53</td>\n    </tr>\n    <tr>\n      <th>Netherlands</th>\n      <td>17.0</td>\n      <td>0.91</td>\n    </tr>\n    <tr>\n      <th>Luxembourg</th>\n      <td>0.6</td>\n      <td>0.06</td>\n    </tr>\n    <tr>\n      <th>Austria</th>\n      <td>9.0</td>\n      <td>0.45</td>\n    </tr>\n    <tr>\n      <th>Switzerland</th>\n      <td>8.0</td>\n      <td>1.044706</td>\n    </tr>\n    <tr>\n      <th>Denmark</th>\n      <td>6.0</td>\n      <td>0.35</td>\n    </tr>\n    <tr>\n      <th>Sweden</th>\n      <td>10.0</td>\n      <td>0.53</td>\n    </tr>\n    <tr>\n      <th>Norway</th>\n      <td>5.0</td>\n      <td>0.4</td>\n    </tr>\n    <tr>\n      <th>Finland</th>\n      <td>5.0</td>\n      <td>0.27</td>\n    </tr>\n    <tr>\n      <th>Iceland</th>\n      <td>0.3</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>Ireland</th>\n      <td>5.0</td>\n      <td>0.33</td>\n    </tr>\n    <tr>\n      <th>United Kingdom</th>\n      <td>67.0</td>\n      <td>2.83</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "#a.\n",
    "europe.isnull()\n",
    "#b.\n",
    "europe_b = europe.dropna()\n",
    "print(europe_b)\n",
    "#c\n",
    "europe_c = europe.copy()\n",
    "europe_c['GDP'] = europe_c['GDP'].fillna(europe_c['GDP'].mean())\n",
    "europe_c = europe_c.dropna(axis='columns')\n",
    "europe_c\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<!--BOOK_INFORMATION-->\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"figures/PDSH-cover-small.png\">\n",
    "\n",
    "*This notebook contains an excerpt from the [Python Data Science Handbook](http://shop.oreilly.com/product/0636920034919.do) by Jake VanderPlas; the content is available [on GitHub](https://github.com/jakevdp/PythonDataScienceHandbook).*\n",
    "\n",
    "*The text is released under the [CC-BY-NC-ND license](https://creativecommons.org/licenses/by-nc-nd/3.0/us/legalcode), and code is released under the [MIT license](https://opensource.org/licenses/MIT). If you find this content useful, please consider supporting the work by [buying the book](http://shop.oreilly.com/product/0636920034919.do)!*"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<!--NAVIGATION-->\n",
    "< [Combining Datasets: Concat and Append](03.06-Concat-And-Append.ipynb) | [Contents](Index.ipynb) | [Aggregation and Grouping](03.08-Aggregation-and-Grouping.ipynb) >\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.07-Merge-and-Join.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Combining Datasets: Merge and Join"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "One essential feature offered by Pandas is its high-performance, in-memory join and merge operations.\n",
    "If you have ever worked with databases, you should be familiar with this type of data interaction.\n",
    "The main interface for this is the ``pd.merge`` function, and we'll see few examples of how this can work in practice.\n",
    "\n",
    "For convenience, we will start by redefining the ``display()`` functionality from the previous section:"
   ]
  },
  {
   "metadata": {
    "collapsed": true,
    "id": "OC34Hi-6upMy"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class display(object):\n",
    "    \"\"\"Display HTML representation of multiple objects\"\"\"\n",
    "    template = \"\"\"<div style=\"float: left; padding: 10px;\">\n",
    "    <p style='font-family:\"Courier New\", Courier, monospace'>{0}</p>{1}\n",
    "    </div>\"\"\"\n",
    "    def __init__(self, *args):\n",
    "        self.args = args\n",
    "\n",
    "    def _repr_html_(self):\n",
    "        return '\\n'.join(self.template.format(a, eval(a)._repr_html_())\n",
    "                         for a in self.args)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '\\n\\n'.join(a + '\\n' + repr(eval(a))\n",
    "                           for a in self.args)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Relational Algebra\n",
    "\n",
    "The behavior implemented in ``pd.merge()`` is a subset of what is known as *relational algebra*, which is a formal set of rules for manipulating relational data, and forms the conceptual foundation of operations available in most databases.\n",
    "The strength of the relational algebra approach is that it proposes several primitive operations, which become the building blocks of more complicated operations on any dataset.\n",
    "With this lexicon of fundamental operations implemented efficiently in a database or other program, a wide range of fairly complicated composite operations can be performed.\n",
    "\n",
    "Pandas implements several of these fundamental building-blocks in the ``pd.merge()`` function and the related ``join()`` method of ``Series`` and ``Dataframe``s.\n",
    "As we will see, these let you efficiently link data from different sources."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Categories of Joins\n",
    "\n",
    "The ``pd.merge()`` function implements a number of types of joins: the *one-to-one*, *many-to-one*, and *many-to-many* joins.\n",
    "All three types of joins are accessed via an identical call to the ``pd.merge()`` interface; the type of join performed depends on the form of the input data.\n",
    "Here we will show simple examples of the three types of merges, and discuss detailed options further below."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### One-to-one joins\n",
    "\n",
    "Perhaps the simplest type of merge expresion is the one-to-one join, which is in many ways very similar to the column-wise concatenation seen in [Combining Datasets: Concat & Append](03.06-Concat-And-Append.ipynb).\n",
    "As a concrete example, consider the following two ``DataFrames`` which contain information on several employees in a company:"
   ]
  },
  {
   "metadata": {
    "id": "l9gM6g_0upM5",
    "outputId": "7233ded5-2b4e-4757-e7e7-f2d59e2c76c0"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>df1</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Accounting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jake</td>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lisa</td>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sue</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>\n",
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>df2</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee</th>\n",
       "      <th>hire_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lisa</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jake</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sue</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>"
      ],
      "text/plain": [
       "df1\n",
       "  employee        group\n",
       "0      Bob   Accounting\n",
       "1     Jake  Engineering\n",
       "2     Lisa  Engineering\n",
       "3      Sue           HR\n",
       "\n",
       "df2\n",
       "  employee  hire_date\n",
       "0     Lisa       2004\n",
       "1      Bob       2008\n",
       "2     Jake       2012\n",
       "3      Sue       2014"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "df1 = pd.DataFrame({'employee': ['Bob', 'Jake', 'Lisa', 'Sue'],\n",
    "                    'group': ['Accounting', 'Engineering', 'Engineering', 'HR']})\n",
    "df2 = pd.DataFrame({'employee': ['Lisa', 'Bob', 'Jake', 'Sue'],\n",
    "                    'hire_date': [2004, 2008, 2012, 2014]})\n",
    "display('df1', 'df2')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "To combine this information into a single ``DataFrame``, we can use the ``pd.merge()`` function:"
  },
  {
   "metadata": {
    "id": "pN7AceDZupM8",
    "outputId": "0bc90333-90c1-4d63-e725-71613d4e0162"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee</th>\n",
       "      <th>group</th>\n",
       "      <th>hire_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Accounting</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jake</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lisa</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sue</td>\n",
       "      <td>HR</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  employee        group  hire_date\n",
       "0      Bob   Accounting       2008\n",
       "1     Jake  Engineering       2012\n",
       "2     Lisa  Engineering       2004\n",
       "3      Sue           HR       2014"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "df3 = pd.merge(df1, df2)\n",
    "df3"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The ``pd.merge()`` function recognizes that each ``DataFrame`` has an \"employee\" column, and automatically joins using this column as a key.\n",
    "The result of the merge is a new ``DataFrame`` that combines the information from the two inputs.\n",
    "Notice that the order of entries in each column is not necessarily maintained: in this case, the order of the \"employee\" column differs between ``df1`` and ``df2``, and the ``pd.merge()`` function correctly accounts for this.\n",
    "Additionally, keep in mind that the merge in general discards the index, except in the special case of merges by index (see the ``left_index`` and ``right_index`` keywords, discussed momentarily)."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Many-to-one joins"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Many-to-one joins are joins in which one of the two key columns contains duplicate entries.\n",
    "For the many-to-one case, the resulting ``DataFrame`` will preserve those duplicate entries as appropriate.\n",
    "Consider the following example of a many-to-one join:"
   ]
  },
  {
   "metadata": {
    "id": "NBRcYw3PupM-",
    "outputId": "abe3a452-ef2a-492a-ab10-e33fea92092d"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>df3</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee</th>\n",
       "      <th>group</th>\n",
       "      <th>hire_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Accounting</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jake</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lisa</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sue</td>\n",
       "      <td>HR</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>\n",
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>df4</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>supervisor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accounting</td>\n",
       "      <td>Carly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Engineering</td>\n",
       "      <td>Guido</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HR</td>\n",
       "      <td>Steve</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>\n",
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>pd.merge(df3, df4)</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee</th>\n",
       "      <th>group</th>\n",
       "      <th>hire_date</th>\n",
       "      <th>supervisor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Accounting</td>\n",
       "      <td>2008</td>\n",
       "      <td>Carly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jake</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>2012</td>\n",
       "      <td>Guido</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lisa</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>2004</td>\n",
       "      <td>Guido</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sue</td>\n",
       "      <td>HR</td>\n",
       "      <td>2014</td>\n",
       "      <td>Steve</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>"
      ],
      "text/plain": [
       "df3\n",
       "  employee        group  hire_date\n",
       "0      Bob   Accounting       2008\n",
       "1     Jake  Engineering       2012\n",
       "2     Lisa  Engineering       2004\n",
       "3      Sue           HR       2014\n",
       "\n",
       "df4\n",
       "         group supervisor\n",
       "0   Accounting      Carly\n",
       "1  Engineering      Guido\n",
       "2           HR      Steve\n",
       "\n",
       "pd.merge(df3, df4)\n",
       "  employee        group  hire_date supervisor\n",
       "0      Bob   Accounting       2008      Carly\n",
       "1     Jake  Engineering       2012      Guido\n",
       "2     Lisa  Engineering       2004      Guido\n",
       "3      Sue           HR       2014      Steve"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "df4 = pd.DataFrame({'group': ['Accounting', 'Engineering', 'HR'],\n",
    "                    'supervisor': ['Carly', 'Guido', 'Steve']})\n",
    "display('df3', 'df4', 'pd.merge(df3, df4)')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The resulting ``DataFrame`` has an aditional column with the \"supervisor\" information, where the information is repeated in one or more locations as required by the inputs."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Many-to-many joins"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Many-to-many joins are a bit confusing conceptually, but are nevertheless well defined.\n",
    "If the key column in both the left and right array contains duplicates, then the result is a many-to-many merge.\n",
    "This will be perhaps most clear with a concrete example.\n",
    "Consider the following, where we have a ``DataFrame`` showing one or more skills associated with a particular group.\n",
    "By performing a many-to-many join, we can recover the skills associated with any individual person:"
   ]
  },
  {
   "metadata": {
    "id": "neGezvBYupNC",
    "outputId": "c9fb4ccc-57c9-4ac3-f35d-be776f49fc11"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>df1</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Accounting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jake</td>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lisa</td>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sue</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>\n",
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>df5</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accounting</td>\n",
       "      <td>math</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accounting</td>\n",
       "      <td>spreadsheets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Engineering</td>\n",
       "      <td>coding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Engineering</td>\n",
       "      <td>linux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HR</td>\n",
       "      <td>spreadsheets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HR</td>\n",
       "      <td>organization</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>\n",
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>pd.merge(df1, df5)</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee</th>\n",
       "      <th>group</th>\n",
       "      <th>skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Accounting</td>\n",
       "      <td>math</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Accounting</td>\n",
       "      <td>spreadsheets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jake</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>coding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jake</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>linux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lisa</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>coding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lisa</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>linux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sue</td>\n",
       "      <td>HR</td>\n",
       "      <td>spreadsheets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sue</td>\n",
       "      <td>HR</td>\n",
       "      <td>organization</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>"
      ],
      "text/plain": [
       "df1\n",
       "  employee        group\n",
       "0      Bob   Accounting\n",
       "1     Jake  Engineering\n",
       "2     Lisa  Engineering\n",
       "3      Sue           HR\n",
       "\n",
       "df5\n",
       "         group        skills\n",
       "0   Accounting          math\n",
       "1   Accounting  spreadsheets\n",
       "2  Engineering        coding\n",
       "3  Engineering         linux\n",
       "4           HR  spreadsheets\n",
       "5           HR  organization\n",
       "\n",
       "pd.merge(df1, df5)\n",
       "  employee        group        skills\n",
       "0      Bob   Accounting          math\n",
       "1      Bob   Accounting  spreadsheets\n",
       "2     Jake  Engineering        coding\n",
       "3     Jake  Engineering         linux\n",
       "4     Lisa  Engineering        coding\n",
       "5     Lisa  Engineering         linux\n",
       "6      Sue           HR  spreadsheets\n",
       "7      Sue           HR  organization"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "df5 = pd.DataFrame({'group': ['Accounting', 'Accounting',\n",
    "                              'Engineering', 'Engineering', 'HR', 'HR'],\n",
    "                    'skills': ['math', 'spreadsheets', 'coding', 'linux',\n",
    "                               'spreadsheets', 'organization']})\n",
    "display('df1', 'df5', \"pd.merge(df1, df5)\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "These three types of joins can be used with other Pandas tools to implement a wide array of functionality.\n",
    "But in practice, datasets are rarely as clean as the one we're working with here.\n",
    "In the following section we'll consider some of the options provided by ``pd.merge()`` that enable you to tune how the join operations work."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Specification of the Merge Key"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We've already seen the default behavior of ``pd.merge()``: it looks for one or more matching column names between the two inputs, and uses this as the key.\n",
    "However, often the column names will not match so nicely, and ``pd.merge()`` provides a variety of options for handling this."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### The ``on`` keyword\n",
    "\n",
    "Most simply, you can explicitly specify the name of the key column using the ``on`` keyword, which takes a column name or a list of column names:"
   ]
  },
  {
   "metadata": {
    "id": "Imrs9oLgupNE",
    "outputId": "4e300803-f882-46aa-a75f-54a0f125b579"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>df1</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Accounting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jake</td>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lisa</td>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sue</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>\n",
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>df2</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee</th>\n",
       "      <th>hire_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lisa</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jake</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sue</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>\n",
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>pd.merge(df1, df2, on='employee')</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee</th>\n",
       "      <th>group</th>\n",
       "      <th>hire_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Accounting</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jake</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lisa</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sue</td>\n",
       "      <td>HR</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>"
      ],
      "text/plain": [
       "df1\n",
       "  employee        group\n",
       "0      Bob   Accounting\n",
       "1     Jake  Engineering\n",
       "2     Lisa  Engineering\n",
       "3      Sue           HR\n",
       "\n",
       "df2\n",
       "  employee  hire_date\n",
       "0     Lisa       2004\n",
       "1      Bob       2008\n",
       "2     Jake       2012\n",
       "3      Sue       2014\n",
       "\n",
       "pd.merge(df1, df2, on='employee')\n",
       "  employee        group  hire_date\n",
       "0      Bob   Accounting       2008\n",
       "1     Jake  Engineering       2012\n",
       "2     Lisa  Engineering       2004\n",
       "3      Sue           HR       2014"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "display('df1', 'df2', \"pd.merge(df1, df2, on='employee')\")"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This option works only if both the left and right ``DataFrame``s have the specified column name."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### The ``left_on`` and ``right_on`` keywords\n",
    "\n",
    "At times you may wish to merge two datasets with different column names; for example, we may have a dataset in which the employee name is labeled as \"name\" rather than \"employee\".\n",
    "In this case, we can use the ``left_on`` and ``right_on`` keywords to specify the two column names:"
   ]
  },
  {
   "metadata": {
    "id": "GEK8G2PlupNF",
    "outputId": "59c0bda1-4af0-4fa8-ed21-8548bc02a667"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>df1</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Accounting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jake</td>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lisa</td>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sue</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>\n",
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>df3</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bob</td>\n",
       "      <td>70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jake</td>\n",
       "      <td>80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lisa</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sue</td>\n",
       "      <td>90000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>\n",
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>pd.merge(df1, df3, left_on=\"employee\", right_on=\"name\")</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee</th>\n",
       "      <th>group</th>\n",
       "      <th>name</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Accounting</td>\n",
       "      <td>Bob</td>\n",
       "      <td>70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jake</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>Jake</td>\n",
       "      <td>80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lisa</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>Lisa</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sue</td>\n",
       "      <td>HR</td>\n",
       "      <td>Sue</td>\n",
       "      <td>90000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>"
      ],
      "text/plain": [
       "df1\n",
       "  employee        group\n",
       "0      Bob   Accounting\n",
       "1     Jake  Engineering\n",
       "2     Lisa  Engineering\n",
       "3      Sue           HR\n",
       "\n",
       "df3\n",
       "   name  salary\n",
       "0   Bob   70000\n",
       "1  Jake   80000\n",
       "2  Lisa  120000\n",
       "3   Sue   90000\n",
       "\n",
       "pd.merge(df1, df3, left_on=\"employee\", right_on=\"name\")\n",
       "  employee        group  name  salary\n",
       "0      Bob   Accounting   Bob   70000\n",
       "1     Jake  Engineering  Jake   80000\n",
       "2     Lisa  Engineering  Lisa  120000\n",
       "3      Sue           HR   Sue   90000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "df3 = pd.DataFrame({'name': ['Bob', 'Jake', 'Lisa', 'Sue'],\n",
    "                    'salary': [70000, 80000, 120000, 90000]})\n",
    "display('df1', 'df3', 'pd.merge(df1, df3, left_on=\"employee\", right_on=\"name\")')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The result has a redundant column that we can drop if desired–for example, by using the ``drop()`` method of ``DataFrame``s:"
  },
  {
   "metadata": {
    "id": "yDSRy-nDupNG",
    "outputId": "daed2b52-5be2-4d1a-ff5f-6d04817d9ae5"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee</th>\n",
       "      <th>group</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Accounting</td>\n",
       "      <td>70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jake</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lisa</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sue</td>\n",
       "      <td>HR</td>\n",
       "      <td>90000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  employee        group  salary\n",
       "0      Bob   Accounting   70000\n",
       "1     Jake  Engineering   80000\n",
       "2     Lisa  Engineering  120000\n",
       "3      Sue           HR   90000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "pd.merge(df1, df3, left_on=\"employee\", right_on=\"name\").drop('name', axis=1)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### The ``left_index`` and ``right_index`` keywords\n",
    "\n",
    "Sometimes, rather than merging on a column, you would instead like to merge on an index.\n",
    "For example, your data might look like this:"
   ]
  },
  {
   "metadata": {
    "id": "QQBBScl3upNH",
    "outputId": "1ab333f6-1c51-4209-ebb3-87881be96ae1"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>df1a</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employee</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bob</th>\n",
       "      <td>Accounting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jake</th>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lisa</th>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sue</th>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>\n",
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>df2a</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hire_date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employee</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lisa</th>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bob</th>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jake</th>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sue</th>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>"
      ],
      "text/plain": [
       "df1a\n",
       "                group\n",
       "employee             \n",
       "Bob        Accounting\n",
       "Jake      Engineering\n",
       "Lisa      Engineering\n",
       "Sue                HR\n",
       "\n",
       "df2a\n",
       "          hire_date\n",
       "employee           \n",
       "Lisa           2004\n",
       "Bob            2008\n",
       "Jake           2012\n",
       "Sue            2014"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "df1a = df1.set_index('employee')\n",
    "df2a = df2.set_index('employee')\n",
    "display('df1a', 'df2a')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "You can use the index as the key for merging by specifying the ``left_index`` and/or ``right_index`` flags in ``pd.merge()``:"
  },
  {
   "metadata": {
    "id": "0kfKQ7O-upNI",
    "outputId": "f47a17ac-52c9-4a85-814c-67f83ad6a266"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>df1a</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employee</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bob</th>\n",
       "      <td>Accounting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jake</th>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lisa</th>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sue</th>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>\n",
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>df2a</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hire_date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employee</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lisa</th>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bob</th>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jake</th>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sue</th>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>\n",
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>pd.merge(df1a, df2a, left_index=True, right_index=True)</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>hire_date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employee</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lisa</th>\n",
       "      <td>Engineering</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bob</th>\n",
       "      <td>Accounting</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jake</th>\n",
       "      <td>Engineering</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sue</th>\n",
       "      <td>HR</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>"
      ],
      "text/plain": [
       "df1a\n",
       "                group\n",
       "employee             \n",
       "Bob        Accounting\n",
       "Jake      Engineering\n",
       "Lisa      Engineering\n",
       "Sue                HR\n",
       "\n",
       "df2a\n",
       "          hire_date\n",
       "employee           \n",
       "Lisa           2004\n",
       "Bob            2008\n",
       "Jake           2012\n",
       "Sue            2014\n",
       "\n",
       "pd.merge(df1a, df2a, left_index=True, right_index=True)\n",
       "                group  hire_date\n",
       "employee                        \n",
       "Lisa      Engineering       2004\n",
       "Bob        Accounting       2008\n",
       "Jake      Engineering       2012\n",
       "Sue                HR       2014"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "display('df1a', 'df2a',\n",
    "        \"pd.merge(df1a, df2a, left_index=True, right_index=True)\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "For convenience, ``DataFrame``s implement the ``join()`` method, which performs a merge that defaults to joining on indices:"
  },
  {
   "metadata": {
    "id": "gtU4gzWjupNK",
    "outputId": "c9279ea4-02bb-4905-a5c1-d858c9907cbe"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>df1a</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employee</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bob</th>\n",
       "      <td>Accounting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jake</th>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lisa</th>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sue</th>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>\n",
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>df2a</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hire_date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employee</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lisa</th>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bob</th>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jake</th>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sue</th>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>\n",
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>df1a.join(df2a)</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>hire_date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employee</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bob</th>\n",
       "      <td>Accounting</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jake</th>\n",
       "      <td>Engineering</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lisa</th>\n",
       "      <td>Engineering</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sue</th>\n",
       "      <td>HR</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>"
      ],
      "text/plain": [
       "df1a\n",
       "                group\n",
       "employee             \n",
       "Bob        Accounting\n",
       "Jake      Engineering\n",
       "Lisa      Engineering\n",
       "Sue                HR\n",
       "\n",
       "df2a\n",
       "          hire_date\n",
       "employee           \n",
       "Lisa           2004\n",
       "Bob            2008\n",
       "Jake           2012\n",
       "Sue            2014\n",
       "\n",
       "df1a.join(df2a)\n",
       "                group  hire_date\n",
       "employee                        \n",
       "Bob        Accounting       2008\n",
       "Jake      Engineering       2012\n",
       "Lisa      Engineering       2004\n",
       "Sue                HR       2014"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "display('df1a', 'df2a', 'df1a.join(df2a)')"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "If you'd like to mix indices and columns, you can combine ``left_index`` with ``right_on`` or ``left_on`` with ``right_index`` to get the desired behavior:"
  },
  {
   "metadata": {
    "id": "fZzY_mz3upNL",
    "outputId": "3db5c25d-0c08-45fb-e529-fb42e34ee1d1"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>df1a</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employee</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bob</th>\n",
       "      <td>Accounting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jake</th>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lisa</th>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sue</th>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>\n",
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>df3</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bob</td>\n",
       "      <td>70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jake</td>\n",
       "      <td>80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lisa</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sue</td>\n",
       "      <td>90000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>\n",
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>pd.merge(df1a, df3, left_index=True, right_on='name')</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>name</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accounting</td>\n",
       "      <td>Bob</td>\n",
       "      <td>70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Engineering</td>\n",
       "      <td>Jake</td>\n",
       "      <td>80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Engineering</td>\n",
       "      <td>Lisa</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HR</td>\n",
       "      <td>Sue</td>\n",
       "      <td>90000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>"
      ],
      "text/plain": [
       "df1a\n",
       "                group\n",
       "employee             \n",
       "Bob        Accounting\n",
       "Jake      Engineering\n",
       "Lisa      Engineering\n",
       "Sue                HR\n",
       "\n",
       "df3\n",
       "   name  salary\n",
       "0   Bob   70000\n",
       "1  Jake   80000\n",
       "2  Lisa  120000\n",
       "3   Sue   90000\n",
       "\n",
       "pd.merge(df1a, df3, left_index=True, right_on='name')\n",
       "         group  name  salary\n",
       "0   Accounting   Bob   70000\n",
       "1  Engineering  Jake   80000\n",
       "2  Engineering  Lisa  120000\n",
       "3           HR   Sue   90000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "display('df1a', 'df3', \"pd.merge(df1a, df3, left_index=True, right_on='name')\")"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "All of these options also work with multiple indices and/or multiple columns; the interface for this behavior is very intuitive.\n",
    "For more information on this, see the [\"Merge, Join, and Concatenate\" section](http://pandas.pydata.org/pandas-docs/stable/merging.html) of the Pandas documentation."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Specifying Set Arithmetic for Joins"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In all the preceding examples we have glossed over one important consideration in performing a join: the type of set arithmetic used in the join.\n",
    "This comes up when a value appears in one key column but not the other. Consider this example:"
   ]
  },
  {
   "metadata": {
    "id": "Vb5sfvJNupNS",
    "outputId": "c169cdb3-75d1-4c5a-bdfc-21300d96eec5"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>df6</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>food</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Peter</td>\n",
       "      <td>fish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paul</td>\n",
       "      <td>beans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mary</td>\n",
       "      <td>bread</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>\n",
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>df7</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>drink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mary</td>\n",
       "      <td>wine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joseph</td>\n",
       "      <td>beer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>\n",
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>pd.merge(df6, df7)</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>food</th>\n",
       "      <th>drink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mary</td>\n",
       "      <td>bread</td>\n",
       "      <td>wine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>"
      ],
      "text/plain": [
       "df6\n",
       "    name   food\n",
       "0  Peter   fish\n",
       "1   Paul  beans\n",
       "2   Mary  bread\n",
       "\n",
       "df7\n",
       "     name drink\n",
       "0    Mary  wine\n",
       "1  Joseph  beer\n",
       "\n",
       "pd.merge(df6, df7)\n",
       "   name   food drink\n",
       "0  Mary  bread  wine"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "df6 = pd.DataFrame({'name': ['Peter', 'Paul', 'Mary'],\n",
    "                    'food': ['fish', 'beans', 'bread']},\n",
    "                   columns=['name', 'food'])\n",
    "df7 = pd.DataFrame({'name': ['Mary', 'Joseph'],\n",
    "                    'drink': ['wine', 'beer']},\n",
    "                   columns=['name', 'drink'])\n",
    "display('df6', 'df7', 'pd.merge(df6, df7)')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Here we have merged two datasets that have only a single \"name\" entry in common: Mary.\n",
    "By default, the result contains the *intersection* of the two sets of inputs; this is what is known as an *inner join*.\n",
    "We can specify this explicitly using the ``how`` keyword, which defaults to ``\"inner\"``:"
   ]
  },
  {
   "metadata": {
    "id": "ILgnN-CzupNT",
    "outputId": "d4973fa8-a54e-4409-fd4d-936b398ac730"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>food</th>\n",
       "      <th>drink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mary</td>\n",
       "      <td>bread</td>\n",
       "      <td>wine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name   food drink\n",
       "0  Mary  bread  wine"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "pd.merge(df6, df7, how='inner')"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Other options for the ``how`` keyword are ``'outer'``, ``'left'``, and ``'right'``.\n",
    "An *outer join* returns a join over the union of the input columns, and fills in all missing values with NAs:"
   ]
  },
  {
   "metadata": {
    "id": "Vav_jsWbupNT",
    "outputId": "d35d00ee-f8a1-4171-b6c3-93d15a4cf652"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>df6</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>food</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Peter</td>\n",
       "      <td>fish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paul</td>\n",
       "      <td>beans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mary</td>\n",
       "      <td>bread</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>\n",
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>df7</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>drink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mary</td>\n",
       "      <td>wine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joseph</td>\n",
       "      <td>beer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>\n",
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>pd.merge(df6, df7, how='outer')</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>food</th>\n",
       "      <th>drink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Peter</td>\n",
       "      <td>fish</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paul</td>\n",
       "      <td>beans</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mary</td>\n",
       "      <td>bread</td>\n",
       "      <td>wine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Joseph</td>\n",
       "      <td>NaN</td>\n",
       "      <td>beer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>"
      ],
      "text/plain": [
       "df6\n",
       "    name   food\n",
       "0  Peter   fish\n",
       "1   Paul  beans\n",
       "2   Mary  bread\n",
       "\n",
       "df7\n",
       "     name drink\n",
       "0    Mary  wine\n",
       "1  Joseph  beer\n",
       "\n",
       "pd.merge(df6, df7, how='outer')\n",
       "     name   food drink\n",
       "0   Peter   fish   NaN\n",
       "1    Paul  beans   NaN\n",
       "2    Mary  bread  wine\n",
       "3  Joseph    NaN  beer"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "display('df6', 'df7', \"pd.merge(df6, df7, how='outer')\")"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The *left join* and *right join* return joins over the left entries and right entries, respectively.\n",
    "For example:"
   ]
  },
  {
   "metadata": {
    "id": "R4QiZlH5upNT",
    "outputId": "1786e1f1-d9c4-49d4-9127-01c0cf74896f"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>df6</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>food</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Peter</td>\n",
       "      <td>fish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paul</td>\n",
       "      <td>beans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mary</td>\n",
       "      <td>bread</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>\n",
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>df7</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>drink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mary</td>\n",
       "      <td>wine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joseph</td>\n",
       "      <td>beer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>\n",
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>pd.merge(df6, df7, how='left')</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>food</th>\n",
       "      <th>drink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Peter</td>\n",
       "      <td>fish</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paul</td>\n",
       "      <td>beans</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mary</td>\n",
       "      <td>bread</td>\n",
       "      <td>wine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>"
      ],
      "text/plain": [
       "df6\n",
       "    name   food\n",
       "0  Peter   fish\n",
       "1   Paul  beans\n",
       "2   Mary  bread\n",
       "\n",
       "df7\n",
       "     name drink\n",
       "0    Mary  wine\n",
       "1  Joseph  beer\n",
       "\n",
       "pd.merge(df6, df7, how='left')\n",
       "    name   food drink\n",
       "0  Peter   fish   NaN\n",
       "1   Paul  beans   NaN\n",
       "2   Mary  bread  wine"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "display('df6', 'df7', \"pd.merge(df6, df7, how='left')\")"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The output rows now correspond to the entries in the left input. Using\n",
    "``how='right'`` works in a similar manner.\n",
    "\n",
    "All of these options can be applied straightforwardly to any of the preceding join types."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Overlapping Column Names: The ``suffixes`` Keyword"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Finally, you may end up in a case where your two input ``DataFrame``s have conflicting column names.\n",
    "Consider this example:"
   ]
  },
  {
   "metadata": {
    "id": "LFKOxnuPupNU",
    "outputId": "ee0474d1-6bbf-49a7-e43f-3955acc5f2a6"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>df8</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bob</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jake</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lisa</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sue</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>\n",
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>df9</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bob</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jake</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lisa</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sue</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>\n",
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>pd.merge(df8, df9, on=\"name\")</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>rank_x</th>\n",
       "      <th>rank_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bob</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jake</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lisa</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sue</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>"
      ],
      "text/plain": [
       "df8\n",
       "   name  rank\n",
       "0   Bob     1\n",
       "1  Jake     2\n",
       "2  Lisa     3\n",
       "3   Sue     4\n",
       "\n",
       "df9\n",
       "   name  rank\n",
       "0   Bob     3\n",
       "1  Jake     1\n",
       "2  Lisa     4\n",
       "3   Sue     2\n",
       "\n",
       "pd.merge(df8, df9, on=\"name\")\n",
       "   name  rank_x  rank_y\n",
       "0   Bob       1       3\n",
       "1  Jake       2       1\n",
       "2  Lisa       3       4\n",
       "3   Sue       4       2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "df8 = pd.DataFrame({'name': ['Bob', 'Jake', 'Lisa', 'Sue'],\n",
    "                    'rank': [1, 2, 3, 4]})\n",
    "df9 = pd.DataFrame({'name': ['Bob', 'Jake', 'Lisa', 'Sue'],\n",
    "                    'rank': [3, 1, 4, 2]})\n",
    "display('df8', 'df9', 'pd.merge(df8, df9, on=\"name\")')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Because the output would have two conflicting column names, the merge function automatically appends a suffix ``_x`` or ``_y`` to make the output columns unique.\n",
    "If these defaults are inappropriate, it is possible to specify a custom suffix using the ``suffixes`` keyword:"
   ]
  },
  {
   "metadata": {
    "id": "pYnBl1g9upNU",
    "outputId": "1df9e2ee-0aa2-417b-be27-5a498f25d2e5"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>df8</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bob</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jake</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lisa</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sue</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>\n",
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>df9</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bob</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jake</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lisa</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sue</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>\n",
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>pd.merge(df8, df9, on=\"name\", suffixes=[\"_L\", \"_R\"])</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>rank_L</th>\n",
       "      <th>rank_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bob</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jake</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lisa</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sue</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>"
      ],
      "text/plain": [
       "df8\n",
       "   name  rank\n",
       "0   Bob     1\n",
       "1  Jake     2\n",
       "2  Lisa     3\n",
       "3   Sue     4\n",
       "\n",
       "df9\n",
       "   name  rank\n",
       "0   Bob     3\n",
       "1  Jake     1\n",
       "2  Lisa     4\n",
       "3   Sue     2\n",
       "\n",
       "pd.merge(df8, df9, on=\"name\", suffixes=[\"_L\", \"_R\"])\n",
       "   name  rank_L  rank_R\n",
       "0   Bob       1       3\n",
       "1  Jake       2       1\n",
       "2  Lisa       3       4\n",
       "3   Sue       4       2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "display('df8', 'df9', 'pd.merge(df8, df9, on=\"name\", suffixes=[\"_L\", \"_R\"])')"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "These suffixes work in any of the possible join patterns, and work also if there are multiple overlapping columns."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "For more information on these patterns, see [Aggregation and Grouping](03.08-Aggregation-and-Grouping.ipynb) where we dive a bit deeper into relational algebra.\n",
    "Also see the [Pandas \"Merge, Join and Concatenate\" documentation](http://pandas.pydata.org/pandas-docs/stable/merging.html) for further discussion of these topics."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Example: US States Data\n",
    "\n",
    "Merge and join operations come up most often when combining data from different sources.\n",
    "Here we will consider an example of some data about US states and their populations.\n",
    "The data files can be found at http://github.com/jakevdp/data-USstates/:"
   ]
  },
  {
   "metadata": {
    "id": "eYj2ja_UupNW"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Following are shell commands to download the data\n",
    "# !curl -O https://raw.githubusercontent.com/jakevdp/data-USstates/master/state-population.csv\n",
    "# !curl -O https://raw.githubusercontent.com/jakevdp/data-USstates/master/state-areas.csv\n",
    "# !curl -O https://raw.githubusercontent.com/jakevdp/data-USstates/master/state-abbrevs.csv"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's take a look at the three datasets, using the Pandas ``read_csv()`` function:"
  },
  {
   "metadata": {
    "id": "8Cgt4llOupNX",
    "outputId": "cfa4c5d3-277e-4fc5-cfd0-ef21693bd991"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>pop.head()</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state/region</th>\n",
       "      <th>ages</th>\n",
       "      <th>year</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>under18</td>\n",
       "      <td>2012</td>\n",
       "      <td>1117489.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL</td>\n",
       "      <td>total</td>\n",
       "      <td>2012</td>\n",
       "      <td>4817528.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL</td>\n",
       "      <td>under18</td>\n",
       "      <td>2010</td>\n",
       "      <td>1130966.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AL</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>4785570.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AL</td>\n",
       "      <td>under18</td>\n",
       "      <td>2011</td>\n",
       "      <td>1125763.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>\n",
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>areas.head()</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>area (sq. mi)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>52423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>656425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>114006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>53182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>163707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>\n",
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>abbrevs.head()</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>abbreviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>"
      ],
      "text/plain": [
       "pop.head()\n",
       "  state/region     ages  year  population\n",
       "0           AL  under18  2012   1117489.0\n",
       "1           AL    total  2012   4817528.0\n",
       "2           AL  under18  2010   1130966.0\n",
       "3           AL    total  2010   4785570.0\n",
       "4           AL  under18  2011   1125763.0\n",
       "\n",
       "areas.head()\n",
       "        state  area (sq. mi)\n",
       "0     Alabama          52423\n",
       "1      Alaska         656425\n",
       "2     Arizona         114006\n",
       "3    Arkansas          53182\n",
       "4  California         163707\n",
       "\n",
       "abbrevs.head()\n",
       "        state abbreviation\n",
       "0     Alabama           AL\n",
       "1      Alaska           AK\n",
       "2     Arizona           AZ\n",
       "3    Arkansas           AR\n",
       "4  California           CA"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "pop = pd.read_csv('data/state-population.csv')\n",
    "areas = pd.read_csv('data/state-areas.csv')\n",
    "abbrevs = pd.read_csv('data/state-abbrevs.csv')\n",
    "\n",
    "display('pop.head()', 'areas.head()', 'abbrevs.head()')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Given this information, say we want to compute a relatively straightforward result: rank US states and territories by their 2010 population density.\n",
    "We clearly have the data here to find this result, but we'll have to combine the datasets to find the result.\n",
    "\n",
    "We'll start with a many-to-one merge that will give us the full state name within the population ``DataFrame``.\n",
    "We want to merge based on the ``state/region``  column of ``pop``, and the ``abbreviation`` column of ``abbrevs``.\n",
    "We'll use ``how='outer'`` to make sure no data is thrown away due to mismatched labels."
   ]
  },
  {
   "metadata": {
    "id": "f4CBCLJ8upNY",
    "outputId": "1ef6f18d-1255-42e6-d913-0ca690945218"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state/region</th>\n",
       "      <th>ages</th>\n",
       "      <th>year</th>\n",
       "      <th>population</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>under18</td>\n",
       "      <td>2012</td>\n",
       "      <td>1117489.0</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL</td>\n",
       "      <td>total</td>\n",
       "      <td>2012</td>\n",
       "      <td>4817528.0</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL</td>\n",
       "      <td>under18</td>\n",
       "      <td>2010</td>\n",
       "      <td>1130966.0</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AL</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>4785570.0</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AL</td>\n",
       "      <td>under18</td>\n",
       "      <td>2011</td>\n",
       "      <td>1125763.0</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state/region     ages  year  population    state\n",
       "0           AL  under18  2012   1117489.0  Alabama\n",
       "1           AL    total  2012   4817528.0  Alabama\n",
       "2           AL  under18  2010   1130966.0  Alabama\n",
       "3           AL    total  2010   4785570.0  Alabama\n",
       "4           AL  under18  2011   1125763.0  Alabama"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "merged = pd.merge(pop, abbrevs, how='outer',\n",
    "                  left_on='state/region', right_on='abbreviation')\n",
    "merged = merged.drop('abbreviation', 1) # drop duplicate info\n",
    "merged.head()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's double-check whether there were any mismatches here, which we can do by looking for rows with nulls:"
  },
  {
   "metadata": {
    "id": "bwG_XFRzupNZ",
    "outputId": "d545e764-818c-4fb3-e880-91198d7bd6b2"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state/region    False\n",
       "ages            False\n",
       "year            False\n",
       "population       True\n",
       "state            True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "merged.isnull().any()"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Some of the ``population`` info is null; let's figure out which these are!"
  },
  {
   "metadata": {
    "id": "ey1mVrgtupNa",
    "outputId": "1bcef3ca-420b-49f5-d7b3-f75bd85798cf"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state/region</th>\n",
       "      <th>ages</th>\n",
       "      <th>year</th>\n",
       "      <th>population</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2448</th>\n",
       "      <td>PR</td>\n",
       "      <td>under18</td>\n",
       "      <td>1990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2449</th>\n",
       "      <td>PR</td>\n",
       "      <td>total</td>\n",
       "      <td>1990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2450</th>\n",
       "      <td>PR</td>\n",
       "      <td>total</td>\n",
       "      <td>1991</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2451</th>\n",
       "      <td>PR</td>\n",
       "      <td>under18</td>\n",
       "      <td>1991</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2452</th>\n",
       "      <td>PR</td>\n",
       "      <td>total</td>\n",
       "      <td>1993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     state/region     ages  year  population state\n",
       "2448           PR  under18  1990         NaN   NaN\n",
       "2449           PR    total  1990         NaN   NaN\n",
       "2450           PR    total  1991         NaN   NaN\n",
       "2451           PR  under18  1991         NaN   NaN\n",
       "2452           PR    total  1993         NaN   NaN"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "merged[merged['population'].isnull()].head()"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "It appears that all the null population values are from Puerto Rico prior to the year 2000; this is likely due to this data not being available from the original source.\n",
    "\n",
    "More importantly, we see also that some of the new ``state`` entries are also null, which means that there was no corresponding entry in the ``abbrevs`` key!\n",
    "Let's figure out which regions lack this match:"
   ]
  },
  {
   "metadata": {
    "id": "2_NRxRFPupNb",
    "outputId": "496e5227-a9af-4288-ad34-ad360d632161"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['PR', 'USA'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "merged.loc[merged['state'].isnull(), 'state/region'].unique()"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We can quickly infer the issue: our population data includes entries for Puerto Rico (PR) and the United States as a whole (USA), while these entries do not appear in the state abbreviation key.\n",
    "We can fix these quickly by filling in appropriate entries:"
   ]
  },
  {
   "metadata": {
    "id": "MVy8gFxxupNc",
    "outputId": "046c1989-d2b7-47d7-8d96-55dc3ac43d1c"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state/region    False\n",
       "ages            False\n",
       "year            False\n",
       "population       True\n",
       "state           False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "merged.loc[merged['state/region'] == 'PR', 'state'] = 'Puerto Rico'\n",
    "merged.loc[merged['state/region'] == 'USA', 'state'] = 'United States'\n",
    "merged.isnull().any()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "No more nulls in the ``state`` column: we're all set!\n",
    "\n",
    "Now we can merge the result with the area data using a similar procedure.\n",
    "Examining our results, we will want to join on the ``state`` column in both:"
   ]
  },
  {
   "metadata": {
    "id": "PwRXu8qyupNd",
    "outputId": "e1bbc337-19ff-4109-ac26-8a50726e61af"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state/region</th>\n",
       "      <th>ages</th>\n",
       "      <th>year</th>\n",
       "      <th>population</th>\n",
       "      <th>state</th>\n",
       "      <th>area (sq. mi)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>under18</td>\n",
       "      <td>2012</td>\n",
       "      <td>1117489.0</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>52423.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL</td>\n",
       "      <td>total</td>\n",
       "      <td>2012</td>\n",
       "      <td>4817528.0</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>52423.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL</td>\n",
       "      <td>under18</td>\n",
       "      <td>2010</td>\n",
       "      <td>1130966.0</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>52423.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AL</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>4785570.0</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>52423.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AL</td>\n",
       "      <td>under18</td>\n",
       "      <td>2011</td>\n",
       "      <td>1125763.0</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>52423.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state/region     ages  year  population    state  area (sq. mi)\n",
       "0           AL  under18  2012   1117489.0  Alabama        52423.0\n",
       "1           AL    total  2012   4817528.0  Alabama        52423.0\n",
       "2           AL  under18  2010   1130966.0  Alabama        52423.0\n",
       "3           AL    total  2010   4785570.0  Alabama        52423.0\n",
       "4           AL  under18  2011   1125763.0  Alabama        52423.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "final = pd.merge(merged, areas, on='state', how='left')\n",
    "final.head()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Again, let's check for nulls to see if there were any mismatches:"
  },
  {
   "metadata": {
    "id": "UHaHwwG-upNe",
    "outputId": "434f7585-8b37-49d5-8fbf-5c54d690d4ec"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state/region     False\n",
       "ages             False\n",
       "year             False\n",
       "population        True\n",
       "state            False\n",
       "area (sq. mi)     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "final.isnull().any()"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "There are nulls in the ``area`` column; we can take a look to see which regions were ignored here:"
  },
  {
   "metadata": {
    "id": "PID6_wcJupNf",
    "outputId": "9f51a5f0-8163-41e5-f0b0-0347ee1df95b"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['United States'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "final['state'][final['area (sq. mi)'].isnull()].unique()"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We see that our ``areas`` ``DataFrame`` does not contain the area of the United States as a whole.\n",
    "We could insert the appropriate value (using the sum of all state areas, for instance), but in this case we'll just drop the null values because the population density of the entire United States is not relevant to our current discussion:"
   ]
  },
  {
   "metadata": {
    "id": "DNYt33-kupNf",
    "outputId": "e76f40c7-693d-4af3-abea-9d5c2208a587"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state/region</th>\n",
       "      <th>ages</th>\n",
       "      <th>year</th>\n",
       "      <th>population</th>\n",
       "      <th>state</th>\n",
       "      <th>area (sq. mi)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>under18</td>\n",
       "      <td>2012</td>\n",
       "      <td>1117489.0</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>52423.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL</td>\n",
       "      <td>total</td>\n",
       "      <td>2012</td>\n",
       "      <td>4817528.0</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>52423.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL</td>\n",
       "      <td>under18</td>\n",
       "      <td>2010</td>\n",
       "      <td>1130966.0</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>52423.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AL</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>4785570.0</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>52423.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AL</td>\n",
       "      <td>under18</td>\n",
       "      <td>2011</td>\n",
       "      <td>1125763.0</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>52423.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state/region     ages  year  population    state  area (sq. mi)\n",
       "0           AL  under18  2012   1117489.0  Alabama        52423.0\n",
       "1           AL    total  2012   4817528.0  Alabama        52423.0\n",
       "2           AL  under18  2010   1130966.0  Alabama        52423.0\n",
       "3           AL    total  2010   4785570.0  Alabama        52423.0\n",
       "4           AL  under18  2011   1125763.0  Alabama        52423.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "final.dropna(inplace=True)\n",
    "final.head()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now we have all the data we need. To answer the question of interest, let's first select the portion of the data corresponding with the year 2000, and the total population.\n",
    "We'll use the ``query()`` function to do this quickly (this requires the ``numexpr`` package to be installed; see [High-Performance Pandas: ``eval()`` and ``query()``](03.12-Performance-Eval-and-Query.ipynb)):"
   ]
  },
  {
   "metadata": {
    "id": "n45Sb-ufupNh",
    "outputId": "10cedd87-f99b-453c-f32c-fe926f29519e"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state/region</th>\n",
       "      <th>ages</th>\n",
       "      <th>year</th>\n",
       "      <th>population</th>\n",
       "      <th>state</th>\n",
       "      <th>area (sq. mi)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AL</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>4785570.0</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>52423.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>AK</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>713868.0</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>656425.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>AZ</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>6408790.0</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>114006.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>AR</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>2922280.0</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>53182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>CA</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>37333601.0</td>\n",
       "      <td>California</td>\n",
       "      <td>163707.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    state/region   ages  year  population       state  area (sq. mi)\n",
       "3             AL  total  2010   4785570.0     Alabama        52423.0\n",
       "91            AK  total  2010    713868.0      Alaska       656425.0\n",
       "101           AZ  total  2010   6408790.0     Arizona       114006.0\n",
       "189           AR  total  2010   2922280.0    Arkansas        53182.0\n",
       "197           CA  total  2010  37333601.0  California       163707.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "data2010 = final.query(\"year == 2010 & ages == 'total'\")\n",
    "data2010.head()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now let's compute the population density and display it in order.\n",
    "We'll start by re-indexing our data on the state, and then compute the result:"
   ]
  },
  {
   "metadata": {
    "id": "K6doWNkVupNh"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "data2010.set_index('state', inplace=True)\n",
    "density = data2010['population'] / data2010['area (sq. mi)']"
   ]
  },
  {
   "metadata": {
    "id": "993z_aHRupNi",
    "outputId": "9f03e01e-1f30-4f88-9b94-cd8c2b7918e3"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state\n",
       "District of Columbia    8898.897059\n",
       "Puerto Rico             1058.665149\n",
       "New Jersey              1009.253268\n",
       "Rhode Island             681.339159\n",
       "Connecticut              645.600649\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "density.sort_values(ascending=False, inplace=True)\n",
    "density.head()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The result is a ranking of US states plus Washington, DC, and Puerto Rico in order of their 2010 population density, in residents per square mile.\n",
    "We can see that by far the densest region in this dataset is Washington, DC (i.e., the District of Columbia); among states, the densest is New Jersey.\n",
    "\n",
    "We can also check the end of the list:"
   ]
  },
  {
   "metadata": {
    "id": "p9N-pHz_upNj",
    "outputId": "f26e3d3b-adfc-4720-e5b2-49c60cfa968b"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state\n",
       "South Dakota    10.583512\n",
       "North Dakota     9.537565\n",
       "Montana          6.736171\n",
       "Wyoming          5.768079\n",
       "Alaska           1.087509\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "density.tail()"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We see that the least dense state, by far, is Alaska, averaging slightly over one resident per square mile.\n",
    "\n",
    "This type of messy data merging is a common task when trying to answer questions using real-world data sources.\n",
    "I hope that this example has given you an idea of the ways you can combine tools we've covered in order to gain insight from your data!"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<!--NAVIGATION-->\n",
    "< [Combining Datasets: Concat and Append](03.06-Concat-And-Append.ipynb) | [Contents](Index.ipynb) | [Aggregation and Grouping](03.08-Aggregation-and-Grouping.ipynb) >\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.07-Merge-and-Join.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The datasets in this exercise are imported from csv-files. You will learn how to do this in a seperate course."
  },
  {
   "metadata": {
    "id": "47cb13143eec58f1",
    "ExecuteTime": {
     "end_time": "2025-02-04T12:43:36.308180Z",
     "start_time": "2025-02-04T12:43:35.794502Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_customer = pd.read_csv('../../datasets/customer.csv')\n",
    "df_sales = pd.read_csv('../../datasets/sales.csv')\n",
    "df_product = pd.read_csv('../../datasets/products.csv')\n",
    "df_prod_supplier=pd.read_csv('../../datasets/prod_suppliers.csv')\n",
    "df_supplier=pd.read_csv('../../datasets/suppliers.csv')\n",
    "df_prod_supplier2=pd.read_csv('../../datasets/prod_suppliers2.csv')\n",
    "df_product1=pd.read_csv('../../datasets/products.csv')\n",
    "df_product2=pd.read_csv('../../datasets/products2.csv')\n",
    "df_product3=pd.read_csv('../../datasets/products3.csv')\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T12:43:36.364809Z",
     "start_time": "2025-02-04T12:43:36.338209Z"
    },
    "id": "ff65c33393e83b4c",
    "outputId": "92baff05-7f1a-4948-afd4-621b691b7b17"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  Student_name                 Minor\n",
       "0        Alice  French communication\n",
       "1        Frank                   LLM\n",
       "2          Ali         Cybersecurity"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student_name</th>\n",
       "      <th>Minor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>French communication</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Frank</td>\n",
       "      <td>LLM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ali</td>\n",
       "      <td>Cybersecurity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "df_courses = pd.DataFrame({\n",
    "    'major': ['AI', 'AI','AI','Infrastructure & System Engineering','Infrastructure & System Engineering', 'Infrastructure & System Engineering','Application Development','Application Development','Application Development','Application Development','Application Development','Application Development'],\n",
    "    'courses': [\n",
    "        'Machine Learning', 'Deep Learning', 'Natural Language Processing',\n",
    "        'Network Security', 'Cloud Computing', 'Database Management',\n",
    "        'Software Engineering', 'Systems Design', 'Embedded Systems',\n",
    "        'Web Development', 'Mobile App Development', 'Software Testing'\n",
    "    ]\n",
    "})\n",
    "df_students= pd.DataFrame({\n",
    "    'student_name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva', 'Frank'],\n",
    "    'major': ['AI', 'Infrastructure & System Engineering', 'Infrastructure & System Engineering', 'Application Development', 'AI', 'Application Development']\n",
    "})\n",
    "\n",
    "data={'Student_name':['Alice','Frank','Ali'],'Minor':['French communication','LLM','Cybersecurity']}\n",
    "df_minor=pd.DataFrame(data)\n",
    "df_minor"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Merge and joins\n",
    "Five dataframes are given: customer, sales, products, prod_supplier and supplier. Investigate the dataframes.\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T12:43:36.750660Z",
     "start_time": "2025-02-04T12:43:36.677176Z"
    },
    "id": "958aa9c5c010dea6",
    "outputId": "0c624a12-ae69-4aed-f3cf-acd4af0dd765"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   c_id Customer\n",
       "0     1     Rabi\n",
       "1     2     Raju\n",
       "2     3     Alex\n",
       "3     4     Rani\n",
       "4     5     King"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_id</th>\n",
       "      <th>Customer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Rabi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Raju</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Alex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Rani</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>King</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "   sale_id  c_id  p_id  product  qty store\n",
       "0        1     2     3  Monitor    2   ABC\n",
       "1        2     2     4      CPU    1   DEF\n",
       "2        3     1     3  Monitor    3   ABC\n",
       "3        4     4     2      RAM    2   DEF\n",
       "4        5     2     3  Monitor    3   ABC"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sale_id</th>\n",
       "      <th>c_id</th>\n",
       "      <th>p_id</th>\n",
       "      <th>product</th>\n",
       "      <th>qty</th>\n",
       "      <th>store</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Monitor</td>\n",
       "      <td>2</td>\n",
       "      <td>ABC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>CPU</td>\n",
       "      <td>1</td>\n",
       "      <td>DEF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Monitor</td>\n",
       "      <td>3</td>\n",
       "      <td>ABC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>RAM</td>\n",
       "      <td>2</td>\n",
       "      <td>DEF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Monitor</td>\n",
       "      <td>3</td>\n",
       "      <td>ABC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "   p_id       product  price\n",
       "0     1     Hard Disk     80\n",
       "1     2           RAM     90\n",
       "2     3       Monitor     75\n",
       "3     4           CPU     55\n",
       "4     5      Keyboard     20\n",
       "5     6         Mouse     10\n",
       "6     7   Motherboard     50\n",
       "7     8  Power supply     20"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_id</th>\n",
       "      <th>product</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Hard Disk</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>RAM</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Monitor</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>CPU</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Keyboard</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Mouse</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Motherboard</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Power supply</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "   p_id  supp_id      suppliername\n",
       "0     1        1  Hypertek Systems\n",
       "1     2        1  Hypertek Systems\n",
       "2     3        2   informatique.nl\n",
       "3     8        1  Hypertek Systems\n",
       "4     4        3    centurytech.sg\n",
       "5     5        3    centurytech.sg\n",
       "6     6        2   informatique.nl\n",
       "7     7        3    centurytech.sg"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_id</th>\n",
       "      <th>supp_id</th>\n",
       "      <th>suppliername</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Hypertek Systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Hypertek Systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>informatique.nl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Hypertek Systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>centurytech.sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>centurytech.sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>informatique.nl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>centurytech.sg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "   supp_id      suppliername                 email       phone  \\\n",
       "0        1  Hypertek Systems     sales@hypertek.be  3256894514   \n",
       "1        2   informatique.nl  info@informatique.nl   312335679   \n",
       "2        3    centurytech.sg   info@centurytech.sg   657754637   \n",
       "\n",
       "                    address  \n",
       "0   Groenplaats 4 Antwerpen  \n",
       "1  Willem2plein 3 Rotterdam  \n",
       "2   China Tower 3 Singapore  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>supp_id</th>\n",
       "      <th>suppliername</th>\n",
       "      <th>email</th>\n",
       "      <th>phone</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Hypertek Systems</td>\n",
       "      <td>sales@hypertek.be</td>\n",
       "      <td>3256894514</td>\n",
       "      <td>Groenplaats 4 Antwerpen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>informatique.nl</td>\n",
       "      <td>info@informatique.nl</td>\n",
       "      <td>312335679</td>\n",
       "      <td>Willem2plein 3 Rotterdam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>centurytech.sg</td>\n",
       "      <td>info@centurytech.sg</td>\n",
       "      <td>657754637</td>\n",
       "      <td>China Tower 3 Singapore</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "df_customer.head()\n",
    "#SOLUTION_END\n",
    "#SOLUTION_START\n",
    "df_sales.head()\n",
    "#SOLUTION_END\n",
    "#SOLUTION_START\n",
    "df_product\n",
    "#SOLUTION_END\n",
    "#SOLUTION_START\n",
    "df_prod_supplier\n",
    "#SOLUTION_END md\n",
    "#SOLUTION_START\n",
    "df_supplier\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "### One-to-one joins"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "a. Construct a new dataframe df_product_extended which adds the columns 'supp_id' and 'suppliername' from df_prod_supplier to df_products.Verify if the operation is ok."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T12:43:38.022393Z",
     "start_time": "2025-02-04T12:43:37.986155Z"
    },
    "id": "f795558c63707201",
    "outputId": "a8c3f5b1-3627-4778-f3ff-c7184265982d"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   p_id       product  price  supp_id      suppliername\n",
       "0     1     Hard Disk     80        1  Hypertek Systems\n",
       "1     2           RAM     90        1  Hypertek Systems\n",
       "2     3       Monitor     75        2   informatique.nl\n",
       "3     4           CPU     55        3    centurytech.sg\n",
       "4     5      Keyboard     20        3    centurytech.sg\n",
       "5     6         Mouse     10        2   informatique.nl\n",
       "6     7   Motherboard     50        3    centurytech.sg\n",
       "7     8  Power supply     20        1  Hypertek Systems"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_id</th>\n",
       "      <th>product</th>\n",
       "      <th>price</th>\n",
       "      <th>supp_id</th>\n",
       "      <th>suppliername</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Hard Disk</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>Hypertek Systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>RAM</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>Hypertek Systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Monitor</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>informatique.nl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>CPU</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>centurytech.sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Keyboard</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>centurytech.sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Mouse</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>informatique.nl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Motherboard</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>centurytech.sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Power supply</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>Hypertek Systems</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "df_product_extended=pd.merge(df_product,df_prod_supplier)\n",
    "#SOLUTION_END\n",
    "#SOLUTION_START\n",
    "df_product_extended\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "b. What did you notice about the merge?"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T12:43:39.221137Z",
     "start_time": "2025-02-04T12:43:39.212462Z"
    },
    "id": "db0ff7138fb54e28"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "#A. It \"knows\" that p_id is the join key (in SQL we needed to specify the join key)\n",
    "#B. The rows do not need to appear in the same order (e.g. Power supply with p_id 8 was in row 4 for the prod_supplier table) )\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Many-to-one joins (similar to SQL INNER JOIN)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "a. How can we create a table with the prod_supplier information and also the emails, phone numbers and address of the suppliers? Identify the new dataframe as df_prod_extended_supplier\n"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T12:43:41.029326Z",
     "start_time": "2025-02-04T12:43:41.004227Z"
    },
    "id": "8cd1f6dc0da14a38"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "df_prod_extended_supplier=pd.merge(df_prod_supplier,df_supplier)\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T12:43:41.824029Z",
     "start_time": "2025-02-04T12:43:41.807182Z"
    },
    "id": "d6532ae1a0d19e41",
    "outputId": "59a73d8c-1cbf-49e0-deb3-d67d08e23b95"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   p_id  supp_id      suppliername                 email       phone  \\\n",
       "0     1        1  Hypertek Systems     sales@hypertek.be  3256894514   \n",
       "1     2        1  Hypertek Systems     sales@hypertek.be  3256894514   \n",
       "2     3        2   informatique.nl  info@informatique.nl   312335679   \n",
       "3     8        1  Hypertek Systems     sales@hypertek.be  3256894514   \n",
       "4     4        3    centurytech.sg   info@centurytech.sg   657754637   \n",
       "5     5        3    centurytech.sg   info@centurytech.sg   657754637   \n",
       "6     6        2   informatique.nl  info@informatique.nl   312335679   \n",
       "7     7        3    centurytech.sg   info@centurytech.sg   657754637   \n",
       "\n",
       "                    address  \n",
       "0   Groenplaats 4 Antwerpen  \n",
       "1   Groenplaats 4 Antwerpen  \n",
       "2  Willem2plein 3 Rotterdam  \n",
       "3   Groenplaats 4 Antwerpen  \n",
       "4   China Tower 3 Singapore  \n",
       "5   China Tower 3 Singapore  \n",
       "6  Willem2plein 3 Rotterdam  \n",
       "7   China Tower 3 Singapore  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_id</th>\n",
       "      <th>supp_id</th>\n",
       "      <th>suppliername</th>\n",
       "      <th>email</th>\n",
       "      <th>phone</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Hypertek Systems</td>\n",
       "      <td>sales@hypertek.be</td>\n",
       "      <td>3256894514</td>\n",
       "      <td>Groenplaats 4 Antwerpen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Hypertek Systems</td>\n",
       "      <td>sales@hypertek.be</td>\n",
       "      <td>3256894514</td>\n",
       "      <td>Groenplaats 4 Antwerpen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>informatique.nl</td>\n",
       "      <td>info@informatique.nl</td>\n",
       "      <td>312335679</td>\n",
       "      <td>Willem2plein 3 Rotterdam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Hypertek Systems</td>\n",
       "      <td>sales@hypertek.be</td>\n",
       "      <td>3256894514</td>\n",
       "      <td>Groenplaats 4 Antwerpen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>centurytech.sg</td>\n",
       "      <td>info@centurytech.sg</td>\n",
       "      <td>657754637</td>\n",
       "      <td>China Tower 3 Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>centurytech.sg</td>\n",
       "      <td>info@centurytech.sg</td>\n",
       "      <td>657754637</td>\n",
       "      <td>China Tower 3 Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>informatique.nl</td>\n",
       "      <td>info@informatique.nl</td>\n",
       "      <td>312335679</td>\n",
       "      <td>Willem2plein 3 Rotterdam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>centurytech.sg</td>\n",
       "      <td>info@centurytech.sg</td>\n",
       "      <td>657754637</td>\n",
       "      <td>China Tower 3 Singapore</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "df_prod_extended_supplier\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "b. What happens when in one of the files you have supplier_name instead of suppliername?\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T12:43:42.617457Z",
     "start_time": "2025-02-04T12:43:42.607167Z"
    },
    "id": "1120bd843a5feead"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    " #SOLUTION_START\n",
    " # Both columns are will appear in the new dataframe\n",
    " #SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Many-to-many joins\n"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "a. Investigate both df_courses and df_students"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T12:43:43.063223Z",
     "start_time": "2025-02-04T12:43:43.024085Z"
    },
    "id": "10978b6d42fbee6d",
    "outputId": "10ca21d6-7260-4f58-c6eb-ea1798e24f5d"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                  major                      courses\n",
       "0                                    AI             Machine Learning\n",
       "1                                    AI                Deep Learning\n",
       "2                                    AI  Natural Language Processing\n",
       "3   Infrastructure & System Engineering             Network Security\n",
       "4   Infrastructure & System Engineering              Cloud Computing\n",
       "5   Infrastructure & System Engineering          Database Management\n",
       "6               Application Development         Software Engineering\n",
       "7               Application Development               Systems Design\n",
       "8               Application Development             Embedded Systems\n",
       "9               Application Development              Web Development\n",
       "10              Application Development       Mobile App Development\n",
       "11              Application Development             Software Testing"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>major</th>\n",
       "      <th>courses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AI</td>\n",
       "      <td>Machine Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AI</td>\n",
       "      <td>Deep Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AI</td>\n",
       "      <td>Natural Language Processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Infrastructure &amp; System Engineering</td>\n",
       "      <td>Network Security</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Infrastructure &amp; System Engineering</td>\n",
       "      <td>Cloud Computing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Infrastructure &amp; System Engineering</td>\n",
       "      <td>Database Management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Application Development</td>\n",
       "      <td>Software Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Application Development</td>\n",
       "      <td>Systems Design</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Application Development</td>\n",
       "      <td>Embedded Systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Application Development</td>\n",
       "      <td>Web Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Application Development</td>\n",
       "      <td>Mobile App Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Application Development</td>\n",
       "      <td>Software Testing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "  student_name                                major\n",
       "0        Alice                                   AI\n",
       "1          Bob  Infrastructure & System Engineering\n",
       "2      Charlie  Infrastructure & System Engineering\n",
       "3        David              Application Development\n",
       "4          Eva                                   AI\n",
       "5        Frank              Application Development"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_name</th>\n",
       "      <th>major</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Infrastructure &amp; System Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>Infrastructure &amp; System Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>David</td>\n",
       "      <td>Application Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eva</td>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Frank</td>\n",
       "      <td>Application Development</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "df_courses\n",
    "df_students\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "b. Construct a list of all the courses a student needs to follow."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T12:43:44.034443Z",
     "start_time": "2025-02-04T12:43:44.001731Z"
    },
    "id": "264ee1c588c66c9e",
    "outputId": "d12bc2e5-2fd0-4d14-99ae-0c9adf69c33d"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   student_name                                major  \\\n",
       "0         Alice                                   AI   \n",
       "1         Alice                                   AI   \n",
       "2         Alice                                   AI   \n",
       "3           Bob  Infrastructure & System Engineering   \n",
       "4           Bob  Infrastructure & System Engineering   \n",
       "5           Bob  Infrastructure & System Engineering   \n",
       "6       Charlie  Infrastructure & System Engineering   \n",
       "7       Charlie  Infrastructure & System Engineering   \n",
       "8       Charlie  Infrastructure & System Engineering   \n",
       "9         David              Application Development   \n",
       "10        David              Application Development   \n",
       "11        David              Application Development   \n",
       "12        David              Application Development   \n",
       "13        David              Application Development   \n",
       "14        David              Application Development   \n",
       "15          Eva                                   AI   \n",
       "16          Eva                                   AI   \n",
       "17          Eva                                   AI   \n",
       "18        Frank              Application Development   \n",
       "19        Frank              Application Development   \n",
       "20        Frank              Application Development   \n",
       "21        Frank              Application Development   \n",
       "22        Frank              Application Development   \n",
       "23        Frank              Application Development   \n",
       "\n",
       "                        courses  \n",
       "0              Machine Learning  \n",
       "1                 Deep Learning  \n",
       "2   Natural Language Processing  \n",
       "3              Network Security  \n",
       "4               Cloud Computing  \n",
       "5           Database Management  \n",
       "6              Network Security  \n",
       "7               Cloud Computing  \n",
       "8           Database Management  \n",
       "9          Software Engineering  \n",
       "10               Systems Design  \n",
       "11             Embedded Systems  \n",
       "12              Web Development  \n",
       "13       Mobile App Development  \n",
       "14             Software Testing  \n",
       "15             Machine Learning  \n",
       "16                Deep Learning  \n",
       "17  Natural Language Processing  \n",
       "18         Software Engineering  \n",
       "19               Systems Design  \n",
       "20             Embedded Systems  \n",
       "21              Web Development  \n",
       "22       Mobile App Development  \n",
       "23             Software Testing  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_name</th>\n",
       "      <th>major</th>\n",
       "      <th>courses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>AI</td>\n",
       "      <td>Machine Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alice</td>\n",
       "      <td>AI</td>\n",
       "      <td>Deep Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alice</td>\n",
       "      <td>AI</td>\n",
       "      <td>Natural Language Processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Infrastructure &amp; System Engineering</td>\n",
       "      <td>Network Security</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Infrastructure &amp; System Engineering</td>\n",
       "      <td>Cloud Computing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Infrastructure &amp; System Engineering</td>\n",
       "      <td>Database Management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>Infrastructure &amp; System Engineering</td>\n",
       "      <td>Network Security</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>Infrastructure &amp; System Engineering</td>\n",
       "      <td>Cloud Computing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>Infrastructure &amp; System Engineering</td>\n",
       "      <td>Database Management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>David</td>\n",
       "      <td>Application Development</td>\n",
       "      <td>Software Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>David</td>\n",
       "      <td>Application Development</td>\n",
       "      <td>Systems Design</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>David</td>\n",
       "      <td>Application Development</td>\n",
       "      <td>Embedded Systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>David</td>\n",
       "      <td>Application Development</td>\n",
       "      <td>Web Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>David</td>\n",
       "      <td>Application Development</td>\n",
       "      <td>Mobile App Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>David</td>\n",
       "      <td>Application Development</td>\n",
       "      <td>Software Testing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Eva</td>\n",
       "      <td>AI</td>\n",
       "      <td>Machine Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Eva</td>\n",
       "      <td>AI</td>\n",
       "      <td>Deep Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Eva</td>\n",
       "      <td>AI</td>\n",
       "      <td>Natural Language Processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Frank</td>\n",
       "      <td>Application Development</td>\n",
       "      <td>Software Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Frank</td>\n",
       "      <td>Application Development</td>\n",
       "      <td>Systems Design</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Frank</td>\n",
       "      <td>Application Development</td>\n",
       "      <td>Embedded Systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Frank</td>\n",
       "      <td>Application Development</td>\n",
       "      <td>Web Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Frank</td>\n",
       "      <td>Application Development</td>\n",
       "      <td>Mobile App Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Frank</td>\n",
       "      <td>Application Development</td>\n",
       "      <td>Software Testing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "df_listcourses=pd.merge(df_students,df_courses)\n",
    "\n",
    "df_listcourses\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "### Merge keys"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "a. Read the file prod_suppliers2.csv next in Suppliers.csv we still have suppliersname but in prod_suppliers the column is named 'supplier'. Also supp_id is unavailable. Perform a merge without renaming the columns."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T12:43:45.142935Z",
     "start_time": "2025-02-04T12:43:45.082287Z"
    },
    "id": "ffddd5d996d9e57b",
    "outputId": "ea5f16ad-572c-449e-d3ba-d1bedb0d88e7"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   p_id  supp_id      suppliername                 email       phone  \\\n",
       "0     1        1  Hypertek Systems     sales@hypertek.be  3256894514   \n",
       "1     2        1  Hypertek Systems     sales@hypertek.be  3256894514   \n",
       "2     3        2   informatique.nl  info@informatique.nl   312335679   \n",
       "3     8        1  Hypertek Systems     sales@hypertek.be  3256894514   \n",
       "4     4        3    centurytech.sg   info@centurytech.sg   657754637   \n",
       "\n",
       "                    address  \n",
       "0   Groenplaats 4 Antwerpen  \n",
       "1   Groenplaats 4 Antwerpen  \n",
       "2  Willem2plein 3 Rotterdam  \n",
       "3   Groenplaats 4 Antwerpen  \n",
       "4   China Tower 3 Singapore  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_id</th>\n",
       "      <th>supp_id</th>\n",
       "      <th>suppliername</th>\n",
       "      <th>email</th>\n",
       "      <th>phone</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Hypertek Systems</td>\n",
       "      <td>sales@hypertek.be</td>\n",
       "      <td>3256894514</td>\n",
       "      <td>Groenplaats 4 Antwerpen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Hypertek Systems</td>\n",
       "      <td>sales@hypertek.be</td>\n",
       "      <td>3256894514</td>\n",
       "      <td>Groenplaats 4 Antwerpen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>informatique.nl</td>\n",
       "      <td>info@informatique.nl</td>\n",
       "      <td>312335679</td>\n",
       "      <td>Willem2plein 3 Rotterdam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Hypertek Systems</td>\n",
       "      <td>sales@hypertek.be</td>\n",
       "      <td>3256894514</td>\n",
       "      <td>Groenplaats 4 Antwerpen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>centurytech.sg</td>\n",
       "      <td>info@centurytech.sg</td>\n",
       "      <td>657754637</td>\n",
       "      <td>China Tower 3 Singapore</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "df=pd.merge(df_prod_supplier2,df_supplier, left_on='supplier',right_on=\"suppliername\").drop('supplier',axis=1)\n",
    "df.head()\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "b. Take df_product and df_prod_supplier2 transform the p_id in an index\\\n",
    "c. Merge the two tables on the index\\\n",
    "d. Do the same but use the join method of Pandas\\\n",
    "e. Verify that both are the same"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T12:43:46.268576Z",
     "start_time": "2025-02-04T12:43:46.246677Z"
    },
    "id": "b099f6f5131425c9",
    "outputId": "5ad13c33-3469-472f-f20b-5832a990cfea"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           product  price          supplier\n",
      "p_id                                       \n",
      "1        Hard Disk     80  Hypertek Systems\n",
      "2              RAM     90  Hypertek Systems\n",
      "3          Monitor     75   informatique.nl\n",
      "4              CPU     55    centurytech.sg\n",
      "5         Keyboard     20    centurytech.sg\n",
      "6            Mouse     10   informatique.nl\n",
      "7      Motherboard     50    centurytech.sg\n",
      "8     Power supply     20  Hypertek Systems\n",
      "           product  price          supplier\n",
      "p_id                                       \n",
      "1        Hard Disk     80  Hypertek Systems\n",
      "2              RAM     90  Hypertek Systems\n",
      "3          Monitor     75   informatique.nl\n",
      "4              CPU     55    centurytech.sg\n",
      "5         Keyboard     20    centurytech.sg\n",
      "6            Mouse     10   informatique.nl\n",
      "7      Motherboard     50    centurytech.sg\n",
      "8     Power supply     20  Hypertek Systems\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "df_product=df_product.set_index('p_id')\n",
    "df_prod_supplier2=df_prod_supplier2.set_index('p_id')\n",
    "\n",
    "\n",
    "df=pd.merge(df_product,df_prod_supplier2,left_index=True,right_index=True)\n",
    "print(df)\n",
    "\n",
    "dfj=df_product.join(df_prod_supplier2)\n",
    "print(dfj)\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "f.Merge the sales, prod_suppliers and products into one dataframe. What wil you merge first\n",
    "    b.How do you avoid having double columns?"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T12:43:46.936609Z",
     "start_time": "2025-02-04T12:43:46.875745Z"
    },
    "id": "fbdecd2048496170",
    "outputId": "82108c51-df9a-4e2e-ff77-4d0e0a7f32ab"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sale_id  c_id  p_id  product  qty store  price\n",
      "0        1     2     3  Monitor    2   ABC     75\n",
      "1        2     2     4      CPU    1   DEF     55\n",
      "2        3     1     3  Monitor    3   ABC     75\n",
      "3        4     4     2      RAM    2   DEF     90\n",
      "4        5     2     3  Monitor    3   ABC     75\n",
      "5        6     3     3  Monitor    2   DEF     75\n",
      "6        7     2     2      RAM    3   ABC     90\n",
      "7        8     3     2      RAM    2   DEF     90\n",
      "8        9     2     3  Monitor    2   ABC     75\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   sale_id  c_id  p_id  product  qty store  price  supp_id      suppliername\n",
       "0        1     2     3  Monitor    2   ABC     75        2   informatique.nl\n",
       "1        2     2     4      CPU    1   DEF     55        3    centurytech.sg\n",
       "2        3     1     3  Monitor    3   ABC     75        2   informatique.nl\n",
       "3        4     4     2      RAM    2   DEF     90        1  Hypertek Systems\n",
       "4        5     2     3  Monitor    3   ABC     75        2   informatique.nl\n",
       "5        6     3     3  Monitor    2   DEF     75        2   informatique.nl\n",
       "6        7     2     2      RAM    3   ABC     90        1  Hypertek Systems\n",
       "7        8     3     2      RAM    2   DEF     90        1  Hypertek Systems\n",
       "8        9     2     3  Monitor    2   ABC     75        2   informatique.nl"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sale_id</th>\n",
       "      <th>c_id</th>\n",
       "      <th>p_id</th>\n",
       "      <th>product</th>\n",
       "      <th>qty</th>\n",
       "      <th>store</th>\n",
       "      <th>price</th>\n",
       "      <th>supp_id</th>\n",
       "      <th>suppliername</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Monitor</td>\n",
       "      <td>2</td>\n",
       "      <td>ABC</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>informatique.nl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>CPU</td>\n",
       "      <td>1</td>\n",
       "      <td>DEF</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>centurytech.sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Monitor</td>\n",
       "      <td>3</td>\n",
       "      <td>ABC</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>informatique.nl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>RAM</td>\n",
       "      <td>2</td>\n",
       "      <td>DEF</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>Hypertek Systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Monitor</td>\n",
       "      <td>3</td>\n",
       "      <td>ABC</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>informatique.nl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Monitor</td>\n",
       "      <td>2</td>\n",
       "      <td>DEF</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>informatique.nl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>RAM</td>\n",
       "      <td>3</td>\n",
       "      <td>ABC</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>Hypertek Systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>RAM</td>\n",
       "      <td>2</td>\n",
       "      <td>DEF</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>Hypertek Systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Monitor</td>\n",
       "      <td>2</td>\n",
       "      <td>ABC</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>informatique.nl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "df_temp=pd.merge(df_sales,df_product,left_on=['p_id','product'],right_on=['p_id','product'])\n",
    "print(df_temp)\n",
    "\n",
    "df_final=pd.merge(df_temp,df_prod_supplier,left_on='p_id',right_on='p_id')\n",
    "df_final\n",
    "#SOLUTION_END md\n",
    "### What about left, right and outer joins?\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In SQL we have the notion of a left and right join and an outer join. What are the pandas counterparts?\n",
    "Let's review our student example"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T12:43:47.791305Z",
     "start_time": "2025-02-04T12:43:47.780508Z"
    },
    "id": "eca4a9a786280307",
    "outputId": "a229bc7d-5aa1-4949-9959-54ddbf952c2e"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  student_name                                major\n",
      "0        Alice                                   AI\n",
      "1          Bob  Infrastructure & System Engineering\n",
      "2      Charlie  Infrastructure & System Engineering\n",
      "3        David              Application Development\n",
      "4          Eva                                   AI\n",
      "5        Frank              Application Development\n"
     ]
    }
   ],
   "execution_count": null,
   "source": "print(df_students)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "12. Students can also follow a minor. The dataframe df_minor contains the information about the minor of the students. Investigate the dataframe. One of the students follows a minor but no major.\\\n",
    "a. Merge the df_students (containing students and their major) with df_minor. What happens?\\\n",
    "b. Do we have duplicate columns? How do we drop them?\\\n",
    "c Construct a dataframe with all the information of all the students.\\\n",
    "d. Construct a dataframe with all the information of the majors and optional that of the minors.\\\n",
    "e. Construct a dataframe with all the info about the minors and optional that of the majors\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T12:43:48.566478Z",
     "start_time": "2025-02-04T12:43:48.555233Z"
    },
    "id": "48138b1343116ecb"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "#a\n",
    "df=pd.merge(df_students,df_minor,left_on='student_name',right_on='Student_name')\n",
    "# We see only the information for Alice and Frank because they are the only ones with a minor and a major"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T12:43:49.771618Z",
     "start_time": "2025-02-04T12:43:49.697883Z"
    },
    "id": "6d544790e56fb4db",
    "outputId": "fff16394-580a-4785-d751-83f06ebc82b0"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  student_name                                major Student_name  \\\n",
       "0          NaN                                  NaN          Ali   \n",
       "1        Alice                                   AI        Alice   \n",
       "2          Bob  Infrastructure & System Engineering          NaN   \n",
       "3      Charlie  Infrastructure & System Engineering          NaN   \n",
       "4        David              Application Development          NaN   \n",
       "5          Eva                                   AI          NaN   \n",
       "6        Frank              Application Development        Frank   \n",
       "\n",
       "                  Minor  \n",
       "0         Cybersecurity  \n",
       "1  French communication  \n",
       "2                   NaN  \n",
       "3                   NaN  \n",
       "4                   NaN  \n",
       "5                   NaN  \n",
       "6                   LLM  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_name</th>\n",
       "      <th>major</th>\n",
       "      <th>Student_name</th>\n",
       "      <th>Minor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ali</td>\n",
       "      <td>Cybersecurity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alice</td>\n",
       "      <td>AI</td>\n",
       "      <td>Alice</td>\n",
       "      <td>French communication</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Infrastructure &amp; System Engineering</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>Infrastructure &amp; System Engineering</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>David</td>\n",
       "      <td>Application Development</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Eva</td>\n",
       "      <td>AI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Frank</td>\n",
       "      <td>Application Development</td>\n",
       "      <td>Frank</td>\n",
       "      <td>LLM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "  student_name                                major Student_name  \\\n",
       "0        Alice                                   AI        Alice   \n",
       "1          Bob  Infrastructure & System Engineering          NaN   \n",
       "2      Charlie  Infrastructure & System Engineering          NaN   \n",
       "3        David              Application Development          NaN   \n",
       "4          Eva                                   AI          NaN   \n",
       "5        Frank              Application Development        Frank   \n",
       "\n",
       "                  Minor  \n",
       "0  French communication  \n",
       "1                   NaN  \n",
       "2                   NaN  \n",
       "3                   NaN  \n",
       "4                   NaN  \n",
       "5                   LLM  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_name</th>\n",
       "      <th>major</th>\n",
       "      <th>Student_name</th>\n",
       "      <th>Minor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>AI</td>\n",
       "      <td>Alice</td>\n",
       "      <td>French communication</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Infrastructure &amp; System Engineering</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>Infrastructure &amp; System Engineering</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>David</td>\n",
       "      <td>Application Development</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eva</td>\n",
       "      <td>AI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Frank</td>\n",
       "      <td>Application Development</td>\n",
       "      <td>Frank</td>\n",
       "      <td>LLM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "  student_name                    major Student_name                 Minor\n",
       "0        Alice                       AI        Alice  French communication\n",
       "1        Frank  Application Development        Frank                   LLM\n",
       "2          NaN                      NaN          Ali         Cybersecurity"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_name</th>\n",
       "      <th>major</th>\n",
       "      <th>Student_name</th>\n",
       "      <th>Minor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>AI</td>\n",
       "      <td>Alice</td>\n",
       "      <td>French communication</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Frank</td>\n",
       "      <td>Application Development</td>\n",
       "      <td>Frank</td>\n",
       "      <td>LLM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ali</td>\n",
       "      <td>Cybersecurity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "\n",
    "#b\n",
    "df=df.drop('Student_name',axis=1)\n",
    "\n",
    "#c\n",
    "df_outer=pd.merge(df_students,df_minor,left_on='student_name',right_on='Student_name',how='outer')\n",
    "df_outer\n",
    "\n",
    "#d\n",
    "df_left=pd.merge(df_students,df_minor,left_on='student_name',right_on='Student_name',how='left')\n",
    "df_left\n",
    "\n",
    "#e\n",
    "df_right=pd.merge(df_students,df_minor,left_on='student_name',right_on='Student_name',how='right')\n",
    "df_right\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<!--BOOK_INFORMATION-->\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"figures/PDSH-cover-small.png\">\n",
    "\n",
    "*This notebook contains an excerpt from the [Python Data Science Handbook](http://shop.oreilly.com/product/0636920034919.do) by Jake VanderPlas; the content is available [on GitHub](https://github.com/jakevdp/PythonDataScienceHandbook).*\n",
    "\n",
    "*The text is released under the [CC-BY-NC-ND license](https://creativecommons.org/licenses/by-nc-nd/3.0/us/legalcode), and code is released under the [MIT license](https://opensource.org/licenses/MIT). If you find this content useful, please consider supporting the work by [buying the book](http://shop.oreilly.com/product/0636920034919.do)!*"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<!--NAVIGATION-->\n",
    "< [Combining Datasets: Merge and Join](03.07-Merge-and-Join.ipynb) | [Contents](Index.ipynb) | [Pivot Tables](03.09-Pivot-Tables.ipynb) >\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.08-Aggregation-and-Grouping.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Aggregation and Grouping"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "An essential piece of analysis of large data is efficient summarization: computing aggregations like ``sum()``, ``mean()``, ``median()``, ``min()``, and ``max()``, in which a single number gives insight into the nature of a potentially large dataset.\n",
    "In this section, we'll explore aggregations in Pandas, from simple operations akin to what we've seen on NumPy arrays, to more sophisticated operations based on the concept of a ``groupby``."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "For convenience, we'll use the same ``display`` magic function that we've seen in previous sections:"
  },
  {
   "metadata": {
    "collapsed": true,
    "id": "qL38qNXF5woD"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class display(object):\n",
    "    \"\"\"Display HTML representation of multiple objects\"\"\"\n",
    "    template = \"\"\"<div style=\"float: left; padding: 10px;\">\n",
    "    <p style='font-family:\"Courier New\", Courier, monospace'>{0}</p>{1}\n",
    "    </div>\"\"\"\n",
    "    def __init__(self, *args):\n",
    "        self.args = args\n",
    "\n",
    "    def _repr_html_(self):\n",
    "        return '\\n'.join(self.template.format(a, eval(a)._repr_html_())\n",
    "                         for a in self.args)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '\\n\\n'.join(a + '\\n' + repr(eval(a))\n",
    "                           for a in self.args)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Planets Data\n",
    "\n",
    "Here we will use the Planets dataset, available via the [Seaborn package](http://seaborn.pydata.org/) (see [Visualization With Seaborn](04.14-Visualization-With-Seaborn.ipynb)).\n",
    "It gives information on planets that astronomers have discovered around other stars (known as *extrasolar planets* or *exoplanets* for short). It can be downloaded with a simple Seaborn command:"
   ]
  },
  {
   "metadata": {
    "id": "-buhNdIQ5woG",
    "outputId": "6a363e6f-6d05-473d-8f10-c2d3819cef9f"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1035, 6)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "import seaborn as sns\n",
    "planets = sns.load_dataset('planets')\n",
    "planets.shape"
   ]
  },
  {
   "metadata": {
    "id": "uE1hgayB5woH",
    "outputId": "0366caad-da09-4ef8-d229-3393cd117f47"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>number</th>\n",
       "      <th>orbital_period</th>\n",
       "      <th>mass</th>\n",
       "      <th>distance</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Radial Velocity</td>\n",
       "      <td>1</td>\n",
       "      <td>269.300</td>\n",
       "      <td>7.10</td>\n",
       "      <td>77.40</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Radial Velocity</td>\n",
       "      <td>1</td>\n",
       "      <td>874.774</td>\n",
       "      <td>2.21</td>\n",
       "      <td>56.95</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Radial Velocity</td>\n",
       "      <td>1</td>\n",
       "      <td>763.000</td>\n",
       "      <td>2.60</td>\n",
       "      <td>19.84</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Radial Velocity</td>\n",
       "      <td>1</td>\n",
       "      <td>326.030</td>\n",
       "      <td>19.40</td>\n",
       "      <td>110.62</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Radial Velocity</td>\n",
       "      <td>1</td>\n",
       "      <td>516.220</td>\n",
       "      <td>10.50</td>\n",
       "      <td>119.47</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            method  number  orbital_period   mass  distance  year\n",
       "0  Radial Velocity       1         269.300   7.10     77.40  2006\n",
       "1  Radial Velocity       1         874.774   2.21     56.95  2008\n",
       "2  Radial Velocity       1         763.000   2.60     19.84  2011\n",
       "3  Radial Velocity       1         326.030  19.40    110.62  2007\n",
       "4  Radial Velocity       1         516.220  10.50    119.47  2009"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "planets.head()"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This has some details on the 1,000+ extrasolar planets discovered up to 2014."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Simple Aggregation in Pandas"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Earlier, we explored some of the data aggregations available for NumPy arrays ([\"Aggregations: Min, Max, and Everything In Between\"](02.04-Computation-on-arrays-aggregates.ipynb)).\n",
    "As with a one-dimensional NumPy array, for a Pandas ``Series`` the aggregates return a single value:"
   ]
  },
  {
   "metadata": {
    "id": "xtL3wlJ-5woJ",
    "outputId": "009ed1ec-547e-481f-d57b-286a78cc556b"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.374540\n",
       "1    0.950714\n",
       "2    0.731994\n",
       "3    0.598658\n",
       "4    0.156019\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "rng = np.random.RandomState(42)\n",
    "ser = pd.Series(rng.rand(5))\n",
    "ser"
   ]
  },
  {
   "metadata": {
    "id": "65EzTaLN5woJ",
    "outputId": "c585d639-519c-48a1-b066-82ed8ecf13a2"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8119254917081569"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "ser.sum()"
  },
  {
   "metadata": {
    "id": "VQcjfxv05woK",
    "outputId": "057dc474-99c1-4af1-966c-334ae65056b8"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56238509834163142"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "ser.mean()"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "For a ``DataFrame``, by default the aggregates return results within each column:"
  },
  {
   "metadata": {
    "id": "2LYf1xn55woK",
    "outputId": "24216432-4c02-4099-a5eb-257cdb3fab51"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.155995</td>\n",
       "      <td>0.020584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.058084</td>\n",
       "      <td>0.969910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.866176</td>\n",
       "      <td>0.832443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.601115</td>\n",
       "      <td>0.212339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.708073</td>\n",
       "      <td>0.181825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A         B\n",
       "0  0.155995  0.020584\n",
       "1  0.058084  0.969910\n",
       "2  0.866176  0.832443\n",
       "3  0.601115  0.212339\n",
       "4  0.708073  0.181825"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "df = pd.DataFrame({'A': rng.rand(5),\n",
    "                   'B': rng.rand(5)})\n",
    "df"
   ]
  },
  {
   "metadata": {
    "id": "aJD7i46g5woK",
    "outputId": "446ea89e-12b4-4bce-9384-e6814977f4e4"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    0.477888\n",
       "B    0.443420\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "df.mean()"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "By specifying the ``axis`` argument, you can instead aggregate within each row:"
  },
  {
   "metadata": {
    "id": "N4w7RnEe5woL",
    "outputId": "66118d5b-0d2e-4d69-8c59-6bf25a7924ae"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.088290\n",
       "1    0.513997\n",
       "2    0.849309\n",
       "3    0.406727\n",
       "4    0.444949\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "df.mean(axis='columns')"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Pandas ``Series`` and ``DataFrame``s include all of the common aggregates mentioned in [Aggregations: Min, Max, and Everything In Between](02.04-Computation-on-arrays-aggregates.ipynb); in addition, there is a convenience method ``describe()`` that computes several common aggregates for each column and returns the result.\n",
    "Let's use this on the Planets data, for now dropping rows with missing values:"
   ]
  },
  {
   "metadata": {
    "id": "PkOGWvum5woL",
    "outputId": "3a8b21f9-73fa-4336-e510-d93a767fc90c"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>orbital_period</th>\n",
       "      <th>mass</th>\n",
       "      <th>distance</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>498.00000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.73494</td>\n",
       "      <td>835.778671</td>\n",
       "      <td>2.509320</td>\n",
       "      <td>52.068213</td>\n",
       "      <td>2007.377510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.17572</td>\n",
       "      <td>1469.128259</td>\n",
       "      <td>3.636274</td>\n",
       "      <td>46.596041</td>\n",
       "      <td>4.167284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.328300</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.350000</td>\n",
       "      <td>1989.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>38.272250</td>\n",
       "      <td>0.212500</td>\n",
       "      <td>24.497500</td>\n",
       "      <td>2005.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>357.000000</td>\n",
       "      <td>1.245000</td>\n",
       "      <td>39.940000</td>\n",
       "      <td>2009.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.00000</td>\n",
       "      <td>999.600000</td>\n",
       "      <td>2.867500</td>\n",
       "      <td>59.332500</td>\n",
       "      <td>2011.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.00000</td>\n",
       "      <td>17337.500000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          number  orbital_period        mass    distance         year\n",
       "count  498.00000      498.000000  498.000000  498.000000   498.000000\n",
       "mean     1.73494      835.778671    2.509320   52.068213  2007.377510\n",
       "std      1.17572     1469.128259    3.636274   46.596041     4.167284\n",
       "min      1.00000        1.328300    0.003600    1.350000  1989.000000\n",
       "25%      1.00000       38.272250    0.212500   24.497500  2005.000000\n",
       "50%      1.00000      357.000000    1.245000   39.940000  2009.000000\n",
       "75%      2.00000      999.600000    2.867500   59.332500  2011.000000\n",
       "max      6.00000    17337.500000   25.000000  354.000000  2014.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "planets.dropna().describe()"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This can be a useful way to begin understanding the overall properties of a dataset.\n",
    "For example, we see in the ``year`` column that although exoplanets were discovered as far back as 1989, half of all known expolanets were not discovered until 2010 or after.\n",
    "This is largely thanks to the *Kepler* mission, which is a space-based telescope specifically designed for finding eclipsing planets around other stars."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The following table summarizes some other built-in Pandas aggregations:\n",
    "\n",
    "| Aggregation              | Description                     |\n",
    "|--------------------------|---------------------------------|\n",
    "| ``count()``              | Total number of items           |\n",
    "| ``first()``, ``last()``  | First and last item             |\n",
    "| ``mean()``, ``median()`` | Mean and median                 |\n",
    "| ``min()``, ``max()``     | Minimum and maximum             |\n",
    "| ``std()``, ``var()``     | Standard deviation and variance |\n",
    "| ``mad()``                | Mean absolute deviation         |\n",
    "| ``prod()``               | Product of all items            |\n",
    "| ``sum()``                | Sum of all items                |\n",
    "\n",
    "These are all methods of ``DataFrame`` and ``Series`` objects."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "To go deeper into the data, however, simple aggregates are often not enough.\n",
    "The next level of data summarization is the ``groupby`` operation, which allows you to quickly and efficiently compute aggregates on subsets of data."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## GroupBy: Split, Apply, Combine\n",
    "\n",
    "Simple aggregations can give you a flavor of your dataset, but often we would prefer to aggregate conditionally on some label or index: this is implemented in the so-called ``groupby`` operation.\n",
    "The name \"group by\" comes from a command in the SQL database language, but it is perhaps more illuminative to think of it in the terms first coined by Hadley Wickham of Rstats fame: *split, apply, combine*."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Split, apply, combine\n",
    "\n",
    "A canonical example of this split-apply-combine operation, where the \"apply\" is a summation aggregation, is illustrated in this figure:"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "![](figures/03.08-split-apply-combine.png)\n",
    "[figure source in Appendix](06.00-Figure-Code.ipynb#Split-Apply-Combine)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This makes clear what the ``groupby`` accomplishes:\n",
    "\n",
    "- The *split* step involves breaking up and grouping a ``DataFrame`` depending on the value of the specified key.\n",
    "- The *apply* step involves computing some function, usually an aggregate, transformation, or filtering, within the individual groups.\n",
    "- The *combine* step merges the results of these operations into an output array.\n",
    "\n",
    "While this could certainly be done manually using some combination of the masking, aggregation, and merging commands covered earlier, an important realization is that *the intermediate splits do not need to be explicitly instantiated*. Rather, the ``GroupBy`` can (often) do this in a single pass over the data, updating the sum, mean, count, min, or other aggregate for each group along the way.\n",
    "The power of the ``GroupBy`` is that it abstracts away these steps: the user need not think about *how* the computation is done under the hood, but rather thinks about the *operation as a whole*.\n",
    "\n",
    "As a concrete example, let's take a look at using Pandas for the computation shown in this diagram.\n",
    "We'll start by creating the input ``DataFrame``:"
   ]
  },
  {
   "metadata": {
    "id": "-8zMCj4g5woQ",
    "outputId": "c83b2ac2-2463-4405-f8b6-bf3a7ececf79"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  key  data\n",
       "0   A     0\n",
       "1   B     1\n",
       "2   C     2\n",
       "3   A     3\n",
       "4   B     4\n",
       "5   C     5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "df = pd.DataFrame({'key': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
    "                   'data': range(6)}, columns=['key', 'data'])\n",
    "df"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The most basic split-apply-combine operation can be computed with the ``groupby()`` method of ``DataFrame``s, passing the name of the desired key column:"
  },
  {
   "metadata": {
    "id": "DIX1mPMW5woR",
    "outputId": "1d734fe2-9731-42c8-f8e8-f120b30c3088"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.DataFrameGroupBy object at 0x117272160>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "df.groupby('key')"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Notice that what is returned is not a set of ``DataFrame``s, but a ``DataFrameGroupBy`` object.\n",
    "This object is where the magic is: you can think of it as a special view of the ``DataFrame``, which is poised to dig into the groups but does no actual computation until the aggregation is applied.\n",
    "This \"lazy evaluation\" approach means that common aggregates can be implemented very efficiently in a way that is almost transparent to the user.\n",
    "\n",
    "To produce a result, we can apply an aggregate to this ``DataFrameGroupBy`` object, which will perform the appropriate apply/combine steps to produce the desired result:"
   ]
  },
  {
   "metadata": {
    "id": "ncV_FzXX5woT",
    "outputId": "7c09d5ff-7bea-4686-c820-3f90f56dd1c2"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     data\n",
       "key      \n",
       "A       3\n",
       "B       5\n",
       "C       7"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "df.groupby('key').sum()"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The ``sum()`` method is just one possibility here; you can apply virtually any common Pandas or NumPy aggregation function, as well as virtually any valid ``DataFrame`` operation, as we will see in the following discussion."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### The GroupBy object\n",
    "\n",
    "The ``GroupBy`` object is a very flexible abstraction.\n",
    "In many ways, you can simply treat it as if it's a collection of ``DataFrame``s, and it does the difficult things under the hood. Let's see some examples using the Planets data.\n",
    "\n",
    "Perhaps the most important operations made available by a ``GroupBy`` are *aggregate*, *filter*, *transform*, and *apply*.\n",
    "We'll discuss each of these more fully in [\"Aggregate, Filter, Transform, Apply\"](#Aggregate,-Filter,-Transform,-Apply), but before that let's introduce some of the other functionality that can be used with the basic ``GroupBy`` operation."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Column indexing\n",
    "\n",
    "The ``GroupBy`` object supports column indexing in the same way as the ``DataFrame``, and returns a modified ``GroupBy`` object.\n",
    "For example:"
   ]
  },
  {
   "metadata": {
    "id": "82m2PSGY5woV",
    "outputId": "df13deeb-147a-4ca1-8b35-a57ae0472b63"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.DataFrameGroupBy object at 0x1172727b8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "planets.groupby('method')"
  },
  {
   "metadata": {
    "id": "-INudCz25woW",
    "outputId": "5d8cbf24-7b8a-4247-e185-8d25a99dbca1"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.SeriesGroupBy object at 0x117272da0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "planets.groupby('method')['orbital_period']"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Here we've selected a particular ``Series`` group from the original ``DataFrame`` group by reference to its column name.\n",
    "As with the ``GroupBy`` object, no computation is done until we call some aggregate on the object:"
   ]
  },
  {
   "metadata": {
    "id": "cS2DD0el5wod",
    "outputId": "fdeb0e9d-1c25-44a4-99ca-36d0c3baacb6"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "method\n",
       "Astrometry                         631.180000\n",
       "Eclipse Timing Variations         4343.500000\n",
       "Imaging                          27500.000000\n",
       "Microlensing                      3300.000000\n",
       "Orbital Brightness Modulation        0.342887\n",
       "Pulsar Timing                       66.541900\n",
       "Pulsation Timing Variations       1170.000000\n",
       "Radial Velocity                    360.200000\n",
       "Transit                              5.714932\n",
       "Transit Timing Variations           57.011000\n",
       "Name: orbital_period, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "planets.groupby('method')['orbital_period'].median()"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This gives an idea of the general scale of orbital periods (in days) that each method is sensitive to."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Iteration over groups\n",
    "\n",
    "The ``GroupBy`` object supports direct iteration over the groups, returning each group as a ``Series`` or ``DataFrame``:"
   ]
  },
  {
   "metadata": {
    "id": "pEpq9lAk5woe",
    "outputId": "efaa343d-2f27-4c11-e2eb-dcd6d6b8d7f9"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Astrometry                     shape=(2, 6)\n",
      "Eclipse Timing Variations      shape=(9, 6)\n",
      "Imaging                        shape=(38, 6)\n",
      "Microlensing                   shape=(23, 6)\n",
      "Orbital Brightness Modulation  shape=(3, 6)\n",
      "Pulsar Timing                  shape=(5, 6)\n",
      "Pulsation Timing Variations    shape=(1, 6)\n",
      "Radial Velocity                shape=(553, 6)\n",
      "Transit                        shape=(397, 6)\n",
      "Transit Timing Variations      shape=(4, 6)\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "for (method, group) in planets.groupby('method'):\n",
    "    print(\"{0:30s} shape={1}\".format(method, group.shape))"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This can be useful for doing certain things manually, though it is often much faster to use the built-in ``apply`` functionality, which we will discuss momentarily."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Dispatch methods\n",
    "\n",
    "Through some Python class magic, any method not explicitly implemented by the ``GroupBy`` object will be passed through and called on the groups, whether they are ``DataFrame`` or ``Series`` objects.\n",
    "For example, you can use the ``describe()`` method of ``DataFrame``s to perform a set of aggregations that describe each group in the data:"
   ]
  },
  {
   "metadata": {
    "id": "zvS7b94B5woe",
    "outputId": "b87382fc-4200-4052-aa02-19eebf725571"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Astrometry</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2011.500000</td>\n",
       "      <td>2.121320</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>2010.75</td>\n",
       "      <td>2011.5</td>\n",
       "      <td>2012.25</td>\n",
       "      <td>2013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eclipse Timing Variations</th>\n",
       "      <td>9.0</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>2009.00</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>2011.00</td>\n",
       "      <td>2012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Imaging</th>\n",
       "      <td>38.0</td>\n",
       "      <td>2009.131579</td>\n",
       "      <td>2.781901</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>2008.00</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>2011.00</td>\n",
       "      <td>2013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Microlensing</th>\n",
       "      <td>23.0</td>\n",
       "      <td>2009.782609</td>\n",
       "      <td>2.859697</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>2008.00</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>2012.00</td>\n",
       "      <td>2013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orbital Brightness Modulation</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2011.666667</td>\n",
       "      <td>1.154701</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>2011.00</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>2012.00</td>\n",
       "      <td>2013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pulsar Timing</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1998.400000</td>\n",
       "      <td>8.384510</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>1992.00</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>2003.00</td>\n",
       "      <td>2011.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pulsation Timing Variations</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>2007.00</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>2007.00</td>\n",
       "      <td>2007.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Radial Velocity</th>\n",
       "      <td>553.0</td>\n",
       "      <td>2007.518987</td>\n",
       "      <td>4.249052</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>2005.00</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>2011.00</td>\n",
       "      <td>2014.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transit</th>\n",
       "      <td>397.0</td>\n",
       "      <td>2011.236776</td>\n",
       "      <td>2.077867</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>2010.00</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>2013.00</td>\n",
       "      <td>2014.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transit Timing Variations</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2012.500000</td>\n",
       "      <td>1.290994</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>2011.75</td>\n",
       "      <td>2012.5</td>\n",
       "      <td>2013.25</td>\n",
       "      <td>2014.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               count         mean       std     min      25%  \\\n",
       "method                                                                         \n",
       "Astrometry                       2.0  2011.500000  2.121320  2010.0  2010.75   \n",
       "Eclipse Timing Variations        9.0  2010.000000  1.414214  2008.0  2009.00   \n",
       "Imaging                         38.0  2009.131579  2.781901  2004.0  2008.00   \n",
       "Microlensing                    23.0  2009.782609  2.859697  2004.0  2008.00   \n",
       "Orbital Brightness Modulation    3.0  2011.666667  1.154701  2011.0  2011.00   \n",
       "Pulsar Timing                    5.0  1998.400000  8.384510  1992.0  1992.00   \n",
       "Pulsation Timing Variations      1.0  2007.000000       NaN  2007.0  2007.00   \n",
       "Radial Velocity                553.0  2007.518987  4.249052  1989.0  2005.00   \n",
       "Transit                        397.0  2011.236776  2.077867  2002.0  2010.00   \n",
       "Transit Timing Variations        4.0  2012.500000  1.290994  2011.0  2011.75   \n",
       "\n",
       "                                  50%      75%     max  \n",
       "method                                                  \n",
       "Astrometry                     2011.5  2012.25  2013.0  \n",
       "Eclipse Timing Variations      2010.0  2011.00  2012.0  \n",
       "Imaging                        2009.0  2011.00  2013.0  \n",
       "Microlensing                   2010.0  2012.00  2013.0  \n",
       "Orbital Brightness Modulation  2011.0  2012.00  2013.0  \n",
       "Pulsar Timing                  1994.0  2003.00  2011.0  \n",
       "Pulsation Timing Variations    2007.0  2007.00  2007.0  \n",
       "Radial Velocity                2009.0  2011.00  2014.0  \n",
       "Transit                        2012.0  2013.00  2014.0  \n",
       "Transit Timing Variations      2012.5  2013.25  2014.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "planets.groupby('method')['year'].describe().unstack()"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Looking at this table helps us to better understand the data: for example, the vast majority of planets have been discovered by the Radial Velocity and Transit methods, though the latter only became common (due to new, more accurate telescopes) in the last decade.\n",
    "The newest methods seem to be Transit Timing Variation and Orbital Brightness Modulation, which were not used to discover a new planet until 2011.\n",
    "\n",
    "This is just one example of the utility of dispatch methods.\n",
    "Notice that they are applied *to each individual group*, and the results are then combined within ``GroupBy`` and returned.\n",
    "Again, any valid ``DataFrame``/``Series`` method can be used on the corresponding ``GroupBy`` object, which allows for some very flexible and powerful operations!"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Aggregate, filter, transform, apply\n",
    "\n",
    "The preceding discussion focused on aggregation for the combine operation, but there are more options available.\n",
    "In particular, ``GroupBy`` objects have ``aggregate()``, ``filter()``, ``transform()``, and ``apply()`` methods that efficiently implement a variety of useful operations before combining the grouped data.\n",
    "\n",
    "For the purpose of the following subsections, we'll use this ``DataFrame``:"
   ]
  },
  {
   "metadata": {
    "id": "Am7iwCCs5wog",
    "outputId": "66503c53-64b9-4d42-ea86-9e1400c77ca2"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>data1</th>\n",
       "      <th>data2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  key  data1  data2\n",
       "0   A      0      5\n",
       "1   B      1      0\n",
       "2   C      2      3\n",
       "3   A      3      3\n",
       "4   B      4      7\n",
       "5   C      5      9"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "rng = np.random.RandomState(0)\n",
    "df = pd.DataFrame({'key': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
    "                   'data1': range(6),\n",
    "                   'data2': rng.randint(0, 10, 6)},\n",
    "                   columns = ['key', 'data1', 'data2'])\n",
    "df"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Aggregation\n",
    "\n",
    "We're now familiar with ``GroupBy`` aggregations with ``sum()``, ``median()``, and the like, but the ``aggregate()`` method allows for even more flexibility.\n",
    "It can take a string, a function, or a list thereof, and compute all the aggregates at once.\n",
    "Here is a quick example combining all these:"
   ]
  },
  {
   "metadata": {
    "id": "zXxb1qrz5woh",
    "outputId": "940c7d7f-8f1b-49f7-c502-a7a139af9ea9"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">data1</th>\n",
       "      <th colspan=\"3\" halign=\"left\">data2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>median</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>median</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    data1            data2           \n",
       "      min median max   min median max\n",
       "key                                  \n",
       "A       0    1.5   3     3    4.0   5\n",
       "B       1    2.5   4     0    3.5   7\n",
       "C       2    3.5   5     3    6.0   9"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "df.groupby('key').aggregate(['min', np.median, max])"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Another useful pattern is to pass a dictionary mapping column names to operations to be applied on that column:"
  },
  {
   "metadata": {
    "id": "i0i0ZUUP5woj",
    "outputId": "fc743b5a-041c-4394-86ab-920c1fd27326"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data1</th>\n",
       "      <th>data2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     data1  data2\n",
       "key              \n",
       "A        0      5\n",
       "B        1      7\n",
       "C        2      9"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "df.groupby('key').aggregate({'data1': 'min',\n",
    "                             'data2': 'max'})"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Filtering\n",
    "\n",
    "A filtering operation allows you to drop data based on the group properties.\n",
    "For example, we might want to keep all groups in which the standard deviation is larger than some critical value:"
   ]
  },
  {
   "metadata": {
    "id": "pB_7utbF5wok",
    "outputId": "762e7b24-1036-4fd4-a700-128157ae8a4a"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>df</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>data1</th>\n",
       "      <th>data2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>\n",
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>df.groupby('key').std()</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data1</th>\n",
       "      <th>data2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>2.12132</td>\n",
       "      <td>1.414214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>2.12132</td>\n",
       "      <td>4.949747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>2.12132</td>\n",
       "      <td>4.242641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>\n",
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>df.groupby('key').filter(filter_func)</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>data1</th>\n",
       "      <th>data2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>"
      ],
      "text/plain": [
       "df\n",
       "  key  data1  data2\n",
       "0   A      0      5\n",
       "1   B      1      0\n",
       "2   C      2      3\n",
       "3   A      3      3\n",
       "4   B      4      7\n",
       "5   C      5      9\n",
       "\n",
       "df.groupby('key').std()\n",
       "       data1     data2\n",
       "key                   \n",
       "A    2.12132  1.414214\n",
       "B    2.12132  4.949747\n",
       "C    2.12132  4.242641\n",
       "\n",
       "df.groupby('key').filter(filter_func)\n",
       "  key  data1  data2\n",
       "1   B      1      0\n",
       "2   C      2      3\n",
       "4   B      4      7\n",
       "5   C      5      9"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "def filter_func(x):\n",
    "    return x['data2'].std() > 4\n",
    "\n",
    "display('df', \"df.groupby('key').std()\", \"df.groupby('key').filter(filter_func)\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The filter function should return a Boolean value specifying whether the group passes the filtering. Here because group A does not have a standard deviation greater than 4, it is dropped from the result."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Transformation\n",
    "\n",
    "While aggregation must return a reduced version of the data, transformation can return some transformed version of the full data to recombine.\n",
    "For such a transformation, the output is the same shape as the input.\n",
    "A common example is to center the data by subtracting the group-wise mean:"
   ]
  },
  {
   "metadata": {
    "id": "PYTCt7aM5wom",
    "outputId": "0f7a3d9c-d31d-4d27-d675-4b2be9c9406f"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data1</th>\n",
       "      <th>data2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.5</td>\n",
       "      <td>-3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.5</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.5</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.5</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data1  data2\n",
       "0   -1.5    1.0\n",
       "1   -1.5   -3.5\n",
       "2   -1.5   -3.0\n",
       "3    1.5   -1.0\n",
       "4    1.5    3.5\n",
       "5    1.5    3.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "df.groupby('key').transform(lambda x: x - x.mean())"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### The apply() method\n",
    "\n",
    "The ``apply()`` method lets you apply an arbitrary function to the group results.\n",
    "The function should take a ``DataFrame``, and return either a Pandas object (e.g., ``DataFrame``, ``Series``) or a scalar; the combine operation will be tailored to the type of output returned.\n",
    "\n",
    "For example, here is an ``apply()`` that normalizes the first column by the sum of the second:"
   ]
  },
  {
   "metadata": {
    "id": "wr8q-mF_5woo",
    "outputId": "61262498-80f6-4010-9ef2-de0e95726641"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>df</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>data1</th>\n",
       "      <th>data2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>\n",
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>df.groupby('key').apply(norm_by_data2)</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>data1</th>\n",
       "      <th>data2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>"
      ],
      "text/plain": [
       "df\n",
       "  key  data1  data2\n",
       "0   A      0      5\n",
       "1   B      1      0\n",
       "2   C      2      3\n",
       "3   A      3      3\n",
       "4   B      4      7\n",
       "5   C      5      9\n",
       "\n",
       "df.groupby('key').apply(norm_by_data2)\n",
       "  key     data1  data2\n",
       "0   A  0.000000      5\n",
       "1   B  0.142857      0\n",
       "2   C  0.166667      3\n",
       "3   A  0.375000      3\n",
       "4   B  0.571429      7\n",
       "5   C  0.416667      9"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "def norm_by_data2(x):\n",
    "    # x is a DataFrame of group values\n",
    "    x['data1'] /= x['data2'].sum()\n",
    "    return x\n",
    "\n",
    "display('df', \"df.groupby('key').apply(norm_by_data2)\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "``apply()`` within a ``GroupBy`` is quite flexible: the only criterion is that the function takes a ``DataFrame`` and returns a Pandas object or scalar; what you do in the middle is up to you!"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Specifying the split key\n",
    "\n",
    "In the simple examples presented before, we split the ``DataFrame`` on a single column name.\n",
    "This is just one of many options by which the groups can be defined, and we'll go through some other options for group specification here."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### A list, array, series, or index providing the grouping keys\n",
    "\n",
    "The key can be any series or list with a length matching that of the ``DataFrame``. For example:"
   ]
  },
  {
   "metadata": {
    "id": "2JzQB6tk5woq",
    "outputId": "2d31b3de-499c-4830-9fa2-909d0ed84e62"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>df</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>data1</th>\n",
       "      <th>data2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>\n",
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>df.groupby(L).sum()</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data1</th>\n",
       "      <th>data2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>"
      ],
      "text/plain": [
       "df\n",
       "  key  data1  data2\n",
       "0   A      0      5\n",
       "1   B      1      0\n",
       "2   C      2      3\n",
       "3   A      3      3\n",
       "4   B      4      7\n",
       "5   C      5      9\n",
       "\n",
       "df.groupby(L).sum()\n",
       "   data1  data2\n",
       "0      7     17\n",
       "1      4      3\n",
       "2      4      7"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "L = [0, 1, 0, 1, 2, 0]\n",
    "display('df', 'df.groupby(L).sum()')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Of course, this means there's another, more verbose way of accomplishing the ``df.groupby('key')`` from before:"
  },
  {
   "metadata": {
    "id": "HDq5yFWW5wor",
    "outputId": "4cd55cf7-8c92-437c-a2cf-eae321cb6610"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>df</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>data1</th>\n",
       "      <th>data2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>\n",
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>df.groupby(df['key']).sum()</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data1</th>\n",
       "      <th>data2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>"
      ],
      "text/plain": [
       "df\n",
       "  key  data1  data2\n",
       "0   A      0      5\n",
       "1   B      1      0\n",
       "2   C      2      3\n",
       "3   A      3      3\n",
       "4   B      4      7\n",
       "5   C      5      9\n",
       "\n",
       "df.groupby(df['key']).sum()\n",
       "     data1  data2\n",
       "key              \n",
       "A        3      8\n",
       "B        5      7\n",
       "C        7     12"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "display('df', \"df.groupby(df['key']).sum()\")"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### A dictionary or series mapping index to group\n",
    "\n",
    "Another method is to provide a dictionary that maps index values to the group keys:"
   ]
  },
  {
   "metadata": {
    "id": "CuuEy2U95wos",
    "outputId": "151054b6-f9ff-4139-ce18-b4095e066433"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>df2</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data1</th>\n",
       "      <th>data2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>\n",
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>df2.groupby(mapping).sum()</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data1</th>\n",
       "      <th>data2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>consonant</th>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vowel</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>"
      ],
      "text/plain": [
       "df2\n",
       "     data1  data2\n",
       "key              \n",
       "A        0      5\n",
       "B        1      0\n",
       "C        2      3\n",
       "A        3      3\n",
       "B        4      7\n",
       "C        5      9\n",
       "\n",
       "df2.groupby(mapping).sum()\n",
       "           data1  data2\n",
       "consonant     12     19\n",
       "vowel          3      8"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "df2 = df.set_index('key')\n",
    "mapping = {'A': 'vowel', 'B': 'consonant', 'C': 'consonant'}\n",
    "display('df2', 'df2.groupby(mapping).sum()')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Any Python function\n",
    "\n",
    "Similar to mapping, you can pass any Python function that will input the index value and output the group:"
   ]
  },
  {
   "metadata": {
    "id": "Olwl96zh5wot",
    "outputId": "07f79adb-7d90-4462-845e-d85dc8424755"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>df2</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data1</th>\n",
       "      <th>data2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>\n",
       "<div style=\"float: left; padding: 10px;\">\n",
       "    <p style='font-family:\"Courier New\", Courier, monospace'>df2.groupby(str.lower).mean()</p><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data1</th>\n",
       "      <th>data2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>1.5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>2.5</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>3.5</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>"
      ],
      "text/plain": [
       "df2\n",
       "     data1  data2\n",
       "key              \n",
       "A        0      5\n",
       "B        1      0\n",
       "C        2      3\n",
       "A        3      3\n",
       "B        4      7\n",
       "C        5      9\n",
       "\n",
       "df2.groupby(str.lower).mean()\n",
       "   data1  data2\n",
       "a    1.5    4.0\n",
       "b    2.5    3.5\n",
       "c    3.5    6.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "display('df2', 'df2.groupby(str.lower).mean()')"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### A list of valid keys\n",
    "\n",
    "Further, any of the preceding key choices can be combined to group on a multi-index:"
   ]
  },
  {
   "metadata": {
    "id": "yvy4I4Lk5wou",
    "outputId": "c09548fd-933d-4074-a173-da704662c33f"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>data1</th>\n",
       "      <th>data2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <th>vowel</th>\n",
       "      <td>1.5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <th>consonant</th>\n",
       "      <td>2.5</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <th>consonant</th>\n",
       "      <td>3.5</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             data1  data2\n",
       "a vowel        1.5    4.0\n",
       "b consonant    2.5    3.5\n",
       "c consonant    3.5    6.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "df2.groupby([str.lower, mapping]).mean()"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Grouping example\n",
    "\n",
    "As an example of this, in a couple lines of Python code we can put all these together and count discovered planets by method and by decade:"
   ]
  },
  {
   "metadata": {
    "id": "EDsS5ktX5wov",
    "outputId": "759859c4-cedc-4b55-d37c-0b33fd59d9b8"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>decade</th>\n",
       "      <th>1980s</th>\n",
       "      <th>1990s</th>\n",
       "      <th>2000s</th>\n",
       "      <th>2010s</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Astrometry</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eclipse Timing Variations</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Imaging</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Microlensing</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orbital Brightness Modulation</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pulsar Timing</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pulsation Timing Variations</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Radial Velocity</th>\n",
       "      <td>1.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>424.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transit</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>712.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transit Timing Variations</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "decade                         1980s  1990s  2000s  2010s\n",
       "method                                                   \n",
       "Astrometry                       0.0    0.0    0.0    2.0\n",
       "Eclipse Timing Variations        0.0    0.0    5.0   10.0\n",
       "Imaging                          0.0    0.0   29.0   21.0\n",
       "Microlensing                     0.0    0.0   12.0   15.0\n",
       "Orbital Brightness Modulation    0.0    0.0    0.0    5.0\n",
       "Pulsar Timing                    0.0    9.0    1.0    1.0\n",
       "Pulsation Timing Variations      0.0    0.0    1.0    0.0\n",
       "Radial Velocity                  1.0   52.0  475.0  424.0\n",
       "Transit                          0.0    0.0   64.0  712.0\n",
       "Transit Timing Variations        0.0    0.0    0.0    9.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "decade = 10 * (planets['year'] // 10)\n",
    "decade = decade.astype(str) + 's'\n",
    "decade.name = 'decade'\n",
    "planets.groupby(['method', decade])['number'].sum().unstack().fillna(0)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This shows the power of combining many of the operations we've discussed up to this point when looking at realistic datasets.\n",
    "We immediately gain a coarse understanding of when and how planets have been discovered over the past several decades!\n",
    "\n",
    "Here I would suggest digging into these few lines of code, and evaluating the individual steps to make sure you understand exactly what they are doing to the result.\n",
    "It's certainly a somewhat complicated example, but understanding these pieces will give you the means to similarly explore your own data."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<!--NAVIGATION-->\n",
    "< [Combining Datasets: Merge and Join](03.07-Merge-and-Join.ipynb) | [Contents](Index.ipynb) | [Pivot Tables](03.09-Pivot-Tables.ipynb) >\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.08-Aggregation-and-Grouping.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Exercices : Aggregation and grouping\n",
    "\n",
    "### Aggregation"
   ]
  },
  {
   "metadata": {
    "id": "x1HFuq5BAIKV",
    "outputId": "bc6dfd52-277f-4052-a922-9b08609e2582",
    "ExecuteTime": {
     "end_time": "2025-02-06T08:49:16.527548Z",
     "start_time": "2025-02-06T08:49:16.498747Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Earphones  Laptop  Cell Phone  Power Bank\n",
       "Week 1        150      50         300         400\n",
       "Week 2        200      60         320         420\n",
       "Week 3        190      55         310         410\n",
       "Week 4        250      65         305         430\n",
       "Week 5        300      80         315         450"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Earphones</th>\n",
       "      <th>Laptop</th>\n",
       "      <th>Cell Phone</th>\n",
       "      <th>Power Bank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Week 1</th>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>300</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Week 2</th>\n",
       "      <td>200</td>\n",
       "      <td>60</td>\n",
       "      <td>320</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Week 3</th>\n",
       "      <td>190</td>\n",
       "      <td>55</td>\n",
       "      <td>310</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Week 4</th>\n",
       "      <td>250</td>\n",
       "      <td>65</td>\n",
       "      <td>305</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Week 5</th>\n",
       "      <td>300</td>\n",
       "      <td>80</td>\n",
       "      <td>315</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "#  Aggregation Functions in Pandas with Realistic Product Data\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Consider Weekly sales of different products\n",
    "data = {\n",
    "    'Earphones': [150, 200, 190, 250, 300],\n",
    "    'Laptop': [50, 60, 55, 65, 80],\n",
    "    'Cell Phone': [300, 320, 310, 305, 315],\n",
    "    'Power Bank': [400, 420, 410, 430, 450]\n",
    "}\n",
    "\n",
    "# Index represents the week numbers (Week 1 to Week 5)\n",
    "index = ['Week 1', 'Week 2', 'Week 3', 'Week 4', 'Week 5']\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data, index=index)\n",
    "df\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "3) Answer following questions with code:\\\n",
    "   a) Get the total amount of products sold for each week\\\n",
    "   b) Get the total amount of products sold for each category\\\n",
    "   c) Get the total amount of sold products\n"
   ]
  },
  {
   "metadata": {
    "id": "F6PHAl9KAIKX",
    "outputId": "a586452c-d1d6-40b9-9db0-565f3f7a7f6a",
    "ExecuteTime": {
     "end_time": "2025-02-06T08:49:16.693814Z",
     "start_time": "2025-02-06T08:49:16.682794Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of sales data along products:\n",
      "Earphones     1090\n",
      "Laptop         310\n",
      "Cell Phone    1550\n",
      "Power Bank    2110\n",
      "dtype: int64\n",
      "Count of sales data along weeks:\n",
      "Week 1     900\n",
      "Week 2    1000\n",
      "Week 3     965\n",
      "Week 4    1050\n",
      "Week 5    1145\n",
      "dtype: int64\n",
      "Total number of products sold:\n",
      "5060\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "# Hint: Use df.sum() with axis=0 and axis=1.\n",
    "\n",
    "#SOLUTION_START\n",
    "print(f\"Count of sales data along products:\\n{df.sum(axis=0)}\")\n",
    "print(f\"Count of sales data along weeks:\\n{df.sum(axis=1)}\")\n",
    "print(f\"Total number of products sold:\\n{df.sum(axis=1).sum()}\")\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "2) a) Calculate the mean of sold products across weeks\\\n",
    "   b) Calculate the median for each week\\\n",
    "   c) Calculate the overall mean of products sold per week"
   ]
  },
  {
   "metadata": {
    "id": "0HNJYuVSAIKY",
    "outputId": "cd7450da-9cd8-4774-83a4-9d73584cb4e5",
    "ExecuteTime": {
     "end_time": "2025-02-06T08:49:16.890193Z",
     "start_time": "2025-02-06T08:49:16.863056Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean sales for each product across weeks:\n",
      "Earphones     218.0\n",
      "Laptop         62.0\n",
      "Cell Phone    310.0\n",
      "Power Bank    422.0\n",
      "dtype: float64\n",
      "Median sales for each week across products:\n",
      "Week 1    225.0\n",
      "Week 2    260.0\n",
      "Week 3    250.0\n",
      "Week 4    277.5\n",
      "Week 5    307.5\n",
      "dtype: float64\n",
      "Mean sales overall:253.0\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "mean_sales = df.mean(axis=0)\n",
    "print(f\"Mean sales for each product across weeks:\\n{df.mean(axis=0)}\")\n",
    "median_weekly_sales = df.median(axis=1)\n",
    "print(f\"Median sales for each week across products:\\n{df.median(axis=1)}\")\n",
    "#Overall median\n",
    "total_mean_sales = df.mean(axis=0).mean()\n",
    "print(f\"Mean sales overall:{df.mean(axis=0).mean()}\")\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "3) a) What was the maximum number of items sold in one week for Cell Phone's\\\n",
    "   b) What is the minimum number of items sold in week 3?\\\n",
    "   c) What are the minimum sales for each week across products\\\n",
    "   d) What are the maximum sales for each product across weeks"
   ]
  },
  {
   "metadata": {
    "id": "1RTzVXLlAIKY",
    "outputId": "7b3585eb-e03c-4b56-b39e-a097b60d5448",
    "ExecuteTime": {
     "end_time": "2025-02-06T08:49:17.233984Z",
     "start_time": "2025-02-06T08:49:17.217362Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sales for cell phones across weeks:320\n",
      "Min sales for week 3:55\n",
      "Minimum sales for each week across products:\n",
      "Week 1    50\n",
      "Week 2    60\n",
      "Week 3    55\n",
      "Week 4    65\n",
      "Week 5    80\n",
      "dtype: int64\n",
      "Maximum sales for each week across products:\n",
      "Earphones     300\n",
      "Laptop         80\n",
      "Cell Phone    320\n",
      "Power Bank    450\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "print(f\"Maximum sales for cell phones across weeks:{df['Cell Phone'].max()}\")\n",
    "print(f\"Min sales for week 3:{df.loc[\"Week 3\"].min()}\")\n",
    "print(f\"Minimum sales for each week across products:\\n{df.min(axis=1)}\")\n",
    "print(f\"Maximum sales for each week across products:\\n{df.max(axis=0)}\")\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "5) a) Count the number of items in a row\\\n",
    "   b) Count the number of itams in a column\n"
   ]
  },
  {
   "metadata": {
    "id": "0IylRm2SAIKa",
    "outputId": "978535b4-b1e8-4122-fec9-58af60c52db8",
    "ExecuteTime": {
     "end_time": "2025-02-06T08:49:17.627802Z",
     "start_time": "2025-02-06T08:49:17.597877Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of sales data along products (axis=0):\n",
      "Earphones     5\n",
      "Laptop        5\n",
      "Cell Phone    5\n",
      "Power Bank    5\n",
      "dtype: int64\n",
      "Count of sales data along weeks (axis=1):\n",
      "Week 1    4\n",
      "Week 2    4\n",
      "Week 3    4\n",
      "Week 4    4\n",
      "Week 5    4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "print(f\"Count of sales data along products (axis=0):\\n{df.count(axis=0)}\")\n",
    "print(f\"Count of sales data along weeks (axis=1):\\n{df.count(axis=1)}\")\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Grouping\n",
    "\n",
    "First consider the dataframe df"
   ]
  },
  {
   "metadata": {
    "id": "alnULOOBAIKa",
    "outputId": "4d3a1c7c-9d2b-4eba-8bee-003a8e3fdc73",
    "ExecuteTime": {
     "end_time": "2025-02-06T08:49:17.788131Z",
     "start_time": "2025-02-06T08:49:17.757963Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "productName    40\n",
       "week           40\n",
       "amount_sold    40\n",
       "price          40\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Original data with computer-related products\n",
    "data = {\n",
    "    'productName': ['Laptop', 'Monitor', 'Mouse', 'Keyboard', 'External Hard Drive'] * 4,\n",
    "    'week': [1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4],\n",
    "    'amount_sold': [120, 80, 50, 40, 90, 130, 85, 60, 55, 95, 125, 90, 70, 45, 100, 140, 100, 65, 50, 110],\n",
    "    'price': [999.99, 199.99, 25.99, 49.99, 79.99, 999.99, 199.99, 25.99, 49.99, 79.99, 999.99, 199.99, 25.99, 49.99, 79.99, 999.99, 199.99, 25.99, 49.99, 79.99]\n",
    "}\n",
    "\n",
    "# Additional data\n",
    "additional_data = {\n",
    "    'productName': ['Graphics Card', 'Gaming Chair', 'Headset', 'Webcam', 'Router'] * 4,\n",
    "    'week': [1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4],\n",
    "    'amount_sold': [30, 15, 60, 25, 45, 50, 20, 75, 35, 40, 60, 25, 80, 30, 50, 65, 35, 85, 40, 55],\n",
    "    'price': [599.99, 150.99, 49.99, 89.99, 129.99, 599.99, 150.99, 49.99, 89.99, 129.99, 599.99, 150.99, 49.99, 89.99, 129.99, 599.99, 150.99, 49.99, 89.99, 129.99]\n",
    "}\n",
    "\n",
    "# Creating DataFrames\n",
    "df_computer = pd.DataFrame(data)\n",
    "df_additional = pd.DataFrame(additional_data)\n",
    "\n",
    "# Concatenating the new data with the existing DataFrame\n",
    "df_combined = pd.concat([df_computer, df_additional], ignore_index=True)\n",
    "\n",
    "# Shuffling the rows of the combined DataFrame\n",
    "df = df_combined.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Displaying the shuffled DataFrame\n",
    "df.count(axis=0)\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "6) a) Calculate the total number of units sold for each product across all weeks.\\\n",
    "   b) Calculate the average price for each product.\\\n",
    "   c) Calculate the total revenue for each week."
   ]
  },
  {
   "metadata": {
    "id": "l_LldLd9AIKb",
    "outputId": "72d9b19a-2b74-4abd-c9f8-d963e3e4fd3e",
    "ExecuteTime": {
     "end_time": "2025-02-06T08:49:17.995950Z",
     "start_time": "2025-02-06T08:49:17.969456Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "productName\n",
      "External Hard Drive    395\n",
      "Gaming Chair            95\n",
      "Graphics Card          205\n",
      "Headset                300\n",
      "Keyboard               190\n",
      "Laptop                 515\n",
      "Monitor                355\n",
      "Mouse                  245\n",
      "Router                 190\n",
      "Webcam                 130\n",
      "Name: amount_sold, dtype: int64\n",
      "productName\n",
      "External Hard Drive     79.99\n",
      "Gaming Chair           150.99\n",
      "Graphics Card          599.99\n",
      "Headset                 49.99\n",
      "Keyboard                49.99\n",
      "Laptop                 999.99\n",
      "Monitor                199.99\n",
      "Mouse                   25.99\n",
      "Router                 129.99\n",
      "Webcam                  89.99\n",
      "Name: price, dtype: float64\n",
      "week\n",
      "1    177859.45\n",
      "2    204023.55\n",
      "3    208038.25\n",
      "4    232267.55\n",
      "Name: revenue, dtype: float64\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "# a. Grouping by productName to calculate total units sold per product\n",
    "print(df.groupby('productName')['amount_sold'].sum())\n",
    "# b.Grouping by productName to calculate average price\n",
    "print(df.groupby('productName')['price'].mean())\n",
    "# c.\n",
    "# Creating a new column for revenue\n",
    "df['revenue'] = df['amount_sold'] * df['price']\n",
    "# Grouping by week to calculate total revenue per week\n",
    "print(df.groupby('week')['revenue'].sum())\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "7) Find the product that sold the most units in each week.\n"
  },
  {
   "metadata": {
    "id": "3dJlcfqrAIKb",
    "outputId": "e6744091-2eb6-449b-eb75-c58009dae944",
    "ExecuteTime": {
     "end_time": "2025-02-06T08:49:18.183988Z",
     "start_time": "2025-02-06T08:49:18.164159Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    week productName  amount_sold\n",
      "8      1      Laptop          120\n",
      "14     2      Laptop          130\n",
      "21     3      Laptop          125\n",
      "22     4      Laptop          140\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "# Grouping by week to find the product with the maximum amount sold\n",
    "df_max_sold_per_week = df.loc[df.groupby('week')['amount_sold'].idxmax()]\n",
    "print(df_max_sold_per_week[['week', 'productName', 'amount_sold']])\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "8) Calculate the average number of units sold per product."
  },
  {
   "metadata": {
    "id": "UH-xdrwGAIKc",
    "outputId": "163ede38-1c26-42f9-935f-97667bb04fc0",
    "ExecuteTime": {
     "end_time": "2025-02-06T08:49:18.449664Z",
     "start_time": "2025-02-06T08:49:18.439650Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "productName\n",
      "External Hard Drive     98.75\n",
      "Gaming Chair            23.75\n",
      "Graphics Card           51.25\n",
      "Headset                 75.00\n",
      "Keyboard                47.50\n",
      "Laptop                 128.75\n",
      "Monitor                 88.75\n",
      "Mouse                   61.25\n",
      "Router                  47.50\n",
      "Webcam                  32.50\n",
      "Name: amount_sold, dtype: float64\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "# Grouping by productName to calculate average amount sold per product p\n",
    "df_avg_sold_per_product = df.groupby(['productName'])['amount_sold'].mean()\n",
    "print(df_avg_sold_per_product)\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "9) For each product provide a list of the minimum amount sold, the average and the maximum amount sold\n",
    "\n"
   ]
  },
  {
   "metadata": {
    "id": "QsRMpdl0AIKc",
    "outputId": "db659017-7e6e-47f0-c4b3-0ba0cbb25169",
    "ExecuteTime": {
     "end_time": "2025-02-06T08:49:18.628136Z",
     "start_time": "2025-02-06T08:49:18.603283Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                    amount_sold             \n",
       "                            min    mean  max\n",
       "productName                                 \n",
       "External Hard Drive          90   98.75  110\n",
       "Gaming Chair                 15   23.75   35\n",
       "Graphics Card                30   51.25   65\n",
       "Headset                      60   75.00   85\n",
       "Keyboard                     40   47.50   55\n",
       "Laptop                      120  128.75  140\n",
       "Monitor                      80   88.75  100\n",
       "Mouse                        50   61.25   70\n",
       "Router                       40   47.50   55\n",
       "Webcam                       25   32.50   40"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">amount_sold</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>productName</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>External Hard Drive</th>\n",
       "      <td>90</td>\n",
       "      <td>98.75</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaming Chair</th>\n",
       "      <td>15</td>\n",
       "      <td>23.75</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Graphics Card</th>\n",
       "      <td>30</td>\n",
       "      <td>51.25</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Headset</th>\n",
       "      <td>60</td>\n",
       "      <td>75.00</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Keyboard</th>\n",
       "      <td>40</td>\n",
       "      <td>47.50</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Laptop</th>\n",
       "      <td>120</td>\n",
       "      <td>128.75</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monitor</th>\n",
       "      <td>80</td>\n",
       "      <td>88.75</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mouse</th>\n",
       "      <td>50</td>\n",
       "      <td>61.25</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Router</th>\n",
       "      <td>40</td>\n",
       "      <td>47.50</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Webcam</th>\n",
       "      <td>25</td>\n",
       "      <td>32.50</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "df[['productName','amount_sold']].groupby('productName').aggregate(['min', 'mean', 'max'])\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "10) Provide a table with the productnames and the minimum price for that product the total amount sold and the total revenue for that product"
  },
  {
   "metadata": {
    "id": "165e1cAcAIKc",
    "outputId": "01116835-81a9-4fe4-cfe0-a99196ed2e91",
    "ExecuteTime": {
     "end_time": "2025-02-06T08:49:18.790380Z",
     "start_time": "2025-02-06T08:49:18.771962Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                      price  amount_sold    revenue\n",
       "productName                                        \n",
       "External Hard Drive   79.99          395   31596.05\n",
       "Gaming Chair         150.99           95   14344.05\n",
       "Graphics Card        599.99          205  122997.95\n",
       "Headset               49.99          300   14997.00\n",
       "Keyboard              49.99          190    9498.10\n",
       "Laptop               999.99          515  514994.85\n",
       "Monitor              199.99          355   70996.45\n",
       "Mouse                 25.99          245    6367.55\n",
       "Router               129.99          190   24698.10\n",
       "Webcam                89.99          130   11698.70"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>amount_sold</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>productName</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>External Hard Drive</th>\n",
       "      <td>79.99</td>\n",
       "      <td>395</td>\n",
       "      <td>31596.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaming Chair</th>\n",
       "      <td>150.99</td>\n",
       "      <td>95</td>\n",
       "      <td>14344.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Graphics Card</th>\n",
       "      <td>599.99</td>\n",
       "      <td>205</td>\n",
       "      <td>122997.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Headset</th>\n",
       "      <td>49.99</td>\n",
       "      <td>300</td>\n",
       "      <td>14997.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Keyboard</th>\n",
       "      <td>49.99</td>\n",
       "      <td>190</td>\n",
       "      <td>9498.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Laptop</th>\n",
       "      <td>999.99</td>\n",
       "      <td>515</td>\n",
       "      <td>514994.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monitor</th>\n",
       "      <td>199.99</td>\n",
       "      <td>355</td>\n",
       "      <td>70996.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mouse</th>\n",
       "      <td>25.99</td>\n",
       "      <td>245</td>\n",
       "      <td>6367.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Router</th>\n",
       "      <td>129.99</td>\n",
       "      <td>190</td>\n",
       "      <td>24698.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Webcam</th>\n",
       "      <td>89.99</td>\n",
       "      <td>130</td>\n",
       "      <td>11698.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "df.groupby('productName').aggregate({'price':'min',\n",
    "                                     'amount_sold':'sum',\n",
    "                                     'revenue':'sum'}\n",
    "                                     )\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "11) Only show the productnames which have  sold less than 150 in total over all the dataset and show also the amount_sold in total"
  },
  {
   "metadata": {
    "id": "WtHcWglMAIKd",
    "outputId": "db39360e-4801-40f8-a09b-4b8ccba8b828",
    "ExecuteTime": {
     "end_time": "2025-02-06T08:49:19.109268Z",
     "start_time": "2025-02-06T08:49:19.083974Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              amount_sold\n",
       "productName              \n",
       "Gaming Chair           95\n",
       "Webcam                130"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount_sold</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>productName</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gaming Chair</th>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Webcam</th>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "def filter_func(x):\n",
    "    return x['amount_sold'].sum() < 150\n",
    "\n",
    "display(df.groupby('productName').filter(filter_func).groupby('productName').aggregate({'amount_sold':'sum'}))\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T08:49:19.660955Z",
     "start_time": "2025-02-06T08:49:19.656610Z"
    },
    "id": "zhu3_llGujLV"
   },
   "cell_type": "code",
   "outputs": [],
   "source": "",
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<!--BOOK_INFORMATION-->\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"figures/PDSH-cover-small.png\">\n",
    "\n",
    "*This notebook contains an excerpt from the [Python Data Science Handbook](http://shop.oreilly.com/product/0636920034919.do) by Jake VanderPlas; the content is available [on GitHub](https://github.com/jakevdp/PythonDataScienceHandbook).*\n",
    "\n",
    "*The text is released under the [CC-BY-NC-ND license](https://creativecommons.org/licenses/by-nc-nd/3.0/us/legalcode), and code is released under the [MIT license](https://opensource.org/licenses/MIT). If you find this content useful, please consider supporting the work by [buying the book](http://shop.oreilly.com/product/0636920034919.do)!*"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<!--NAVIGATION-->\n",
    "< [Pivot Tables](03.09-Pivot-Tables.ipynb) | [Contents](Index.ipynb) | [Working with Time Series](03.11-Working-with-Time-Series.ipynb) >\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.10-Working-With-Strings.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Vectorized String Operations"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "One strength of Python is its relative ease in handling and manipulating string data.\n",
    "Pandas builds on this and provides a comprehensive set of *vectorized string operations* that become an essential piece of the type of munging required when working with (read: cleaning up) real-world data.\n",
    "In this section, we'll walk through some of the Pandas string operations, and then take a look at using them to partially clean up a very messy dataset of recipes collected from the Internet."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Introducing Pandas String Operations\n",
    "\n",
    "We saw in previous sections how tools like NumPy and Pandas generalize arithmetic operations so that we can easily and quickly perform the same operation on many array elements. For example:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T16:03:58.022862Z",
     "start_time": "2025-02-04T16:03:57.701611Z"
    },
    "id": "1F_iazNu5za7",
    "outputId": "211ecc99-fc3e-443e-e563-b8b536a9cb82"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  6, 10, 14, 22, 26])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "x = np.array([2, 3, 5, 7, 11, 13])\n",
    "x * 2"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This *vectorization* of operations simplifies the syntax of operating on arrays of data: we no longer have to worry about the size or shape of the array, but just about what operation we want done.\n",
    "For arrays of strings, NumPy does not provide such simple access, and thus you're stuck using a more verbose loop syntax:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T16:03:58.048412Z",
     "start_time": "2025-02-04T16:03:58.039875Z"
    },
    "id": "z0uK_okr5za9",
    "outputId": "356e1841-ac54-4de3-a0c3-fda7a67673e4"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Peter', 'Paul', 'Mary', 'Guido']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "data = ['peter', 'Paul', 'MARY', 'gUIDO']\n",
    "[s.capitalize() for s in data]"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This is perhaps sufficient to work with some data, but it will break if there are any missing values.\n",
    "For example:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T16:03:59.738788Z",
     "start_time": "2025-02-04T16:03:59.313945Z"
    },
    "id": "LCh_iYSv5za-",
    "outputId": "9b8cc84c-188b-4f8b-b3cd-2e58344712d8"
   },
   "cell_type": "code",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'capitalize'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpeter\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPaul\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMARY\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgUIDO\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m----> 2\u001B[0m [\u001B[43ms\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcapitalize\u001B[49m() \u001B[38;5;28;01mfor\u001B[39;00m s \u001B[38;5;129;01min\u001B[39;00m data]\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'capitalize'"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "data = ['peter', 'Paul', None, 'MARY', 'gUIDO']\n",
    "[s.capitalize() for s in data]"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Pandas includes features to address both this need for vectorized string operations and for correctly handling missing data via the ``str`` attribute of Pandas Series and Index objects containing strings.\n",
    "So, for example, suppose we create a Pandas Series with this data:"
   ]
  },
  {
   "metadata": {
    "id": "5e24A4ev5za-",
    "outputId": "6138e499-3dc1-4cf7-aac4-e9950d0c8977"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    peter\n",
       "1     Paul\n",
       "2     None\n",
       "3     MARY\n",
       "4    gUIDO\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "names = pd.Series(data)\n",
    "names"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can now call a single method that will capitalize all the entries, while skipping over any missing values:"
  },
  {
   "metadata": {
    "id": "7uk2K0h45za_",
    "outputId": "ccb681bd-b511-46fd-fb60-315bc5fc46c8"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Peter\n",
       "1     Paul\n",
       "2     None\n",
       "3     Mary\n",
       "4    Guido\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "names.str.capitalize()"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Using tab completion on this ``str`` attribute will list all the vectorized string methods available to Pandas."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Tables of Pandas String Methods\n",
    "\n",
    "If you have a good understanding of string manipulation in Python, most of Pandas string syntax is intuitive enough that it's probably sufficient to just list a table of available methods; we will start with that here, before diving deeper into a few of the subtleties.\n",
    "The examples in this section use the following series of names:"
   ]
  },
  {
   "metadata": {
    "collapsed": true,
    "id": "ibbzZL1-5za_"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "monte = pd.Series(['Graham Chapman', 'John Cleese', 'Terry Gilliam',\n",
    "                   'Eric Idle', 'Terry Jones', 'Michael Palin'])"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Methods similar to Python string methods\n",
    "Nearly all Python's built-in string methods are mirrored by a Pandas vectorized string method. Here is a list of Pandas ``str`` methods that mirror Python string methods:\n",
    "\n",
    "|             |                  |                  |                  |\n",
    "|-------------|------------------|------------------|------------------|\n",
    "|``len()``    | ``lower()``      | ``translate()``  | ``islower()``    |\n",
    "|``ljust()``  | ``upper()``      | ``startswith()`` | ``isupper()``    |\n",
    "|``rjust()``  | ``find()``       | ``endswith()``   | ``isnumeric()``  |\n",
    "|``center()`` | ``rfind()``      | ``isalnum()``    | ``isdecimal()``  |\n",
    "|``zfill()``  | ``index()``      | ``isalpha()``    | ``split()``      |\n",
    "|``strip()``  | ``rindex()``     | ``isdigit()``    | ``rsplit()``     |\n",
    "|``rstrip()`` | ``capitalize()`` | ``isspace()``    | ``partition()``  |\n",
    "|``lstrip()`` |  ``swapcase()``  |  ``istitle()``   | ``rpartition()`` |\n",
    "\n",
    "Notice that these have various return values. Some, like ``lower()``, return a series of strings:"
   ]
  },
  {
   "metadata": {
    "id": "L1WsI-sB5zbA",
    "outputId": "e3d75366-9d71-4431-ab99-79775358169f"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    graham chapman\n",
       "1       john cleese\n",
       "2     terry gilliam\n",
       "3         eric idle\n",
       "4       terry jones\n",
       "5     michael palin\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "monte.str.lower()"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "But some others return numbers:"
  },
  {
   "metadata": {
    "id": "66DhZsV35zbB",
    "outputId": "dc4c3d40-c214-4a66-f559-1eb347a34ebf"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    14\n",
       "1    11\n",
       "2    13\n",
       "3     9\n",
       "4    11\n",
       "5    13\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "monte.str.len()"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Or Boolean values:"
  },
  {
   "metadata": {
    "id": "g-TBusOA5zbB",
    "outputId": "d714bcd4-56af-4042-956f-dd30e3d982a3"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2     True\n",
       "3    False\n",
       "4     True\n",
       "5    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "monte.str.startswith('T')"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Still others return lists or other compound values for each element:"
  },
  {
   "metadata": {
    "id": "cVzP53xj5zbC",
    "outputId": "f56b3b0a-d9d5-4f7a-8003-b4521f760c67"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Graham, Chapman]\n",
       "1       [John, Cleese]\n",
       "2     [Terry, Gilliam]\n",
       "3         [Eric, Idle]\n",
       "4       [Terry, Jones]\n",
       "5     [Michael, Palin]\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "monte.str.split()"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We'll see further manipulations of this kind of series-of-lists object as we continue our discussion."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Methods using regular expressions\n",
    "\n",
    "In addition, there are several methods that accept regular expressions to examine the content of each string element, and follow some of the API conventions of Python's built-in ``re`` module:\n",
    "\n",
    "| Method | Description |\n",
    "|--------|-------------|\n",
    "| ``match()`` | Call ``re.match()`` on each element, returning a boolean. |\n",
    "| ``extract()`` | Call ``re.match()`` on each element, returning matched groups as strings.|\n",
    "| ``findall()`` | Call ``re.findall()`` on each element |\n",
    "| ``replace()`` | Replace occurrences of pattern with some other string|\n",
    "| ``contains()`` | Call ``re.search()`` on each element, returning a boolean |\n",
    "| ``count()`` | Count occurrences of pattern|\n",
    "| ``split()``   | Equivalent to ``str.split()``, but accepts regexps |\n",
    "| ``rsplit()`` | Equivalent to ``str.rsplit()``, but accepts regexps |"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "With these, you can do a wide range of interesting operations.\n",
    "For example, we can extract the first name from each by asking for a contiguous group of characters at the beginning of each element:"
   ]
  },
  {
   "metadata": {
    "id": "qy4OWUqm5zbD",
    "outputId": "8d05f7bf-93a7-4355-d72b-bcd1fdec336e"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Graham\n",
       "1       John\n",
       "2      Terry\n",
       "3       Eric\n",
       "4      Terry\n",
       "5    Michael\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "monte.str.extract('([A-Za-z]+)', expand=False)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Or we can do something more complicated, like finding all names that start and end with a consonant, making use of the start-of-string (``^``) and end-of-string (``$``) regular expression characters:"
  },
  {
   "metadata": {
    "id": "QdILE1KU5zbE",
    "outputId": "ce473b14-0512-4e6f-8192-5e36cc2eff5e"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Graham Chapman]\n",
       "1                  []\n",
       "2     [Terry Gilliam]\n",
       "3                  []\n",
       "4       [Terry Jones]\n",
       "5     [Michael Palin]\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "monte.str.findall(r'^[^AEIOU].*[^aeiou]$')"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The ability to concisely apply regular expressions across ``Series`` or ``Dataframe`` entries opens up many possibilities for analysis and cleaning of data."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Miscellaneous methods\n",
    "Finally, there are some miscellaneous methods that enable other convenient operations:\n",
    "\n",
    "| Method | Description |\n",
    "|--------|-------------|\n",
    "| ``get()`` | Index each element |\n",
    "| ``slice()`` | Slice each element|\n",
    "| ``slice_replace()`` | Replace slice in each element with passed value|\n",
    "| ``cat()``      | Concatenate strings|\n",
    "| ``repeat()`` | Repeat values |\n",
    "| ``normalize()`` | Return Unicode form of string |\n",
    "| ``pad()`` | Add whitespace to left, right, or both sides of strings|\n",
    "| ``wrap()`` | Split long strings into lines with length less than a given width|\n",
    "| ``join()`` | Join strings in each element of the Series with passed separator|\n",
    "| ``get_dummies()`` | extract dummy variables as a dataframe |"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Vectorized item access and slicing\n",
    "\n",
    "The ``get()`` and ``slice()`` operations, in particular, enable vectorized element access from each array.\n",
    "For example, we can get a slice of the first three characters of each array using ``str.slice(0, 3)``.\n",
    "Note that this behavior is also available through Python's normal indexing syntax–for example, ``df.str.slice(0, 3)`` is equivalent to ``df.str[0:3]``:"
   ]
  },
  {
   "metadata": {
    "id": "G78NOh745zbF",
    "outputId": "d8161962-f6bd-4dea-a6cf-537f8bf87b26"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Gra\n",
       "1    Joh\n",
       "2    Ter\n",
       "3    Eri\n",
       "4    Ter\n",
       "5    Mic\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "monte.str[0:3]"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Indexing via ``df.str.get(i)`` and ``df.str[i]`` is likewise similar.\n",
    "\n",
    "These ``get()`` and ``slice()`` methods also let you access elements of arrays returned by ``split()``.\n",
    "For example, to extract the last name of each entry, we can combine ``split()`` and ``get()``:"
   ]
  },
  {
   "metadata": {
    "id": "73zcZFHy5zbG",
    "outputId": "5e5a39e1-fdde-42fc-c707-2e4a87f83c8c"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Chapman\n",
       "1     Cleese\n",
       "2    Gilliam\n",
       "3       Idle\n",
       "4      Jones\n",
       "5      Palin\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "monte.str.split().str.get(-1)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Indicator variables\n",
    "\n",
    "Another method that requires a bit of extra explanation is the ``get_dummies()`` method.\n",
    "This is useful when your data has a column containing some sort of coded indicator.\n",
    "For example, we might have a dataset that contains information in the form of codes, such as A=\"born in America,\" B=\"born in the United Kingdom,\" C=\"likes cheese,\" D=\"likes spam\":"
   ]
  },
  {
   "metadata": {
    "id": "lQ5WAmKn5zbG",
    "outputId": "dd50fb83-b91a-449a-9364-100ee7c1dc8e"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>info</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B|C|D</td>\n",
       "      <td>Graham Chapman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B|D</td>\n",
       "      <td>John Cleese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A|C</td>\n",
       "      <td>Terry Gilliam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B|D</td>\n",
       "      <td>Eric Idle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B|C</td>\n",
       "      <td>Terry Jones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B|C|D</td>\n",
       "      <td>Michael Palin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    info            name\n",
       "0  B|C|D  Graham Chapman\n",
       "1    B|D     John Cleese\n",
       "2    A|C   Terry Gilliam\n",
       "3    B|D       Eric Idle\n",
       "4    B|C     Terry Jones\n",
       "5  B|C|D   Michael Palin"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "full_monte = pd.DataFrame({'name': monte,\n",
    "                           'info': ['B|C|D', 'B|D', 'A|C',\n",
    "                                    'B|D', 'B|C', 'B|C|D']})\n",
    "full_monte"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The ``get_dummies()`` routine lets you quickly split-out these indicator variables into a ``DataFrame``:"
  },
  {
   "metadata": {
    "id": "Y_rH4jRi5zbL",
    "outputId": "8c59d657-bff7-4625-aabf-ecb589a0d51d"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B  C  D\n",
       "0  0  1  1  1\n",
       "1  0  1  0  1\n",
       "2  1  0  1  0\n",
       "3  0  1  0  1\n",
       "4  0  1  1  0\n",
       "5  0  1  1  1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "full_monte['info'].str.get_dummies('|')"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "With these operations as building blocks, you can construct an endless range of string processing procedures when cleaning your data.\n",
    "\n",
    "We won't dive further into these methods here, but I encourage you to read through [\"Working with Text Data\"](http://pandas.pydata.org/pandas-docs/stable/text.html) in the Pandas online documentation, or to refer to the resources listed in [Further Resources](03.13-Further-Resources.ipynb)."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Example: Recipe Database\n",
    "\n",
    "These vectorized string operations become most useful in the process of cleaning up messy, real-world data.\n",
    "Here I'll walk through an example of that, using an open recipe database compiled from various sources on the Web.\n",
    "Our goal will be to parse the recipe data into ingredient lists, so we can quickly find a recipe based on some ingredients we have on hand.\n",
    "\n",
    "The scripts used to compile this can be found at https://github.com/fictivekin/openrecipes, and the link to the current version of the database is found there as well.\n",
    "\n",
    "As of Spring 2016, this database is about 30 MB, and can be downloaded and unzipped with these commands:"
   ]
  },
  {
   "metadata": {
    "id": "vRISwWCu5zbM"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# !curl -O http://openrecipes.s3.amazonaws.com/recipeitems-latest.json.gz\n",
    "# !gunzip recipeitems-latest.json.gz"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The database is in JSON format, so we will try ``pd.read_json`` to read it:"
  },
  {
   "metadata": {
    "id": "fHlgnVb55zbM",
    "outputId": "6bcab84a-1805-444a-9e78-f6ec10075463"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValueError: Trailing data\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "try:\n",
    "    recipes = pd.read_json('recipeitems-latest.json')\n",
    "except ValueError as e:\n",
    "    print(\"ValueError:\", e)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Oops! We get a ``ValueError`` mentioning that there is \"trailing data.\"\n",
    "Searching for the text of this error on the Internet, it seems that it's due to using a file in which *each line* is itself a valid JSON, but the full file is not.\n",
    "Let's check if this interpretation is true:"
   ]
  },
  {
   "metadata": {
    "id": "KkTrwBTA5zbN",
    "outputId": "07bf6af4-0c55-43b3-a784-858be0276895"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 12)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "with open('recipeitems-latest.json') as f:\n",
    "    line = f.readline()\n",
    "pd.read_json(line).shape"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Yes, apparently each line is a valid JSON, so we'll need to string them together.\n",
    "One way we can do this is to actually construct a string representation containing all these JSON entries, and then load the whole thing with ``pd.read_json``:"
   ]
  },
  {
   "metadata": {
    "collapsed": true,
    "id": "gFIgI7U05zbO"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# read the entire file into a Python array\n",
    "with open('recipeitems-latest.json', 'r') as f:\n",
    "    # Extract each line\n",
    "    data = (line.strip() for line in f)\n",
    "    # Reformat so each line is the element of a list\n",
    "    data_json = \"[{0}]\".format(','.join(data))\n",
    "# read the result as a JSON\n",
    "recipes = pd.read_json(data_json)"
   ]
  },
  {
   "metadata": {
    "id": "7cmi5r5I5zbO",
    "outputId": "feb745a7-8df2-4a31-f590-7da440eb2480"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173278, 17)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "recipes.shape"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We see there are nearly 200,000 recipes, and 17 columns.\n",
    "Let's take a look at one row to see what we have:"
   ]
  },
  {
   "metadata": {
    "id": "cp2ihP5d5zbO",
    "outputId": "5aee383a-546e-4642-adcb-16aa2420d0c1"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_id                                {'$oid': '5160756b96cc62079cc2db15'}\n",
       "cookTime                                                          PT30M\n",
       "creator                                                             NaN\n",
       "dateModified                                                        NaN\n",
       "datePublished                                                2013-03-11\n",
       "description           Late Saturday afternoon, after Marlboro Man ha...\n",
       "image                 http://static.thepioneerwoman.com/cooking/file...\n",
       "ingredients           Biscuits\\n3 cups All-purpose Flour\\n2 Tablespo...\n",
       "name                                    Drop Biscuits and Sausage Gravy\n",
       "prepTime                                                          PT10M\n",
       "recipeCategory                                                      NaN\n",
       "recipeInstructions                                                  NaN\n",
       "recipeYield                                                          12\n",
       "source                                                  thepioneerwoman\n",
       "totalTime                                                           NaN\n",
       "ts                                             {'$date': 1365276011104}\n",
       "url                   http://thepioneerwoman.com/cooking/2013/03/dro...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "recipes.iloc[0]"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "There is a lot of information there, but much of it is in a very messy form, as is typical of data scraped from the Web.\n",
    "In particular, the ingredient list is in string format; we're going to have to carefully extract the information we're interested in.\n",
    "Let's start by taking a closer look at the ingredients:"
   ]
  },
  {
   "metadata": {
    "id": "t1X1iDT65zbP",
    "outputId": "cc5d4be5-f317-484e-f3ee-ec996366f92b"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    173278.000000\n",
       "mean        244.617926\n",
       "std         146.705285\n",
       "min           0.000000\n",
       "25%         147.000000\n",
       "50%         221.000000\n",
       "75%         314.000000\n",
       "max        9067.000000\n",
       "Name: ingredients, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "recipes.ingredients.str.len().describe()"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The ingredient lists average 250 characters long, with a minimum of 0 and a maximum of nearly 10,000 characters!\n",
    "\n",
    "Just out of curiousity, let's see which recipe has the longest ingredient list:"
   ]
  },
  {
   "metadata": {
    "id": "Ls7ucgKR5zbQ",
    "outputId": "59f59099-ac3b-4c59-ad7c-116f6d2a0ef7"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Carrot Pineapple Spice &amp; Brownie Layer Cake with Whipped Cream &amp; Cream Cheese Frosting and Marzipan Carrots'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "recipes.name[np.argmax(recipes.ingredients.str.len())]"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "That certainly looks like an involved recipe.\n",
    "\n",
    "We can do other aggregate explorations; for example, let's see how many of the recipes are for breakfast food:"
   ]
  },
  {
   "metadata": {
    "id": "nOHW5dlm5zbR",
    "outputId": "8c857efe-d713-433b-c3b2-d5f8130548bd"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3524"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "recipes.description.str.contains('[Bb]reakfast').sum()"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Or how many of the recipes list cinnamon as an ingredient:"
  },
  {
   "metadata": {
    "id": "RZVrMl0B5zbS",
    "outputId": "ec2f487b-5ecc-4909-9065-c5dca8630871"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10526"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "recipes.ingredients.str.contains('[Cc]innamon').sum()"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We could even look to see whether any recipes misspell the ingredient as \"cinamon\":"
  },
  {
   "metadata": {
    "id": "zP_1tCZG5zbS",
    "outputId": "109e0424-14de-40f5-b1a1-e142281035c6"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "recipes.ingredients.str.contains('[Cc]inamon').sum()"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This is the type of essential data exploration that is possible with Pandas string tools.\n",
    "It is data munging like this that Python really excels at."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### A simple recipe recommender\n",
    "\n",
    "Let's go a bit further, and start working on a simple recipe recommendation system: given a list of ingredients, find a recipe that uses all those ingredients.\n",
    "While conceptually straightforward, the task is complicated by the heterogeneity of the data: there is no easy operation, for example, to extract a clean list of ingredients from each row.\n",
    "So we will cheat a bit: we'll start with a list of common ingredients, and simply search to see whether they are in each recipe's ingredient list.\n",
    "For simplicity, let's just stick with herbs and spices for the time being:"
   ]
  },
  {
   "metadata": {
    "collapsed": true,
    "id": "ZqTHIH2d5zbT"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "spice_list = ['salt', 'pepper', 'oregano', 'sage', 'parsley',\n",
    "              'rosemary', 'tarragon', 'thyme', 'paprika', 'cumin']"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can then build a Boolean ``DataFrame`` consisting of True and False values, indicating whether this ingredient appears in the list:"
  },
  {
   "metadata": {
    "id": "qxuomPWy5zbU",
    "outputId": "075f95c7-fa64-46b9-d87e-78d9e4192cfe"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cumin</th>\n",
       "      <th>oregano</th>\n",
       "      <th>paprika</th>\n",
       "      <th>parsley</th>\n",
       "      <th>pepper</th>\n",
       "      <th>rosemary</th>\n",
       "      <th>sage</th>\n",
       "      <th>salt</th>\n",
       "      <th>tarragon</th>\n",
       "      <th>thyme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cumin oregano paprika parsley pepper rosemary   sage   salt tarragon  thyme\n",
       "0  False   False   False   False  False    False   True  False    False  False\n",
       "1  False   False   False   False  False    False  False  False    False  False\n",
       "2   True   False   False   False   True    False  False   True    False  False\n",
       "3  False   False   False   False  False    False  False  False    False  False\n",
       "4  False   False   False   False  False    False  False  False    False  False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "import re\n",
    "spice_df = pd.DataFrame(dict((spice, recipes.ingredients.str.contains(spice, re.IGNORECASE))\n",
    "                             for spice in spice_list))\n",
    "spice_df.head()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now, as an example, let's say we'd like to find a recipe that uses parsley, paprika, and tarragon.\n",
    "We can compute this very quickly using the ``query()`` method of ``DataFrame``s, discussed in [High-Performance Pandas: ``eval()`` and ``query()``](03.12-Performance-Eval-and-Query.ipynb):"
   ]
  },
  {
   "metadata": {
    "id": "af7DKPBs5zbU",
    "outputId": "b014a71e-6a33-4108-9ca6-3d73259b656a"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "selection = spice_df.query('parsley & paprika & tarragon')\n",
    "len(selection)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We find only 10 recipes with this combination; let's use the index returned by this selection to discover the names of the recipes that have this combination:"
  },
  {
   "metadata": {
    "id": "A67SEGFV5zbV",
    "outputId": "3abceadb-0b33-4158-b647-9ab395e2c0ec"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2069      All cremat with a Little Gem, dandelion and wa...\n",
       "74964                         Lobster with Thermidor butter\n",
       "93768      Burton's Southern Fried Chicken with White Gravy\n",
       "113926                     Mijo's Slow Cooker Shredded Beef\n",
       "137686                     Asparagus Soup with Poached Eggs\n",
       "140530                                 Fried Oyster Po’boys\n",
       "158475                Lamb shank tagine with herb tabbouleh\n",
       "158486                 Southern fried chicken in buttermilk\n",
       "163175            Fried Chicken Sliders with Pickles + Slaw\n",
       "165243                        Bar Tartine Cauliflower Salad\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": "recipes.name[selection.index]"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now that we have narrowed down our recipe selection by a factor of almost 20,000, we are in a position to make a more informed decision about what we'd like to cook for dinner."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Going further with recipes\n",
    "\n",
    "Hopefully this example has given you a bit of a flavor (ba-dum!) for the types of data cleaning operations that are efficiently enabled by Pandas string methods.\n",
    "Of course, building a very robust recipe recommendation system would require a *lot* more work!\n",
    "Extracting full ingredient lists from each recipe would be an important piece of the task; unfortunately, the wide variety of formats used makes this a relatively time-consuming process.\n",
    "This points to the truism that in data science, cleaning and munging of real-world data often comprises the majority of the work, and Pandas provides the tools that can help you do this efficiently."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<!--NAVIGATION-->\n",
    "< [Pivot Tables](03.09-Pivot-Tables.ipynb) | [Contents](Index.ipynb) | [Working with Time Series](03.11-Working-with-Time-Series.ipynb) >\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.10-Working-With-Strings.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Strings methods and strings methods with regular expressions\n",
    "\n",
    "### Strings methods\n",
    "\n",
    "\n",
    "In the cell below a Series object is created with names."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T12:57:01.682515Z",
     "start_time": "2025-02-04T12:57:01.677020Z"
    },
    "id": "I1hf7wSg5zrz"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "df=pd.Series(['Leonardo DiCaprio',\n",
    "'Meryl Streep',\n",
    "'Denzel Washington',\n",
    "'Scarlett Johansson',\n",
    "'  Kevin De Bruyne',\n",
    "'Natalie Portman',\n",
    "'Leonel Messi',\n",
    "' Tom Hanks ',\n",
    "'Angelina Jolie',\n",
    "'Christian Bale',\n",
    "' Kevin Bacon '              ],name=\"famous\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "1) In the list we have some blanks in the beginning and the end. Remove them. Call the Series names."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T12:57:01.725117Z",
     "start_time": "2025-02-04T12:57:01.718834Z"
    },
    "id": "aoU43YK-5zr3",
    "outputId": "0108838d-4d99-4259-c579-cdfdad6a6df5"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      Leonardo DiCaprio\n",
      "1           Meryl Streep\n",
      "2      Denzel Washington\n",
      "3     Scarlett Johansson\n",
      "4        Kevin De Bruyne\n",
      "5        Natalie Portman\n",
      "6           Leonel Messi\n",
      "7              Tom Hanks\n",
      "8         Angelina Jolie\n",
      "9         Christian Bale\n",
      "10           Kevin Bacon\n",
      "Name: famous, dtype: object\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "# first name\n",
    "names=df.str.strip()\n",
    "print(names)\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "2) Make a series with the len of all the actor names in it."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T12:57:01.769773Z",
     "start_time": "2025-02-04T12:57:01.761129Z"
    },
    "id": "4YzntPPW5zr5",
    "outputId": "c327e63d-e25a-4627-853a-0a416eb01e68"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     17\n",
      "1     12\n",
      "2     17\n",
      "3     18\n",
      "4     15\n",
      "5     15\n",
      "6     12\n",
      "7      9\n",
      "8     14\n",
      "9     14\n",
      "10    11\n",
      "Name: famous, dtype: int64\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "\n",
    "names_len=names.str.len()\n",
    "print(names_len)\n",
    "#SOLUTION_START\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "3) Make a list which will transform all the actors name in lower case"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T12:57:01.820892Z",
     "start_time": "2025-02-04T12:57:01.815276Z"
    },
    "id": "kg_DnOgV5zr6"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "df_lower=names.str.lower()\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": "4) Create a dataframe with column 'name' with the names in uppercase and column 'length' with the length\n"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T12:57:01.883580Z",
     "start_time": "2025-02-04T12:57:01.870430Z"
    },
    "id": "THE7E6yn5zr7",
    "outputId": "7e652bc8-93fd-4833-8e1b-c310af2cf801"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  name  length\n",
      "0    LEONARDO DICAPRIO      17\n",
      "1         MERYL STREEP      12\n",
      "2    DENZEL WASHINGTON      17\n",
      "3   SCARLETT JOHANSSON      18\n",
      "4      KEVIN DE BRUYNE      15\n",
      "5      NATALIE PORTMAN      15\n",
      "6         LEONEL MESSI      12\n",
      "7            TOM HANKS       9\n",
      "8       ANGELINA JOLIE      14\n",
      "9       CHRISTIAN BALE      14\n",
      "10         KEVIN BACON      11\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "data = pd.DataFrame({'name':names.str.upper(),'length':names.str.len()})\n",
    "print(data)\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "5) Make a dataframe df_short with:\\\n",
    "   a) Column first_five with only the first 5 characters of each string in the Series names.\\\n",
    "   b) Column not_last_six which will show the string except the last 6 characters of each string of Series names.\\\n",
    "   c) Column last_seven with only the last 7 characters in each string\\"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T12:57:02.117473Z",
     "start_time": "2025-02-04T12:57:02.103843Z"
    },
    "id": "VBMa3hgh5zr8"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "df_short = pd.DataFrame({'first_five':names.str[0:5],'not_last_six':names.str[:-6],'last_seven':names.str[-7:]})\n",
    "#SOLUTION_END\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "6) a) Make a list of all the words in string_to_be_cut.\\\n",
    "   b) Convert the list to a pandas Series\\\n",
    "   c) Use a string function to display the position of the first 'n'\\\n",
    "   d) Split the string in three parts with 'cut' in the middle and print  the 3 parts.\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T12:59:57.102382Z",
     "start_time": "2025-02-04T12:59:57.091352Z"
    },
    "id": "rdPVJT115zr9",
    "outputId": "49852d72-b45f-42d7-bfe8-afa3b6d7e27f"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      This\n",
      "1    string\n",
      "2     needs\n",
      "3        to\n",
      "4        be\n",
      "5       cut\n",
      "6        in\n",
      "7    pieces\n",
      "dtype: object\n",
      "10\n",
      "29\n",
      "0    This string needs to be \n",
      "1                         cut\n",
      "2                   in pieces\n",
      "dtype: object\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "string_to_be_cut=\"This string needs to be cut in pieces\"\n",
    "#SOLUTION_START\n",
    "#a\n",
    "List_string_cut=string_to_be_cut.split()\n",
    "#b\n",
    "Series_string_cut=pd.Series(List_string_cut)\n",
    "print (Series_string_cut)\n",
    "#c\n",
    "first_place=string_to_be_cut.find('n') + 1 # + 1 because first postion is 0\n",
    "print(first_place)\n",
    "#d\n",
    "three_parts=string_to_be_cut.partition(\"cut\")\n",
    "print(pd.Series([three_parts[0],three_parts[1],three_parts[2]]))\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "7.  Create a dataframe with a column 'first_name' and a column 'last_name' with the first and last name of the famous people.\\\n",
    "*Tip 1: Take a look at the split() n parameter*\\\n",
    "*Tip 2: str.get() can be used to get the different strings from the split()*"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T16:21:46.265825Z",
     "start_time": "2025-02-04T16:21:46.223112Z"
    },
    "id": "8bTWGFKH5zr9",
    "outputId": "19ed409b-d7d6-4017-92a2-8b67bea0f7eb"
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        first        last\n",
       "0    Leonardo    DiCaprio\n",
       "1       Meryl      Streep\n",
       "2      Denzel  Washington\n",
       "3    Scarlett   Johansson\n",
       "4       Kevin   De Bruyne\n",
       "5     Natalie     Portman\n",
       "6      Leonel       Messi\n",
       "7         Tom       Hanks\n",
       "8    Angelina       Jolie\n",
       "9   Christian        Bale\n",
       "10      Kevin       Bacon"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Leonardo</td>\n",
       "      <td>DiCaprio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Meryl</td>\n",
       "      <td>Streep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Denzel</td>\n",
       "      <td>Washington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Scarlett</td>\n",
       "      <td>Johansson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kevin</td>\n",
       "      <td>De Bruyne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Natalie</td>\n",
       "      <td>Portman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Leonel</td>\n",
       "      <td>Messi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tom</td>\n",
       "      <td>Hanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Angelina</td>\n",
       "      <td>Jolie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Christian</td>\n",
       "      <td>Bale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Kevin</td>\n",
       "      <td>Bacon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "split_names = names.str.split(n=1)\n",
    "df_name = pd.DataFrame({'first': split_names.str.get(0), 'last': split_names.str.get(1)})\n",
    "df_name\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "6) Make a df_replaced where you replace all the white spaces with '\\\\_' in the list of famous people.\\"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T07:41:49.053705Z",
     "start_time": "2025-02-06T07:41:49.035782Z"
    },
    "id": "iJ1rdNp55zr-",
    "outputId": "e6a2a500-60e7-498f-96e6-2589054c40b5"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      Leonardo_DiCaprio\n",
      "1           Meryl_Streep\n",
      "2      Denzel_Washington\n",
      "3     Scarlett_Johansson\n",
      "4      __Kevin_De_Bruyne\n",
      "5        Natalie_Portman\n",
      "6           Leonel_Messi\n",
      "7            _Tom_Hanks_\n",
      "8         Angelina_Jolie\n",
      "9         Christian_Bale\n",
      "10         _Kevin_Bacon_\n",
      "Name: famous, dtype: object\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "df_replaced = df.str.replace(\" \",\"_\")\n",
    "print(df2)\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "7. In de cell below we have a Series with some rubbish in it.\\"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T07:46:41.245541Z",
     "start_time": "2025-02-06T07:46:41.228722Z"
    },
    "id": "tR5p3PE35zr-"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "rubbish=pd.Series(['just a phrase',\n",
    "\"123\",\n",
    "'45,56',\n",
    "'HI',\n",
    "\"\\u0030\",\n",
    "'Natalie Portman',\n",
    "\"\\u00B2\",\n",
    "'22.23',\n",
    "'Angelina Jolie',\n",
    "'Christian Bale',\n",
    "' Kevin Bacon '              ],name=\"rubbish\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "a) For each element print whether the string is numeric\\\n",
    "b) For each element print whether the string is decimal. Check wheter the results are what you expect.\\\n",
    "c) For each element print whether the string contains the substring 'Ba'\\\n",
    "d)  For each element print whether the strings start with a alphabetic character and ends with an alphabetic character using regex."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T08:02:08.963493Z",
     "start_time": "2025-02-06T08:02:08.926017Z"
    },
    "id": "8fX_eMlB5zr_",
    "outputId": "9550cc95-08dd-457a-cdd9-a836ad018a99"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     False\n",
      "1      True\n",
      "2     False\n",
      "3     False\n",
      "4      True\n",
      "5     False\n",
      "6      True\n",
      "7     False\n",
      "8     False\n",
      "9     False\n",
      "10    False\n",
      "Name: rubbish, dtype: bool\n",
      "0     False\n",
      "1      True\n",
      "2     False\n",
      "3     False\n",
      "4      True\n",
      "5     False\n",
      "6     False\n",
      "7     False\n",
      "8     False\n",
      "9     False\n",
      "10    False\n",
      "Name: rubbish, dtype: bool\n",
      "0     False\n",
      "1     False\n",
      "2     False\n",
      "3     False\n",
      "4     False\n",
      "5     False\n",
      "6     False\n",
      "7     False\n",
      "8     False\n",
      "9      True\n",
      "10     True\n",
      "Name: rubbish, dtype: bool\n",
      "0     False\n",
      "1     False\n",
      "2     False\n",
      "3     False\n",
      "4     False\n",
      "5     False\n",
      "6     False\n",
      "7     False\n",
      "8     False\n",
      "9      True\n",
      "10     True\n",
      "Name: rubbish, dtype: bool\n",
      "0      True\n",
      "1     False\n",
      "2     False\n",
      "3      True\n",
      "4     False\n",
      "5      True\n",
      "6     False\n",
      "7     False\n",
      "8      True\n",
      "9      True\n",
      "10    False\n",
      "Name: rubbish, dtype: bool\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "#SOLUTION_START\n",
    "#a\n",
    "print(rubbish.str.isnumeric())\n",
    "# Entry 4 and 6 considered as True because these are the unicode characters for 0 and ²\n",
    "#b\n",
    "print(rubbish.str.isdecimal())\n",
    "#c\n",
    "print(rubbish.str.contains('Ba'))\n",
    "#alternative with regular expressions\n",
    "print(rubbish.str.contains('Ba',regex=True))\n",
    "#d\n",
    "print(rubbish.str.contains('^[a-zA-Z].*[a-zA-Z]$',regex=True))\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Oplossingen Airports"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Import all necessary libraries to complete the exercise here:"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T12:34:43.602279Z",
     "start_time": "2025-03-17T12:34:43.592048Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 1,
   "source": [
    "#SOLUTION_START\n",
    "import pandas as pd\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Read the following CSV files with the delay data of American airlines into two DataFrames. You can find this data at the following URLs:\\\n",
    "_Tip: Use the URL directly in the read_csv function._\\\n",
    "\n",
    "- https://raw.githubusercontent.com/nickdcox/learn-airline-delays/main/delays_2018.csv (name this dataframe `delays2018`)\n",
    "- https://raw.githubusercontent.com/nickdcox/learn-airline-delays/main/delays_2019.csv (name this dataframe `delays2019`)\n",
    "\n",
    "You will find the following data:\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "```{text}\n",
    "            Column Name                                                                                           Description\n",
    "0                  date                                                   Year and month, in the format YYYY-M (e.g., 2018-1)\n",
    "1               carrier                                                 The two character designator for the carrier/airline.\n",
    "2          carrier_name                                                                 The full name of the carrier/airline.\n",
    "3               airport                                               The three character designator for the arrival airport.\n",
    "4          airport_name                                                                 The full name of the arrival airport.\n",
    "5           arr_flights            The total number of arriving flights for the carrier-airport pair for the month specified.\n",
    "6             arr_del15   The number of arriving flights that were delayed. Delayed is when a flight arrives more than 15 ...\n",
    "7            carrier_ct                                        The number of arriving flights delayed due to a carrier issue.\n",
    "8            weather_ct                                        The number of arriving flights delayed due to a weather issue.\n",
    "9                nas_ct                            The number of arriving flights delayed due to a national air system issue.\n",
    "10          security_ct                                      The number of arriving flights delayed due to a security issue.\n",
    "11     late_aircraft_ct                The number of arriving flights delayed due to an earlier late arrival of an aircraft.\n",
    "12        arr_cancelled                                                                     The number of cancelled flights.\n",
    "13         arr_diverted                                                                      The number of diverted flights.\n",
    "14            arr_delay                                                   The total number of delayed minutes due to delays.\n",
    "15        carrier_delay                                           The total number of delayed minutes due to carrier issues.\n",
    "16        weather_delay                                           The total number of delayed minutes due to weather issues.\n",
    "17            nas_delay                               The total number of delayed minutes due to national air system issues.\n",
    "18       security_delay                                          The total number of delayed minutes due to security issues.\n",
    "19  late_aircraft_delay                        The total number of delayed minutes due to earlier later arrival of aircraft.\n",
    "```\n",
    "After the import, verify all columns and their data types. Adjust the read_csv function if needed."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T12:34:45.141213Z",
     "start_time": "2025-03-17T12:34:43.640685Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20231 entries, 0 to 20230\n",
      "Data columns (total 20 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   date                 20231 non-null  object \n",
      " 1   carrier              20201 non-null  object \n",
      " 2   carrier_name         20201 non-null  object \n",
      " 3   airport              20212 non-null  object \n",
      " 4   airport_name         20212 non-null  object \n",
      " 5   arr_flights          20214 non-null  float64\n",
      " 6   arr_del15            20211 non-null  float64\n",
      " 7   carrier_ct           20214 non-null  float64\n",
      " 8   weather_ct           20214 non-null  float64\n",
      " 9   nas_ct               20214 non-null  float64\n",
      " 10  security_ct          20214 non-null  float64\n",
      " 11  late_aircraft_ct     20214 non-null  float64\n",
      " 12  arr_cancelled        20214 non-null  float64\n",
      " 13  arr_diverted         20214 non-null  float64\n",
      " 14  arr_delay            20214 non-null  float64\n",
      " 15  carrier_delay        20214 non-null  float64\n",
      " 16  weather_delay        20214 non-null  float64\n",
      " 17  nas_delay            20214 non-null  float64\n",
      " 18  security_delay       20214 non-null  float64\n",
      " 19  late_aircraft_delay  20214 non-null  float64\n",
      "dtypes: float64(15), object(5)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "execution_count": 2,
   "source": [
    "#SOLUTION_START\n",
    "delays2018 = pd.read_csv(\"https://raw.githubusercontent.com/nickdcox/learn-airline-delays/main/delays_2018.csv\", sep=\",\", decimal=\".\", header=0)\n",
    "delays2019 = pd.read_csv(\"https://raw.githubusercontent.com/nickdcox/learn-airline-delays/main/delays_2019.csv\", sep=\",\", decimal=\".\", header=0)\n",
    "delays2018.info()\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Concatenate the two dataframes into one dataframe named delays and then display the total number of rows. You can concatenate dataframes with the function pd.concat(). Create a new index when concatenating, which can be done with a specific parameter. In total, you should get 41177 rows. Verify that."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T12:34:47.166690Z",
     "start_time": "2025-03-17T12:34:47.129372Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date carrier carrier_name airport  \\\n",
      "41172  2019-1      MQ    Envoy Air     RIC   \n",
      "41173  2019-1      MQ    Envoy Air     ROA   \n",
      "41174  2019-1      MQ    Envoy Air     ROC   \n",
      "41175  2019-1      MQ    Envoy Air     RST   \n",
      "41176  2019-1      MQ    Envoy Air     SAT   \n",
      "\n",
      "                                            airport_name  arr_flights  \\\n",
      "41172               Richmond, VA: Richmond International        195.0   \n",
      "41173  Roanoke, VA: Roanoke Blacksburg Regional Woodr...         52.0   \n",
      "41174     Rochester, NY: Greater Rochester International        106.0   \n",
      "41175             Rochester, MN: Rochester International        116.0   \n",
      "41176         San Antonio, TX: San Antonio International         26.0   \n",
      "\n",
      "       arr_del15  carrier_ct  weather_ct  nas_ct  security_ct  \\\n",
      "41172       68.0       12.12        1.87   17.97          0.0   \n",
      "41173       14.0        2.74        0.69    2.46          0.0   \n",
      "41174       26.0        4.67        2.26   11.81          0.0   \n",
      "41175       35.0        6.83        6.92   11.50          0.0   \n",
      "41176        4.0        1.16        0.64    1.92          0.0   \n",
      "\n",
      "       late_aircraft_ct  arr_cancelled  arr_diverted  arr_delay  \\\n",
      "41172             36.04           22.0           0.0     4138.0   \n",
      "41173              8.11            2.0           1.0      726.0   \n",
      "41174              7.26           17.0           0.0     1259.0   \n",
      "41175              9.75           22.0           0.0     2307.0   \n",
      "41176              0.29            5.0           0.0      120.0   \n",
      "\n",
      "       carrier_delay  weather_delay  nas_delay  security_delay  \\\n",
      "41172          603.0          196.0      780.0             0.0   \n",
      "41173          323.0           31.0      112.0             0.0   \n",
      "41174          313.0           99.0      484.0             0.0   \n",
      "41175          474.0          633.0      523.0             0.0   \n",
      "41176           50.0           14.0       41.0             0.0   \n",
      "\n",
      "       late_aircraft_delay  \n",
      "41172               2559.0  \n",
      "41173                260.0  \n",
      "41174                363.0  \n",
      "41175                677.0  \n",
      "41176                 15.0  \n",
      "41177\n"
     ]
    }
   ],
   "execution_count": 3,
   "source": [
    "#SOLUTION_START\n",
    "delays = pd.concat([delays2018, delays2019], ignore_index=True)\n",
    "print(delays.tail())\n",
    "print(len(delays))\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Remove all rows where one of the following conditions is met:\n",
    "* the airport has no arriving flights (missing value for arr_flights)\n",
    "* empty carrier or empty airports.\\\n",
    "In total, you should now have 41097 rows left. Verify that."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T12:34:47.313671Z",
     "start_time": "2025-03-17T12:34:47.271609Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41097"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4,
   "source": [
    "#SOLUTION_START\n",
    "delays = delays[delays.arr_flights.notna() & delays.carrier.notna() & delays.airport.notna()]\n",
    "\n",
    "delays.dropna()\n",
    "len(delays)\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Print a list of all airports located in \"Tennessee\". These airports have the letters \"TN:\" in their \"airport_name\". There should be 5 of them."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T12:38:38.137462Z",
     "start_time": "2025-03-17T12:38:37.921155Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BNA', 'MEM', 'CHA', 'TYS', 'TRI'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "         date carrier       carrier_name airport  \\\n",
       "1      2018-1      MQ          Envoy Air     BNA   \n",
       "67     2018-1      MQ          Envoy Air     MEM   \n",
       "160    2018-1      OH  PSA Airlines Inc.     BNA   \n",
       "167    2018-1      OH  PSA Airlines Inc.     CHA   \n",
       "206    2018-1      OH  PSA Airlines Inc.     MEM   \n",
       "...       ...     ...                ...     ...   \n",
       "41038  2019-1      G4      Allegiant Air     TRI   \n",
       "41041  2019-1      G4      Allegiant Air     TYS   \n",
       "41078  2019-1      MQ          Envoy Air     BNA   \n",
       "41087  2019-1      MQ          Envoy Air     CHA   \n",
       "41148  2019-1      MQ          Envoy Air     MEM   \n",
       "\n",
       "                                         airport_name  arr_flights  arr_del15  \\\n",
       "1              Nashville, TN: Nashville International        110.0       21.0   \n",
       "67                 Memphis, TN: Memphis International         80.0       24.0   \n",
       "160            Nashville, TN: Nashville International        169.0       45.0   \n",
       "167                     Chattanooga, TN: Lovell Field        162.0       41.0   \n",
       "206                Memphis, TN: Memphis International        138.0       24.0   \n",
       "...                                               ...          ...        ...   \n",
       "41038  Bristol/Johnson City/Kingsport, TN: Tri Cities          9.0        0.0   \n",
       "41041                     Knoxville, TN: McGhee Tyson         89.0       22.0   \n",
       "41078          Nashville, TN: Nashville International        193.0       51.0   \n",
       "41087                   Chattanooga, TN: Lovell Field         52.0       15.0   \n",
       "41148              Memphis, TN: Memphis International        207.0       55.0   \n",
       "\n",
       "       carrier_ct  weather_ct  nas_ct  security_ct  late_aircraft_ct  \\\n",
       "1            7.17        1.16    6.76         0.00              5.92   \n",
       "67           7.78        1.53    8.05         0.00              6.64   \n",
       "160         14.15        2.33    4.63         0.00             23.89   \n",
       "167         16.64        0.64   11.41         0.00             12.31   \n",
       "206          9.78        0.49    3.46         0.78              9.49   \n",
       "...           ...         ...     ...          ...               ...   \n",
       "41038        0.00        0.00    0.00         0.00              0.00   \n",
       "41041        1.48        1.00    3.99         0.00             15.53   \n",
       "41078        6.67        3.12   16.81         0.00             24.41   \n",
       "41087        2.68        0.53    7.82         0.00              3.97   \n",
       "41148       15.87        4.76   19.73         0.00             14.65   \n",
       "\n",
       "       arr_cancelled  arr_diverted  arr_delay  carrier_delay  weather_delay  \\\n",
       "1                3.0           0.0      897.0          344.0           37.0   \n",
       "67               1.0           0.0     1285.0          328.0          129.0   \n",
       "160              5.0           3.0     3783.0         1319.0           89.0   \n",
       "167              8.0           0.0     2498.0         1002.0          121.0   \n",
       "206              6.0           0.0     1749.0          556.0          126.0   \n",
       "...              ...           ...        ...            ...            ...   \n",
       "41038            0.0           0.0        0.0            0.0            0.0   \n",
       "41041            0.0           0.0      976.0           70.0           17.0   \n",
       "41078           11.0           0.0     3216.0          383.0          258.0   \n",
       "41087            9.0           0.0      482.0          108.0           19.0   \n",
       "41148            9.0           1.0     3187.0         1022.0          367.0   \n",
       "\n",
       "       nas_delay  security_delay  late_aircraft_delay  \n",
       "1          226.0             0.0                290.0  \n",
       "67         430.0             0.0                398.0  \n",
       "160        320.0             0.0               2055.0  \n",
       "167        446.0             0.0                929.0  \n",
       "206        228.0            35.0                804.0  \n",
       "...          ...             ...                  ...  \n",
       "41038        0.0             0.0                  0.0  \n",
       "41041      116.0             0.0                773.0  \n",
       "41078      825.0             0.0               1750.0  \n",
       "41087      220.0             0.0                135.0  \n",
       "41148      754.0             0.0               1044.0  \n",
       "\n",
       "[1194 rows x 20 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>carrier</th>\n",
       "      <th>carrier_name</th>\n",
       "      <th>airport</th>\n",
       "      <th>airport_name</th>\n",
       "      <th>arr_flights</th>\n",
       "      <th>arr_del15</th>\n",
       "      <th>carrier_ct</th>\n",
       "      <th>weather_ct</th>\n",
       "      <th>nas_ct</th>\n",
       "      <th>security_ct</th>\n",
       "      <th>late_aircraft_ct</th>\n",
       "      <th>arr_cancelled</th>\n",
       "      <th>arr_diverted</th>\n",
       "      <th>arr_delay</th>\n",
       "      <th>carrier_delay</th>\n",
       "      <th>weather_delay</th>\n",
       "      <th>nas_delay</th>\n",
       "      <th>security_delay</th>\n",
       "      <th>late_aircraft_delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-1</td>\n",
       "      <td>MQ</td>\n",
       "      <td>Envoy Air</td>\n",
       "      <td>BNA</td>\n",
       "      <td>Nashville, TN: Nashville International</td>\n",
       "      <td>110.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.17</td>\n",
       "      <td>1.16</td>\n",
       "      <td>6.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.92</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>897.0</td>\n",
       "      <td>344.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>290.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2018-1</td>\n",
       "      <td>MQ</td>\n",
       "      <td>Envoy Air</td>\n",
       "      <td>MEM</td>\n",
       "      <td>Memphis, TN: Memphis International</td>\n",
       "      <td>80.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>7.78</td>\n",
       "      <td>1.53</td>\n",
       "      <td>8.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.64</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1285.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>398.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>2018-1</td>\n",
       "      <td>OH</td>\n",
       "      <td>PSA Airlines Inc.</td>\n",
       "      <td>BNA</td>\n",
       "      <td>Nashville, TN: Nashville International</td>\n",
       "      <td>169.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>14.15</td>\n",
       "      <td>2.33</td>\n",
       "      <td>4.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>23.89</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3783.0</td>\n",
       "      <td>1319.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2055.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>2018-1</td>\n",
       "      <td>OH</td>\n",
       "      <td>PSA Airlines Inc.</td>\n",
       "      <td>CHA</td>\n",
       "      <td>Chattanooga, TN: Lovell Field</td>\n",
       "      <td>162.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>16.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>11.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.31</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2498.0</td>\n",
       "      <td>1002.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>446.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>929.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>2018-1</td>\n",
       "      <td>OH</td>\n",
       "      <td>PSA Airlines Inc.</td>\n",
       "      <td>MEM</td>\n",
       "      <td>Memphis, TN: Memphis International</td>\n",
       "      <td>138.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>9.78</td>\n",
       "      <td>0.49</td>\n",
       "      <td>3.46</td>\n",
       "      <td>0.78</td>\n",
       "      <td>9.49</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1749.0</td>\n",
       "      <td>556.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>804.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41038</th>\n",
       "      <td>2019-1</td>\n",
       "      <td>G4</td>\n",
       "      <td>Allegiant Air</td>\n",
       "      <td>TRI</td>\n",
       "      <td>Bristol/Johnson City/Kingsport, TN: Tri Cities</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41041</th>\n",
       "      <td>2019-1</td>\n",
       "      <td>G4</td>\n",
       "      <td>Allegiant Air</td>\n",
       "      <td>TYS</td>\n",
       "      <td>Knoxville, TN: McGhee Tyson</td>\n",
       "      <td>89.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.48</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>976.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>773.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41078</th>\n",
       "      <td>2019-1</td>\n",
       "      <td>MQ</td>\n",
       "      <td>Envoy Air</td>\n",
       "      <td>BNA</td>\n",
       "      <td>Nashville, TN: Nashville International</td>\n",
       "      <td>193.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6.67</td>\n",
       "      <td>3.12</td>\n",
       "      <td>16.81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24.41</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3216.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>825.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41087</th>\n",
       "      <td>2019-1</td>\n",
       "      <td>MQ</td>\n",
       "      <td>Envoy Air</td>\n",
       "      <td>CHA</td>\n",
       "      <td>Chattanooga, TN: Lovell Field</td>\n",
       "      <td>52.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>7.82</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.97</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>482.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41148</th>\n",
       "      <td>2019-1</td>\n",
       "      <td>MQ</td>\n",
       "      <td>Envoy Air</td>\n",
       "      <td>MEM</td>\n",
       "      <td>Memphis, TN: Memphis International</td>\n",
       "      <td>207.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>15.87</td>\n",
       "      <td>4.76</td>\n",
       "      <td>19.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.65</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3187.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>367.0</td>\n",
       "      <td>754.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1044.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1194 rows × 20 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0        False\n",
       "1         True\n",
       "2        False\n",
       "3        False\n",
       "4        False\n",
       "         ...  \n",
       "41172    False\n",
       "41173    False\n",
       "41174    False\n",
       "41175    False\n",
       "41176    False\n",
       "Name: airport_name, Length: 41097, dtype: bool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8,
   "source": [
    "#SOLUTION_START\n",
    "delays.loc[delays['airport_name'].str.contains(\"TN:\"),'airport'].unique()\n",
    "delays[delays.airport_name.str.contains(\"TN:\")]\n",
    "\n",
    "delays.airport_name.str.contains(\"TN:\")\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Import the coordinates file https://raw.githubusercontent.com/nickdcox/learn-airline-delays/main/airport_coordinates.csv. This file contains the latitude and longitude of various American airports as well as their airport code. Check the imported data and adjust the read_csv function if necessary."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T08:43:20.262986Z",
     "start_time": "2025-03-14T08:43:19.937886Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  airport        lat        long\n",
       "0     01A  58.109444 -152.906667\n",
       "1     03A  65.548056 -161.071667\n",
       "2     04A  68.083333 -163.166667\n",
       "3     05A  67.570000 -148.183889\n",
       "4     06A  57.745278 -152.882778"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airport</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01A</td>\n",
       "      <td>58.109444</td>\n",
       "      <td>-152.906667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03A</td>\n",
       "      <td>65.548056</td>\n",
       "      <td>-161.071667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04A</td>\n",
       "      <td>68.083333</td>\n",
       "      <td>-163.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>05A</td>\n",
       "      <td>67.570000</td>\n",
       "      <td>-148.183889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>06A</td>\n",
       "      <td>57.745278</td>\n",
       "      <td>-152.882778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6,
   "source": [
    "#SOLUTION_START\n",
    "airports_coord = pd.read_csv(\"https://raw.githubusercontent.com/nickdcox/learn-airline-delays/main/airport_coordinates.csv\", sep=\",\", decimal=\".\", header=0)\n",
    "airports_coord.head()\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "List the coördinates for each airport that is listed in the ``delays`` dataframe. Create an ``airport`` dataframe with the columns 'airport' and 'airportnames' based on the delays dataframe. Drop the duplicate values with ``drop_duplicates``. Merge the resulting dataframe with the  ."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T08:43:20.500052Z",
     "start_time": "2025-03-14T08:43:20.430190Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 7,
   "source": [
    "#SOLUTION_START\n",
    "airports = delays.loc[:, ['airport', 'airport_name']].drop_duplicates()\n",
    "airports = airports.merge(airports_coord)\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Calculate the average latitude and longitude of all airports whose name starts with the letter 'B'. You can use the \"startswith()\" str-method of Series for this."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T08:43:20.792078Z",
     "start_time": "2025-03-14T08:43:20.771855Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meanLat= 41.75543103413793\n",
      "leanLong= -100.07142720172413\n"
     ]
    }
   ],
   "execution_count": 8,
   "source": [
    "#SOLUTION_START\n",
    "meanLat = airports[airports.airport_name.str.startswith('B')].lat.mean()\n",
    "print(\"meanLat=\", meanLat)\n",
    "meanLong = airports[airports.airport_name.str.startswith('B')].long.mean()\n",
    "print(\"leanLong=\", meanLong)\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Add a new column \"zone\" that indicates where the airport is located. There are four zones:\n",
    "\"SW\": South-Western (lat < 44.48, long < -120.72)\n",
    "\"SE\": South-Eastern (lat < 44.48, long > -120.72)\n",
    "\"NW\": North-Western (lat > 44.48, long < -120.72)\n",
    "\"NE\": North-Eastern (lat > 44.48, long > -120.72) Use the abbreviations SW, SE, NW, and NE as values for the new column."
   ]
  },
  {
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-14T08:43:21.018493Z",
     "start_time": "2025-03-14T08:43:20.976206Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    airport                                    airport_name        lat  \\\n",
       "0       BIS         Bismarck/Mandan, ND: Bismarck Municipal  46.778889   \n",
       "1       BNA          Nashville, TN: Nashville International  36.126667   \n",
       "2       BOI                   Boise, ID: Boise Air Terminal  43.565278   \n",
       "3       BPT  Beaumont/Port Arthur, TX: Jack Brooks Regional  29.950833   \n",
       "4       BUF      Buffalo, NY: Buffalo Niagara International  42.941111   \n",
       "..      ...                                             ...        ...   \n",
       "355     PAE                   Everett, WA: Snohomish County  47.908333   \n",
       "356     ATY               Watertown, SD: Watertown Regional  44.908889   \n",
       "357     PIR                     Pierre, SD: Pierre Regional  44.383611   \n",
       "358     BFM                     Mobile, AL: Mobile Downtown  30.626389   \n",
       "359     XWA    Williston, ND: Williston Basin International  48.260833   \n",
       "\n",
       "           long zone  \n",
       "0   -100.752500   NE  \n",
       "1    -86.681944   SE  \n",
       "2   -116.225000   SE  \n",
       "3    -94.020000   SE  \n",
       "4    -78.736389   SE  \n",
       "..          ...  ...  \n",
       "355 -122.281389   NW  \n",
       "356  -97.154167   NE  \n",
       "357 -100.284167   SE  \n",
       "358  -88.068056   SE  \n",
       "359 -103.751111   NE  \n",
       "\n",
       "[360 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airport</th>\n",
       "      <th>airport_name</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BIS</td>\n",
       "      <td>Bismarck/Mandan, ND: Bismarck Municipal</td>\n",
       "      <td>46.778889</td>\n",
       "      <td>-100.752500</td>\n",
       "      <td>NE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BNA</td>\n",
       "      <td>Nashville, TN: Nashville International</td>\n",
       "      <td>36.126667</td>\n",
       "      <td>-86.681944</td>\n",
       "      <td>SE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOI</td>\n",
       "      <td>Boise, ID: Boise Air Terminal</td>\n",
       "      <td>43.565278</td>\n",
       "      <td>-116.225000</td>\n",
       "      <td>SE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BPT</td>\n",
       "      <td>Beaumont/Port Arthur, TX: Jack Brooks Regional</td>\n",
       "      <td>29.950833</td>\n",
       "      <td>-94.020000</td>\n",
       "      <td>SE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BUF</td>\n",
       "      <td>Buffalo, NY: Buffalo Niagara International</td>\n",
       "      <td>42.941111</td>\n",
       "      <td>-78.736389</td>\n",
       "      <td>SE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>PAE</td>\n",
       "      <td>Everett, WA: Snohomish County</td>\n",
       "      <td>47.908333</td>\n",
       "      <td>-122.281389</td>\n",
       "      <td>NW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>ATY</td>\n",
       "      <td>Watertown, SD: Watertown Regional</td>\n",
       "      <td>44.908889</td>\n",
       "      <td>-97.154167</td>\n",
       "      <td>NE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>PIR</td>\n",
       "      <td>Pierre, SD: Pierre Regional</td>\n",
       "      <td>44.383611</td>\n",
       "      <td>-100.284167</td>\n",
       "      <td>SE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>BFM</td>\n",
       "      <td>Mobile, AL: Mobile Downtown</td>\n",
       "      <td>30.626389</td>\n",
       "      <td>-88.068056</td>\n",
       "      <td>SE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>XWA</td>\n",
       "      <td>Williston, ND: Williston Basin International</td>\n",
       "      <td>48.260833</td>\n",
       "      <td>-103.751111</td>\n",
       "      <td>NE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows × 5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9,
   "source": [
    "#SOLUTION_START\n",
    "airports[\"zone\"] = \"NE\"\n",
    "airports.loc[(airports.lat < 44.48) & (airports.long < -120.72), \"zone\"] = \"SW\"\n",
    "airports.loc[(airports.lat < 44.48) & (airports.long > -120.72), \"zone\"] = \"SE\"\n",
    "airports.loc[(airports.lat > 44.48) & (airports.long < -120.72), \"zone\"] = \"NW\"\n",
    "airports\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now calculate the average latitude and longitude per zone by using aggregation functions."
  },
  {
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-14T09:01:48.492396Z",
     "start_time": "2025-03-14T09:01:48.470769Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            lat        long\n",
       "zone                       \n",
       "NE    46.268081  -97.159407\n",
       "NW    58.226944 -144.120507\n",
       "SE    36.603494  -90.931049\n",
       "SW    35.434575 -130.516993"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zone</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NE</th>\n",
       "      <td>46.268081</td>\n",
       "      <td>-97.159407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NW</th>\n",
       "      <td>58.226944</td>\n",
       "      <td>-144.120507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SE</th>\n",
       "      <td>36.603494</td>\n",
       "      <td>-90.931049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SW</th>\n",
       "      <td>35.434575</td>\n",
       "      <td>-130.516993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11,
   "source": [
    "#SOLUTION_START\n",
    "airports.groupby(\"zone\").aggregate({\"lat\": \"mean\", \"long\": \"mean\"})\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "source": "",
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Weblog Exercise\n",
    "\n",
    "We want to be able to perform analyses on the logs of a web server (\"UofS_access_log.small\"). To do this, you need to get the relevant data into a dataframe. This should be an automated process so that other log files can also be loaded.\n",
    "\n",
    "The following tasks need to be done. The original dataframe should be reworked so that only these columns remain:\n",
    "\n",
    "- domain: contains the addresses of the clients that sent a request\n",
    "- timestamp: is a datetime field (POSIXct) that shows the time of the request\n",
    "- resource: shows the resource that was requested\n",
    "- response_code: gives the HTTP response code returned by the server\n",
    "- response_length: indicates the length of the HTTP response\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Import all necessary libraries here:"
  },
  {
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-17T13:36:24.909541Z",
     "start_time": "2025-03-17T13:36:24.900658Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 1,
   "source": [
    "#SOLUTION_START\n",
    "import pandas as pd\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Reading the data\n",
    "Open the file \"UofS_access_log.small\" and investigate its contents. The file is a log file from a web server.\n",
    "\n",
    "Read the dataframe.\n",
    "- Check for yourself what the separator is.\n",
    "- Incorrect rows can be skipped.\n",
    "- There is no header!\n",
    "- The file uses the \"latin\" encoding (consult the docs to learn how to set the encoding) for characters."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T13:36:34.156022Z",
     "start_time": "2025-03-17T13:36:24.942120Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                         0   1     2                      3       4  \\\n",
       "0             202.32.92.47 NaN  <NA>  [01/Jun/1995:00:00:59  -0600]   \n",
       "1  ix-or7-27.ix.netcom.com NaN  <NA>  [01/Jun/1995:00:02:51  -0600]   \n",
       "2          ram0.huji.ac.il NaN  <NA>  [01/Jun/1995:00:05:44  -0600]   \n",
       "3    eagle40.sasknet.sk.ca NaN  <NA>  [01/Jun/1995:00:08:06  -0600]   \n",
       "4    eagle40.sasknet.sk.ca NaN  <NA>  [01/Jun/1995:00:08:19  -0600]   \n",
       "\n",
       "                           5    6         7  \n",
       "0  GET /~scottp/publish.html  200     271.0  \n",
       "1  GET /~ladd/ostriches.html  200  205908.0  \n",
       "2  GET /~scottp/publish.html  200     271.0  \n",
       "3               GET /~lowey/  200    1116.0  \n",
       "4      GET /~lowey/kevin.gif  200   49649.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202.32.92.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>[01/Jun/1995:00:00:59</td>\n",
       "      <td>-0600]</td>\n",
       "      <td>GET /~scottp/publish.html</td>\n",
       "      <td>200</td>\n",
       "      <td>271.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ix-or7-27.ix.netcom.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>[01/Jun/1995:00:02:51</td>\n",
       "      <td>-0600]</td>\n",
       "      <td>GET /~ladd/ostriches.html</td>\n",
       "      <td>200</td>\n",
       "      <td>205908.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ram0.huji.ac.il</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>[01/Jun/1995:00:05:44</td>\n",
       "      <td>-0600]</td>\n",
       "      <td>GET /~scottp/publish.html</td>\n",
       "      <td>200</td>\n",
       "      <td>271.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eagle40.sasknet.sk.ca</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>[01/Jun/1995:00:08:06</td>\n",
       "      <td>-0600]</td>\n",
       "      <td>GET /~lowey/</td>\n",
       "      <td>200</td>\n",
       "      <td>1116.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eagle40.sasknet.sk.ca</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>[01/Jun/1995:00:08:19</td>\n",
       "      <td>-0600]</td>\n",
       "      <td>GET /~lowey/kevin.gif</td>\n",
       "      <td>200</td>\n",
       "      <td>49649.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2,
   "source": [
    "#SOLUTION_START\n",
    "#log = pd.read_csv(\"../datasets/UofS_access_log.small.csv\", sep=\" \", encoding=\"latin\", header=None, on_bad_lines='skip')\n",
    "\n",
    "#This commented code below is the solution for the wrong type of response_length column.\n",
    "log = pd.read_csv(\"../../datasets/UofS_access_log\", sep=\" \", encoding=\"latin\", header=None, on_bad_lines='skip', na_values=\"-\", dtype={2: 'string'})\n",
    "log.head()\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Investigate the dataframe."
  },
  {
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-14T09:05:36.132412Z",
     "start_time": "2025-03-14T09:05:35.319428Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2408623 entries, 0 to 2408622\n",
      "Data columns (total 8 columns):\n",
      " #   Column  Dtype  \n",
      "---  ------  -----  \n",
      " 0   0       object \n",
      " 1   1       float64\n",
      " 2   2       string \n",
      " 3   3       object \n",
      " 4   4       object \n",
      " 5   5       object \n",
      " 6   6       int64  \n",
      " 7   7       float64\n",
      "dtypes: float64(2), int64(1), object(4), string(1)\n",
      "memory usage: 147.0+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "         1             6             7\n",
       "count  0.0  2.408623e+06  2.362336e+06\n",
       "mean   NaN  2.102198e+02  5.479282e+03\n",
       "std    NaN  3.400302e+01  6.396353e+04\n",
       "min    NaN  2.000000e+02  0.000000e+00\n",
       "25%    NaN  2.000000e+02  5.500000e+02\n",
       "50%    NaN  2.000000e+02  1.723000e+03\n",
       "75%    NaN  2.000000e+02  3.455000e+03\n",
       "max    NaN  5.010000e+02  3.019382e+07"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.408623e+06</td>\n",
       "      <td>2.362336e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.102198e+02</td>\n",
       "      <td>5.479282e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.400302e+01</td>\n",
       "      <td>6.396353e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000e+02</td>\n",
       "      <td>5.500000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000e+02</td>\n",
       "      <td>1.723000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000e+02</td>\n",
       "      <td>3.455000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.010000e+02</td>\n",
       "      <td>3.019382e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4,
   "source": [
    "#SOLUTION_START\n",
    "log.info()\n",
    "log.describe()\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Delete columns 1 and 2 as they do not contain any relevant information. Use the ``drop()`` function on the dataframe."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T13:36:40.857761Z",
     "start_time": "2025-03-17T13:36:40.657659Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 3,
   "source": [
    "#SOLUTION_START\n",
    "log.drop(columns=[1,2], inplace=True)\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Column 0 should be named \"domain\", column (with explicit index) 5 should be named \"resource\", 6 should be named \"response_code\", column 7 should be named response_length.Rename these columns in the dataframe by replacing log.columns with the correct names.\n"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T13:36:45.370789Z",
     "start_time": "2025-03-17T13:36:45.361436Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 4,
   "source": [
    "#SOLUTION_START\n",
    "log.columns = [\"domain\",3,4, \"resource\", \"response_code\", \"response_length\"]\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The \"response_length\" has the 'object' type but we expected it to be numerical. What is the reason? Try to solve the problem when reading the csv file."
  },
  {
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-18T10:37:49.991747Z",
     "start_time": "2025-02-18T10:37:49.984499Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 58,
   "source": [
    "#SOLUTION_START\n",
    "# The CSV contains '-' in the response_length column.  This '-' probably indicates that the response length is unknown. We can replace these with NaN values.\n",
    "# Add the na_values parameter to the read_csv function.\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In the previous question you had to replace '-' with NaN values. How many NaN values are in response_length?"
  },
  {
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-17T13:38:26.974997Z",
     "start_time": "2025-03-17T13:38:26.952615Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46287"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8,
   "source": [
    "#SOLUTION_START\n",
    "log[\"response_length\"].isna().sum()\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "What percentage is that of all rows?"
  },
  {
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-18T10:37:50.650516Z",
     "start_time": "2025-02-18T10:37:50.631694Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9217204186790542"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 60,
   "source": [
    "#SOLUTION_START\n",
    "log[\"response_length\"].isna().sum() / len(log[\"response_length\"]) * 100\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The timestamp is spread across columns 3 (date and time) and 4 (timezone). Combine these into one string. Place the result in a variable \"timestamp\" and drop the original columns."
  },
  {
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-18T10:37:52.223882Z",
     "start_time": "2025-02-18T10:37:50.911837Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 61,
   "source": [
    "#SOLUTION_START\n",
    "log['timestamp']= log.loc[:,3] + log.loc[:,4]\n",
    "log.drop(columns=[3,4], inplace=True)\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "Remove the 'GET' and 'HTTP/1.0' that sometimes appear at the beginning and end of the \"resource\" column."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T10:37:58.309795Z",
     "start_time": "2025-02-18T10:37:52.268751Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 62,
   "source": [
    "#SOLUTION_START\n",
    "log[\"resource\"] = log[\"resource\"].str.replace(\"GET \", \"\", regex=False).str.replace(\"HTTP/1.0\", \"\", regex=False)\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Remove all rows from your dataframe where a missing value occurs."
  },
  {
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-18T10:37:59.307899Z",
     "start_time": "2025-02-18T10:37:58.334723Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                    domain               resource  response_code  \\\n",
       "0             202.32.92.47  /~scottp/publish.html            200   \n",
       "1  ix-or7-27.ix.netcom.com  /~ladd/ostriches.html            200   \n",
       "2          ram0.huji.ac.il  /~scottp/publish.html            200   \n",
       "3    eagle40.sasknet.sk.ca               /~lowey/            200   \n",
       "4    eagle40.sasknet.sk.ca      /~lowey/kevin.gif            200   \n",
       "\n",
       "   response_length                    timestamp  \n",
       "0            271.0  [01/Jun/1995:00:00:59-0600]  \n",
       "1         205908.0  [01/Jun/1995:00:02:51-0600]  \n",
       "2            271.0  [01/Jun/1995:00:05:44-0600]  \n",
       "3           1116.0  [01/Jun/1995:00:08:06-0600]  \n",
       "4          49649.0  [01/Jun/1995:00:08:19-0600]  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>resource</th>\n",
       "      <th>response_code</th>\n",
       "      <th>response_length</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202.32.92.47</td>\n",
       "      <td>/~scottp/publish.html</td>\n",
       "      <td>200</td>\n",
       "      <td>271.0</td>\n",
       "      <td>[01/Jun/1995:00:00:59-0600]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ix-or7-27.ix.netcom.com</td>\n",
       "      <td>/~ladd/ostriches.html</td>\n",
       "      <td>200</td>\n",
       "      <td>205908.0</td>\n",
       "      <td>[01/Jun/1995:00:02:51-0600]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ram0.huji.ac.il</td>\n",
       "      <td>/~scottp/publish.html</td>\n",
       "      <td>200</td>\n",
       "      <td>271.0</td>\n",
       "      <td>[01/Jun/1995:00:05:44-0600]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eagle40.sasknet.sk.ca</td>\n",
       "      <td>/~lowey/</td>\n",
       "      <td>200</td>\n",
       "      <td>1116.0</td>\n",
       "      <td>[01/Jun/1995:00:08:06-0600]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eagle40.sasknet.sk.ca</td>\n",
       "      <td>/~lowey/kevin.gif</td>\n",
       "      <td>200</td>\n",
       "      <td>49649.0</td>\n",
       "      <td>[01/Jun/1995:00:08:19-0600]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 63,
   "source": [
    "#SOLUTION_START\n",
    "log.dropna(inplace=True)\n",
    "log.head()\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Find the row(s) with the largest response_length."
  },
  {
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-18T10:37:59.533847Z",
     "start_time": "2025-02-18T10:37:59.495328Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                    domain                resource  response_code  \\\n",
       "127004   mac40199.usask.ca  /uofs/ivany_movie.mov             200   \n",
       "127629       duke.usask.ca  /uofs/ivany_movie.mov             200   \n",
       "131615   agora.carleton.ca  /uofs/ivany_movie.mov             200   \n",
       "144938     krause.usask.ca  /uofs/ivany_movie.mov             200   \n",
       "161552     grapes.usask.ca  /uofs/ivany_movie.mov             200   \n",
       "164035  palona1.cns.hp.com  /uofs/ivany_movie.mov             200   \n",
       "\n",
       "        response_length                    timestamp  \n",
       "127004       30193824.0  [19/Jun/1995:16:32:20-0600]  \n",
       "127629       30193824.0  [19/Jun/1995:17:59:05-0600]  \n",
       "131615       30193824.0  [20/Jun/1995:08:47:16-0600]  \n",
       "144938       30193824.0  [21/Jun/1995:13:16:53-0600]  \n",
       "161552       30193824.0  [23/Jun/1995:11:09:40-0600]  \n",
       "164035       30193824.0  [23/Jun/1995:15:23:04-0600]  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>resource</th>\n",
       "      <th>response_code</th>\n",
       "      <th>response_length</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>127004</th>\n",
       "      <td>mac40199.usask.ca</td>\n",
       "      <td>/uofs/ivany_movie.mov</td>\n",
       "      <td>200</td>\n",
       "      <td>30193824.0</td>\n",
       "      <td>[19/Jun/1995:16:32:20-0600]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127629</th>\n",
       "      <td>duke.usask.ca</td>\n",
       "      <td>/uofs/ivany_movie.mov</td>\n",
       "      <td>200</td>\n",
       "      <td>30193824.0</td>\n",
       "      <td>[19/Jun/1995:17:59:05-0600]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131615</th>\n",
       "      <td>agora.carleton.ca</td>\n",
       "      <td>/uofs/ivany_movie.mov</td>\n",
       "      <td>200</td>\n",
       "      <td>30193824.0</td>\n",
       "      <td>[20/Jun/1995:08:47:16-0600]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144938</th>\n",
       "      <td>krause.usask.ca</td>\n",
       "      <td>/uofs/ivany_movie.mov</td>\n",
       "      <td>200</td>\n",
       "      <td>30193824.0</td>\n",
       "      <td>[21/Jun/1995:13:16:53-0600]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161552</th>\n",
       "      <td>grapes.usask.ca</td>\n",
       "      <td>/uofs/ivany_movie.mov</td>\n",
       "      <td>200</td>\n",
       "      <td>30193824.0</td>\n",
       "      <td>[23/Jun/1995:11:09:40-0600]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164035</th>\n",
       "      <td>palona1.cns.hp.com</td>\n",
       "      <td>/uofs/ivany_movie.mov</td>\n",
       "      <td>200</td>\n",
       "      <td>30193824.0</td>\n",
       "      <td>[23/Jun/1995:15:23:04-0600]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 64,
   "source": [
    "#SOLUTION_START\n",
    "rows = log.response_length == log.response_length.max()\n",
    "log.loc[rows]\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Save the result in a CSV file \"log_result.csv\". Use ',' as the separator and \".\" for decimal numbers."
  },
  {
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-18T10:38:19.405651Z",
     "start_time": "2025-02-18T10:37:59.977325Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 65,
   "source": [
    "#SOLUTION_START\n",
    "log.to_csv(\"log_result.csv\", sep=\",\", decimal=\".\", index=False)\n",
    "#SOLUTION_END"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now, it is time to check that the solution also works for the full dataset \"UofS_access_log\". Perform the same steps as above. Mind that the file is 227Mb and processing can take a while, but should not take ages.\n",
    "When I ran the code with the full data set, it took about 1 minute.\\\n",
    "I also got a warning ``DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.`` Pandas can only know the dtypes after reading the entire file. This is why it is recommended to set the dtype explicitly when reading the file. I added ``dtype={2: 'string'}`` to the read_csv function."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  }
 ]
}
